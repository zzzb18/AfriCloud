import streamlit as st
import pandas as pd
import os
import json
import hashlib
import mimetypes
import base64
import io
import time
import sqlite3
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import zipfile
import shutil
from pathlib import Path
import requests
from PIL import Image
import re
import numpy as np
from collections import Counter
import jieba
import jieba.analyse
try:
    import fitz  # PyMuPDF for PDF preview
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# AIåŠŸèƒ½ç›¸å…³åº“
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import easyocr
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.pipeline import Pipeline
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    # å¦‚æœtransformersä¸å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¶ä»–æ–¹æ³•

# Set page config with premium aesthetics
st.set_page_config(
    page_title="Agribusiness Expert AI Cloud",
    page_icon="ğŸŒ¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Clean and modern CSS styling
st.markdown("""
<style>
    /* Overall Layout */
    .main {
        background: #f8fafc;
        color: #1e293b;
    }
    
    /* Title Styles */
    h1, h2, h3, h4, h5, h6 {
        color: #1e293b;
        font-family: 'Inter', 'Segoe UI', sans-serif;
        font-weight: 600;
        margin-bottom: 1rem;
    }
    
    /* Button Styles */
    .stButton>button {
        background: #3b82f6;
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: 8px;
        font-weight: 500;
        font-size: 14px;
        transition: all 0.2s ease;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.2);
    }
    
    .stButton>button:hover {
        background: #2563eb;
        transform: translateY(-1px);
        box-shadow: 0 4px 8px rgba(59, 130, 246, 0.3);
    }
    
    /* File Card Styles */
    .file-card {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 12px;
        padding: 16px;
        margin-bottom: 12px;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        transition: all 0.2s ease;
    }
    
    .file-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        transform: translateY(-1px);
    }
    
    /* Metric Card Styles */
    .metric-card {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px;
        text-align: center;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    /* Sidebar Styles */
    .css-1d391kg {
        background: white;
        border-right: 1px solid #e2e8f0;
    }
    
    /* Preview Section Styles */
    .preview-section {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 16px;
        margin-top: 16px;
    }
    
    /* File Icon Styles */
    .file-icon {
        font-size: 24px;
        margin-right: 12px;
    }
    
    /* Action Button Styles */
    .action-btn {
        background: #f1f5f9;
        border: 1px solid #e2e8f0;
        color: #64748b;
        padding: 6px 12px;
        border-radius: 6px;
        font-size: 12px;
        margin: 0 2px;
    }
    
    .action-btn:hover {
        background: #e2e8f0;
        color: #475569;
    }
</style>
""", unsafe_allow_html=True)

class CloudStorageManager:
    def __init__(self):
        # äº‘éƒ¨ç½²é…ç½®
        import os
        self.is_cloud_deployment = os.getenv('STREAMLIT_SERVER_PORT') is not None
        
        if self.is_cloud_deployment:
            # äº‘éƒ¨ç½²ï¼šä½¿ç”¨æŒä¹…åŒ–å­˜å‚¨
            self.storage_dir = Path("/tmp/cloud_storage")
            self.cache_dir = Path("/tmp/local_cache")
            self.ai_analysis_dir = Path("/tmp/ai_analysis")
        else:
            # æœ¬åœ°éƒ¨ç½²ï¼šä½¿ç”¨å½“å‰ç›®å½•
            self.storage_dir = Path("cloud_storage")
            self.cache_dir = Path("local_cache")
            self.ai_analysis_dir = Path("ai_analysis")
        
        # åˆ›å»ºç›®å½•
        self.storage_dir.mkdir(exist_ok=True)
        self.cache_dir.mkdir(exist_ok=True)
        self.ai_analysis_dir.mkdir(exist_ok=True)
        
        self.db_path = self.storage_dir / "storage.db"
        self.init_database()
        
        # åˆå§‹åŒ–AIåŠŸèƒ½
        self.init_ai_models()
        
        # å¤©æ°”ç¼“å­˜
        self.latest_weather: Optional[Dict[str, Any]] = None
        # é¥æ„Ÿç¼“å­˜
        self.latest_remote_sensing: Optional[Dict[str, Any]] = None
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ–‡ä»¶è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                file_path TEXT NOT NULL,
                file_size INTEGER,
                file_type TEXT,
                folder_id INTEGER,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                checksum TEXT,
                is_cached BOOLEAN DEFAULT FALSE,
                FOREIGN KEY (folder_id) REFERENCES folders (id)
            )
        ''')
        
        # æ–‡ä»¶å¤¹è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS folders (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                folder_name TEXT NOT NULL,
                parent_folder_id INTEGER,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (parent_folder_id) REFERENCES folders (id)
            )
        ''')
        
        # ä¸Šä¼ è¿›åº¦è¡¨ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS upload_progress (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                total_size INTEGER,
                uploaded_size INTEGER,
                chunk_size INTEGER,
                checksum TEXT,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # AIåˆ†æç»“æœè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ai_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_id INTEGER,
                analysis_type TEXT,
                industry_category TEXT,
                extracted_text TEXT,
                key_phrases TEXT,
                summary TEXT,
                confidence_score REAL,
                method TEXT,
                analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (file_id) REFERENCES files (id)
            )
        ''')

        # è¿ç§»ï¼šè‹¥æ—§è¡¨æ—  method åˆ—åˆ™è¡¥å……
        try:
            cursor.execute("PRAGMA table_info(ai_analysis)")
            cols = [row[1] for row in cursor.fetchall()]
            if 'method' not in cols:
                cursor.execute('ALTER TABLE ai_analysis ADD COLUMN method TEXT')
        except Exception:
            pass
        
        # è¡Œä¸šåˆ†ç±»è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS industry_categories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category_name TEXT UNIQUE,
                keywords TEXT,
                description TEXT,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def init_ai_models(self):
        """åˆå§‹åŒ–AIæ¨¡å‹"""
        # åˆå§‹åŒ–è¡Œä¸šåˆ†ç±»å…³é”®è¯ï¼ˆAgribusinessç»†åˆ†ï¼Œè¡¥å……éæ´²å¸¸è§ä½œç‰©/è¦ç´ ï¼‰
        self.industry_keywords = {
            "ç§æ¤ä¸š": ["ä½œç‰©", "ç‰ç±³", "å°ç±³", "é«˜ç²±", "æ°´ç¨»", "æœ¨è–¯", "å±±è¯", "çº¢è–¯", "èŠ±ç”Ÿ", "èŠéº»", "è‘µèŠ±ç±½", "æ£‰èŠ±", "å¯å¯", "å’–å•¡", "èŒ¶å¶", "é¦™è•‰", "èŠ’æœ", "è è", "è”¬èœ", "æœå›­", "äº§é‡", "å•äº§", "å…¬é¡·", "äº©", "æ’­ç§", "æ”¶è·", "çŒæº‰", "ç—…è™«å®³", "é™¤è‰", "å¯†åº¦"],
            "ç•œç‰§ä¸š": ["ç”ŸçŒª", "ç‰›ç¾Š", "å®¶ç¦½", "å¥¶ç‰›", "å‡ºæ ", "å­˜æ ", "é¥²æ–™", "æ—¥é¾„", "å¢é‡", "æ–™è‚‰æ¯”", "å…ç–«", "å…½è¯", "ç–«ç—…", "ç¹è‚²", "çŠŠç‰›", "å± å®°"],
            "å†œèµ„ä¸åœŸå£¤": ["è‚¥æ–™", "æ°®è‚¥", "ç£·è‚¥", "é’¾è‚¥", "é…æ–¹æ–½è‚¥", "æœ‰æœºè´¨", "pH", "åœŸå£¤ç›åˆ†", "å¾®é‡å…ƒç´ ", "ä¿æ°´", "è¦†ç›–", "æ·±æ¾", "ç§¸ç§†è¿˜ç”°"],
            "å†œä¸šé‡‘è": ["é‡‡è´­", "æˆæœ¬", "è´·æ¬¾", "ä¿å•", "ä¿é™©", "èµ”ä»˜", "ä¿è´¹", "æˆä¿¡", "ç°é‡‘æµ", "åº”æ”¶", "åº”ä»˜", "åˆ©æ¶¦", "æ¯›åˆ©ç‡", "ä»·æ ¼", "æœŸè´§"],
            "ä¾›åº”é“¾ä¸ä»“å‚¨": ["å†·é“¾", "ä»“å‚¨", "ç‰©æµ", "è¿è¾“", "åº“å®¹", "æŸè€—", "å‘¨è½¬", "äº¤ä»˜", "è®¢å•", "æ‰¹æ¬¡", "è¿½æº¯"],
            "æ°”å€™ä¸é¥æ„Ÿ": ["é™é›¨", "é™æ°´", "æ¸©åº¦", "ç§¯æ¸©", "è’¸æ•£", "å¹²æ—±", "NDVI", "EVI", "å«æ˜Ÿ", "é¥æ„Ÿ", "æ°”è±¡ç«™", "è¾å°„", "æ²™æ¼ è—è™«", "è‰åœ°è´ªå¤œè›¾"],
            "å†œä¸šç‰©è”ç½‘": ["ä¼ æ„Ÿå™¨", "æ¹¿åº¦", "å«æ°´ç‡", "EC", "é˜ˆå€¼", "é˜€é—¨", "æ³µç«™", "æ»´çŒ", "å–·çŒ", "è‡ªåŠ¨åŒ–", "æŠ¥è­¦"]
        }
        
        # åˆå§‹åŒ–OCRæ¨¡å‹
        self.ocr_reader = None
        self.ocr_loading = False
        if OCR_AVAILABLE:
            try:
                # å¼‚æ­¥åŠ è½½OCRæ¨¡å‹ï¼Œé¿å…é˜»å¡ç•Œé¢
                st.info("ğŸ”„ Loading OCR model, please wait...")
                self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])
                st.success("âœ… OCR model loaded successfully")
            except Exception as e:
                st.warning(f"âš ï¸ OCR model loading failed: {str(e)}")
                st.info("ğŸ’¡ Please click 'ğŸ”„ Reload AI' to retry later")
        
        # åˆå§‹åŒ–æ–‡æœ¬åˆ†ç±»æ¨¡å‹
        self.text_classifier = None
        if TRANSFORMERS_AVAILABLE:
            try:
                # ä½¿ç”¨ä¸­æ–‡BERTæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»
                self.text_classifier = pipeline(
                    "text-classification",
                    model="bert-base-chinese",
                    tokenizer="bert-base-chinese"
                )
                st.success("âœ… BERT text classification model loaded successfully")
            except Exception as e:
                st.warning(f"âš ï¸ BERT model loading failed: {str(e)}")
        else:
            st.info("â„¹ï¸ Transformers library not installed, using machine learning classification")
        
        # åˆå§‹åŒ–æ‘˜è¦ç”Ÿæˆæ¨¡å‹
        self.summarizer = None
        if TRANSFORMERS_AVAILABLE:
            try:
                # ä½¿ç”¨T5æ¨¡å‹è¿›è¡Œæ‘˜è¦ç”Ÿæˆ
                self.summarizer = pipeline(
                    "summarization",
                    model="t5-small",
                    tokenizer="t5-small"
                )
                st.success("âœ… T5 summarization model loaded successfully")
            except Exception as e:
                st.warning(f"âš ï¸ T5 model loading failed: {str(e)}")
        else:
            st.info("â„¹ï¸ Using smart summarization algorithm")
        
        # åˆå§‹åŒ–æœºå™¨å­¦ä¹ åˆ†ç±»å™¨
        self.ml_classifier = None
        self.ml_trained = False
        if ML_AVAILABLE:
            try:
                # ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
                self.ml_classifier = Pipeline([
                    ('tfidf', TfidfVectorizer(max_features=1000, stop_words=None)),
                    ('classifier', MultinomialNB())
                ])
                # è‡ªåŠ¨åˆå§‹åŒ–é¢„è®­ç»ƒåˆ†ç±»å™¨
                if self.init_pretrained_classifier():
                    st.success("âœ… Pre-trained machine learning classifier loaded successfully")
                else:
                    st.warning("âš ï¸ Pre-trained classifier initialization failed, using keyword matching")
            except Exception as e:
                st.warning(f"âš ï¸ æœºå™¨å­¦ä¹ åˆ†ç±»å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        else:
            st.info("â„¹ï¸ ä½¿ç”¨å…³é”®è¯åŒ¹é…åˆ†ç±»")
        
        # åˆå§‹åŒ–é»˜è®¤è¡Œä¸šåˆ†ç±»
        self.init_default_categories()

    def fetch_weather_summary(self, latitude: float, longitude: float) -> Dict[str, Any]:
        """ä» Open-Meteo è·å–æœªæ¥7å¤©çš„æ°”è±¡æ‘˜è¦ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰"""
        try:
            url = (
                "https://api.open-meteo.com/v1/forecast"
                f"?latitude={latitude}&longitude={longitude}"
                "&hourly=temperature_2m,precipitation"
                "&daily=precipitation_sum,temperature_2m_max,temperature_2m_min"
                "&forecast_days=7&timezone=auto"
            )
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
            data = resp.json()
            daily = data.get("daily", {})
            result = {
                "location": {"lat": latitude, "lon": longitude},
                "precipitation_sum": daily.get("precipitation_sum", []),
                "tmax": daily.get("temperature_2m_max", []),
                "tmin": daily.get("temperature_2m_min", []),
                "dates": daily.get("time", [])
            }
            # ç®€è¦ç»Ÿè®¡
            try:
                total_rain = float(sum(x for x in result["precipitation_sum"] if isinstance(x, (int, float))))
            except Exception:
                total_rain = 0.0
            result["summary"] = {
                "7d_total_rain_mm": round(total_rain, 1),
                "avg_tmax": round(sum(result["tmax"]) / max(1, len(result["tmax"])), 1) if result["tmax"] else None,
                "avg_tmin": round(sum(result["tmin"]) / max(1, len(result["tmin"])), 1) if result["tmin"] else None,
            }
            self.latest_weather = result
            return {"success": True, "weather": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def compute_remote_sensing_stub(self, latitude: float, longitude: float, days: int = 30) -> Dict[str, Any]:
        """é¥æ„ŸæŒ‡æ•°å ä½ï¼šç”Ÿæˆè¿‘dayså¤©çš„NDVI/EVIç®€æ˜“æ—¶åºï¼ˆæ— éœ€å¤–éƒ¨æœåŠ¡ï¼‰ã€‚"""
        try:
            import math
            base_date = datetime.now()
            dates = [(base_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days-1, -1, -1)]
            ndvi = []
            evi = []
            for i in range(days):
                # ç”Ÿæˆå¹³æ»‘çš„æ³¢åŠ¨æ•°æ®ï¼ŒèŒƒå›´åšç‰©ç†åˆç†çº¦æŸ
                v = 0.5 + 0.3 * math.sin(i/6.0) + 0.1 * math.sin(i/2.5)
                ndvi.append(round(max(0.0, min(0.9, v)), 3))
                e = 0.4 + 0.25 * math.sin(i/7.0 + 0.5)
                evi.append(round(max(0.0, min(0.8, e)), 3))
            summary = {
                "ndvi_avg": round(sum(ndvi)/len(ndvi), 3) if ndvi else None,
                "evi_avg": round(sum(evi)/len(evi), 3) if evi else None,
                "ndvi_last": ndvi[-1] if ndvi else None,
                "evi_last": evi[-1] if evi else None,
            }
            result = {
                "location": {"lat": latitude, "lon": longitude},
                "dates": dates,
                "ndvi": ndvi,
                "evi": evi,
                "summary": summary,
            }
            self.latest_remote_sensing = result
            return {"success": True, "remote_sensing": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def extract_agri_structured_fields(self, text: str) -> Dict[str, Any]:
        """å†œä¸šæŠ¥è¡¨æ¨¡æ¿æŠ½å–ï¼ˆè§„åˆ™ç‰ˆå ä½ï¼‰ï¼šä½œç‰©ã€é¢ç§¯ã€æ—¥æœŸã€æ–½è‚¥/çŒæº‰/ç”¨è¯/å•äº§ç­‰ã€‚"""
        if not text:
            return {}
        import re
        fields: Dict[str, Any] = {}
        try:
            # ä½œç‰©
            m = re.search(r'(ä½œç‰©|å“ç§|ä½œç‰©åç§°)[ï¼š:ï¼Œ]\s*([\u4e00-\u9fffA-Za-z0-9]+)', text)
            if m: fields['ä½œç‰©'] = m.group(2)
            # é¢ç§¯ï¼ˆäº©/å…¬é¡·/haï¼‰
            m = re.search(r'(é¢ç§¯|æ’­ç§é¢ç§¯|æ”¶è·é¢ç§¯)[ï¼š:ï¼Œ]\s*([\d,.]+)\s*(äº©|å…¬é¡·|ha)', text)
            if m: fields['é¢ç§¯'] = f"{m.group(2)} {m.group(3)}"
            # æ—¥æœŸï¼ˆç®€å•è¯†åˆ« å¹´-æœˆ-æ—¥ æˆ– å¹´/æœˆ/æ—¥ æˆ– ä¸­æ–‡ï¼‰
            m = re.search(r'(æ—¥æœŸ|æ—¶é—´|è®°å½•æ—¶é—´)[ï¼š:ï¼Œ]\s*(\d{4}[-å¹´/]\d{1,2}[-æœˆ/]\d{1,2})', text)
            if m: fields['æ—¥æœŸ'] = m.group(2)
            # æ–½è‚¥
            m = re.search(r'(æ–½è‚¥|è‚¥æ–™|é…æ–¹æ–½è‚¥)[ï¼š:ï¼Œ]?\s*([\u4e00-\u9fffA-Za-z0-9]+)?\s*([\d,.]+)\s*(kg|å…¬æ–¤|æ–¤)', text)
            if m: fields['æ–½è‚¥'] = f"{(m.group(2) or '').strip()} {m.group(3)} {m.group(4)}".strip()
            # çŒæº‰
            m = re.search(r'(çŒæº‰|æµ‡æ°´)[ï¼š:ï¼Œ]?\s*([\d,.]+)\s*(mm|ç«‹æ–¹|m3|æ–¹)', text)
            if m: fields['çŒæº‰'] = f"{m.group(2)} {m.group(3)}"
            # ç”¨è¯
            m = re.search(r'(å†œè¯|ç”¨è¯|é˜²æ²»)[ï¼š:ï¼Œ]?\s*([\u4e00-\u9fffA-Za-z0-9]+)\s*([\d,.]+)\s*(ml|æ¯«å‡|L|å‡|kg|å…‹|g)', text)
            if m: fields['ç”¨è¯'] = f"{m.group(2)} {m.group(3)} {m.group(4)}"
            # å•äº§/äº§é‡
            m = re.search(r'(å•äº§|äº©äº§)[ï¼š:ï¼Œ]\s*([\d,.]+)\s*(æ–¤/äº©|å…¬æ–¤/äº©|kg/ha|t/ha)', text)
            if m: fields['å•äº§'] = f"{m.group(2)} {m.group(3)}"
            m = re.search(r'(æ€»äº§|äº§é‡)[ï¼š:ï¼Œ]\s*([\d,.]+)\s*(kg|å¨|t)', text)
            if m: fields['äº§é‡'] = f"{m.group(2)} {m.group(3)}"
        except Exception:
            pass
        return fields
    
    def init_default_categories(self):
        """åˆå§‹åŒ–é»˜è®¤è¡Œä¸šåˆ†ç±»"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for category, keywords in self.industry_keywords.items():
            cursor.execute('''
                INSERT OR IGNORE INTO industry_categories (category_name, keywords, description)
                VALUES (?, ?, ?)
            ''', (category, json.dumps(keywords, ensure_ascii=False), f"{category}ç›¸å…³æ–‡æ¡£"))
        
        conn.commit()
        conn.close()

    def _to_english_category(self, category: str) -> str:
        mapping = {
            "ç§æ¤ä¸š": "Planting",
            "ç•œç‰§ä¸š": "Livestock",
            "å†œèµ„ä¸åœŸå£¤": "Inputs-Soil",
            "å†œä¸šé‡‘è": "Agri-Finance",
            "ä¾›åº”é“¾ä¸ä»“å‚¨": "SupplyChain-Storage",
            "æ°”å€™ä¸é¥æ„Ÿ": "Climate-RemoteSensing",
            "å†œä¸šç‰©è”ç½‘": "Agri-IoT",
        }
        return mapping.get(category, category)
    
    def generate_smart_report(self, file_id: int) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Šå’Œå›¾è¡¨"""
        try:
            # è·å–æ–‡ä»¶ä¿¡æ¯
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            conn.close()
            
            if not result:
                return {"success": False, "error": "æ–‡ä»¶ä¸å­˜åœ¨"}
            
            file_path, file_type, filename = result
            
            # æå–æ–‡æœ¬å†…å®¹
            text = self.extract_text_from_file(file_id)
            if not text:
                return {"success": False, "error": "æ— æ³•æå–æ–‡æœ¬å†…å®¹"}
            
            # åˆ†ææ–‡æ¡£ç»“æ„
            analysis = self.analyze_document_structure(text)
            analysis["full_text"] = text
            
            # æå–æ•°æ®ç‚¹
            data_points = self.extract_data_points(text)
            
            # ç”Ÿæˆå›¾è¡¨
            charts = self.generate_charts(data_points)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.create_smart_report(analysis, charts, filename)
            
            return {
                "success": True,
                "analysis": analysis,
                "data_points": data_points,
                "charts": charts,
                "report": report
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def analyze_document_structure(self, text: str) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£ç»“æ„ï¼Œè¯†åˆ«å†œä¸šé¢†åŸŸæ–‡æ¡£ç±»å‹ä¸è¦ç´ """
        analysis = {
            "document_type": "æœªçŸ¥",
            "data_types": [],
            "key_metrics": [],
            "time_periods": [],
            "categories": [],
            "confidence": 0.0
        }
        
        # è¯†åˆ«å†œä¸šæ–‡æ¡£ç±»å‹
        if any(k in text for k in ["å•äº§", "äº©äº§", "t/ha", "kg/ha", "æ’­ç§é¢ç§¯", "æ”¶è·é¢ç§¯", "äº§é‡"]):
            analysis["document_type"] = "ç§æ¤ä¸šç”Ÿäº§æŠ¥å‘Š"
            analysis["data_types"].extend(["é¢ç§¯", "äº§é‡", "å•äº§", "è¶‹åŠ¿"])
        elif any(k in text for k in ["å‡ºæ ", "å­˜æ ", "å¢é‡", "æ—¥å¢é‡", "æ–™è‚‰æ¯”", "å…ç–«"]):
            analysis["document_type"] = "ç•œç‰§ä¸šç”Ÿäº§æŠ¥å‘Š"
            analysis["data_types"].extend(["å¤´æ•°", "é‡é‡", "è½¬æ¢ç‡", "å…ç–«"])
        elif any(k in text for k in ["é™é›¨", "é™æ°´", "mm", "ç§¯æ¸©", "å¹²æ—±", "NDVI", "é¥æ„Ÿ"]):
            analysis["document_type"] = "æ°”å€™ä¸é¥æ„Ÿç›‘æµ‹"
            analysis["data_types"].extend(["é™é›¨", "æ¸©åº¦", "æŒ‡æ•°", "æ—¶é—´åºåˆ—"])
        elif any(k in text for k in ["æˆæœ¬", "é‡‡è´­", "ä»·æ ¼", "ä¿é™©", "èµ”ä»˜", "åˆ©æ¶¦", "æ¯›åˆ©ç‡"]):
            analysis["document_type"] = "å†œä¸šè´¢åŠ¡/ä¾›åº”é“¾æŠ¥å‘Š"
            analysis["data_types"].extend(["é‡‘é¢", "æ¯”ç‡", "å¯¹æ¯”", "ä»·æ ¼è¶‹åŠ¿"])
        
        # æå–å…³é”®æŒ‡æ ‡
        import re
        # æŸ¥æ‰¾æ•°å­—æ¨¡å¼ï¼ˆæ”¯æŒå¸¦å•ä½ï¼‰
        numbers = re.findall(r'[\d,]+\.?\d*\s*(?:t/ha|kg/ha|kg|t|å¨|å…¬æ–¤|å…ƒ/æ–¤|å…ƒ/å¨|mm)?', text)
        analysis["key_metrics"] = numbers[:10]  # å–å‰10ä¸ªæ•°å­—
        
        # æŸ¥æ‰¾æ—¶é—´æ¨¡å¼
        time_patterns = re.findall(r'\d{4}å¹´|\d{1,2}æœˆ|\d{1,2}æ—¥|Q[1-4]', text)
        analysis["time_periods"] = list(set(time_patterns))
        
        # æŸ¥æ‰¾åˆ†ç±»ä¿¡æ¯
        category_patterns = re.findall(r'[A-Za-z\u4e00-\u9fff]+[ï¼š:]\s*[\d,]+', text)
        analysis["categories"] = category_patterns[:5]
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆå†œä¸šåœºæ™¯ç¨å¾®æé«˜å…³é”®æŒ‡æ ‡æƒé‡ï¼‰
        confidence = min(len(analysis["key_metrics"]) * 0.12 + 
                        len(analysis["time_periods"]) * 0.18 + 
                        len(analysis["categories"]) * 0.1, 1.0)
        analysis["confidence"] = confidence
        
        return analysis
    
    def extract_data_points(self, text: str) -> List[Dict[str, Any]]:
        """æå–æ•°æ®ç‚¹ç”¨äºç”Ÿæˆå›¾è¡¨ï¼ˆå¢å¼ºå†œä¸šå•ä½è¯†åˆ«ï¼‰"""
        data_points = []
        
        import re
        
        # æå–æ•°å€¼å’Œæ ‡ç­¾
        patterns = [
            r'([A-Za-z\u4e00-\u9fff]+)[ï¼š:]\s*([\d,]+\.?\d*)\s*(t/ha|kg/ha|kg|t|å¨|å…¬æ–¤|mm|%)?',
            r'([A-Za-z\u4e00-\u9fff]+)\s*([\d,]+\.?\d*)\s*(%)',
            r'([A-Za-z\u4e00-\u9fff]+)\s*ä¸º\s*([\d,]+\.?\d*)\s*(t/ha|kg/ha|kg|t|å¨|å…¬æ–¤|mm|%)?'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) == 3:
                    label, value, unit = match
                else:
                    label, value = match
                    unit = None
                try:
                    # æ¸…ç†æ•°å€¼
                    clean_value = float(value.replace(',', ''))
                    if clean_value > 0:  # åªä¿ç•™æ­£æ•°
                        data_points.append({
                            "label": label.strip(),
                            "value": clean_value,
                            "type": unit or "æ•°å€¼"
                        })
                except ValueError:
                    continue
        
        # å»é‡å¹¶æ’åº
        seen = set()
        unique_points = []
        for point in data_points:
            key = point["label"]
            if key not in seen:
                seen.add(key)
                unique_points.append(point)
        
        # æŒ‰æ•°å€¼æ’åº
        unique_points.sort(key=lambda x: x["value"], reverse=True)
        
        return unique_points[:10]  # è¿”å›å‰10ä¸ªæ•°æ®ç‚¹
    
    def generate_charts(self, data_points: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå›¾è¡¨æ•°æ®"""
        charts = []
        
        if not data_points:
            return charts
        
        # ç”ŸæˆæŸ±çŠ¶å›¾æ•°æ®
        if len(data_points) >= 2:
            bar_chart = {
                "type": "bar",
                "title": "æ•°æ®å¯¹æ¯”æŸ±çŠ¶å›¾",
                "data": {
                    "labels": [point["label"] for point in data_points[:8]],
                    "values": [point["value"] for point in data_points[:8]]
                }
            }
            charts.append(bar_chart)
        
        # ç”Ÿæˆé¥¼å›¾æ•°æ®ï¼ˆå‰5ä¸ªï¼‰
        if len(data_points) >= 3:
            pie_data = data_points[:5]
            total = sum(point["value"] for point in pie_data)
            pie_chart = {
                "type": "pie",
                "title": "æ•°æ®åˆ†å¸ƒé¥¼å›¾",
                "data": {
                    "labels": [point["label"] for point in pie_data],
                    "values": [point["value"] for point in pie_data],
                    "percentages": [round(point["value"]/total*100, 1) for point in pie_data]
                }
            }
            charts.append(pie_chart)
        
        # ç”Ÿæˆè¶‹åŠ¿å›¾ï¼ˆå¦‚æœæœ‰æ—¶é—´æ•°æ®ï¼‰
        if len(data_points) >= 4:
            line_chart = {
                "type": "line",
                "title": "æ•°æ®è¶‹åŠ¿å›¾",
                "data": {
                    "labels": [point["label"] for point in data_points[:6]],
                    "values": [point["value"] for point in data_points[:6]]
                }
            }
            charts.append(line_chart)
        
        return charts
    
    def create_smart_report(self, analysis: Dict, charts: List[Dict], filename: str) -> str:
        """ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Šï¼ˆåŠ å…¥å†œä¸šæ´å¯Ÿä¸KPIï¼‰"""
        report = f"# ğŸ“Š Agribusiness Smart Analysis Report\n\n"
        report += f"**File name**: {filename}\n\n"
        report += f"**Document type**: {analysis['document_type']}\n\n"
        report += f"**Confidence**: {analysis['confidence']:.1%}\n\n"
        
        # å†œä¸šKPIï¼ˆä»å…¨æ–‡æ™ºèƒ½æå–ï¼‰
        agrikpis = self.compute_agribusiness_kpis(analysis.get('full_text', '')) if isinstance(analysis, dict) else {}
        if agrikpis:
            report += "## ğŸŒ¾ Agribusiness KPIs\n\n"
            for k, v in agrikpis.items():
                report += f"- {k}: {v}\n"
            report += "\n"

        # å¤©æ°”æ‘˜è¦ï¼ˆå¦‚æœå·²è·å–ï¼‰
        if getattr(self, 'latest_weather', None):
            ws = self.latest_weather.get('summary', {})
            report += "## â˜ï¸ Climate summary (next 7 days)\n\n"
            if ws:
                if ws.get('7d_total_rain_mm') is not None:
                    report += f"- Total rainfall: {ws['7d_total_rain_mm']} mm\n"
                if ws.get('avg_tmax') is not None:
                    report += f"- Avg Tmax: {ws['avg_tmax']} Â°C\n"
                if ws.get('avg_tmin') is not None:
                    report += f"- Avg Tmin: {ws['avg_tmin']} Â°C\n"
            report += "\n"

        # é¥æ„Ÿæ‘˜è¦ï¼ˆå¦‚æœå·²è·å–ï¼‰
        if getattr(self, 'latest_remote_sensing', None):
            rs = self.latest_remote_sensing.get('summary', {})
            report += "## ğŸ›°ï¸ Remote sensing summary\n\n"
            if rs:
                if rs.get('ndvi_avg') is not None:
                    report += f"- NDVI average: {rs['ndvi_avg']}\n"
                if rs.get('evi_avg') is not None:
                    report += f"- EVI average: {rs['evi_avg']}\n"
                if rs.get('ndvi_last') is not None:
                    report += f"- Latest NDVI: {rs['ndvi_last']}\n"
                if rs.get('evi_last') is not None:
                    report += f"- Latest EVI: {rs['evi_last']}\n"
            report += "\n"

        # æ¨¡æ¿æŠ½å–ç»“æœ
        structured = self.extract_agri_structured_fields(analysis.get('full_text', '')) if isinstance(analysis, dict) else {}
        if structured:
            report += "## ğŸ—‚ï¸ Structured fields (template extraction)\n\n"
            for k, v in structured.items():
                report += f"- {k}: {v}\n"
            report += "\n"
        
        # Key metrics
        if analysis['key_metrics']:
            report += "## ğŸ”¢ Key metrics\n\n"
            for i, metric in enumerate(analysis['key_metrics'][:5], 1):
                report += f"{i}. {metric}\n"
            report += "\n"

        # Time periods
        if analysis['time_periods']:
            report += "## ğŸ“… Time periods\n\n"
            report += f"Detected time info: {', '.join(analysis['time_periods'])}\n\n"

        # Categories
        if analysis['categories']:
            report += "## ğŸ“‹ Categories\n\n"
            for category in analysis['categories']:
                report += f"- {category}\n"
            report += "\n"

        # Visualization notes
        if charts:
            report += "## ğŸ“ˆ Data visualization\n\n"
            for chart in charts:
                report += f"### {chart['title']}\n\n"
                if chart['type'] == 'bar':
                    report += "Bar chart shows value comparison across categories to spot highs and lows.\n\n"
                elif chart['type'] == 'pie':
                    report += "Pie chart shows proportion distribution for intuitive share comparison.\n\n"
                elif chart['type'] == 'line':
                    report += "Line chart shows temporal trends to identify growth or decline patterns.\n\n"

        # Suggestions
        report += "## ğŸ’¡ Suggestions\n\n"
        if analysis['document_type'] in ["ç§æ¤ä¸šç”Ÿäº§æŠ¥å‘Š", "ç•œç‰§ä¸šç”Ÿäº§æŠ¥å‘Š"]:
            report += "- Track trends of key KPIs (yield, rainfall, FCR).\n"
            report += "- Compare fields/lots or herds to find outliers.\n"
            report += "- Plan interventions (fertigation, pest control) based on thresholds.\n"
        elif analysis['document_type'] in ["å†œä¸šè´¢åŠ¡/ä¾›åº”é“¾æŠ¥å‘Š"]:
            report += "- Monitor margins and price trends.\n"
            report += "- Optimize cost structure and inventory turnover.\n"
            report += "- Manage risk with insurance/hedging where applicable.\n"
        else:
            report += "- Keep data updated regularly.\n"
            report += "- Focus on KPI trends and anomalies.\n"
            report += "- Apply data-driven decisions.\n"
        
        return report

    def compute_agribusiness_kpis(self, text: str) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™å¿«é€Ÿæå–å†œä¸šå¸¸è§KPIï¼ˆè½»é‡å ä½ï¼Œå¯åç»­æ¢æ¨¡å‹ï¼‰"""
        if not text:
            return {}
        import re
        kpis: Dict[str, Any] = {}
        try:
            # å•äº§ï¼ˆæ”¯æŒ kg/ha, t/ha, äº©äº§ï¼‰
            m = re.search(r'(å•äº§|äº©äº§)[:ï¼š]?\s*([\d,.]+)\s*(kg/ha|t/ha|å…¬æ–¤/äº©|æ–¤/äº©|å¨/å…¬é¡·)?', text)
            if m:
                kpis['å•äº§'] = f"{m.group(2)} {m.group(3) or ''}".strip()

            # é¢ç§¯ï¼ˆäº©ã€å…¬é¡·ï¼‰
            m = re.search(r'(æ’­ç§é¢ç§¯|æ”¶è·é¢ç§¯|é¢ç§¯)[:ï¼š]?\s*([\d,.]+)\s*(äº©|å…¬é¡·|ha)', text)
            if m:
                kpis['é¢ç§¯'] = f"{m.group(2)} {m.group(3)}"

            # é™é›¨é‡ï¼ˆmmï¼‰
            m = re.search(r'(é™é›¨|é™æ°´|ç´¯è®¡é™é›¨|ç´¯è®¡é™æ°´)[:ï¼š]?\s*([\d,.]+)\s*mm', text)
            if m:
                kpis['ç´¯è®¡é™é›¨'] = f"{m.group(2)} mm"

            # æˆæœ¬ä¸åˆ©æ¶¦
            m = re.search(r'(æ€»æˆæœ¬|æˆæœ¬)[:ï¼š]?\s*([\d,.]+)', text)
            if m:
                kpis['æˆæœ¬'] = m.group(2)
            m = re.search(r'(åˆ©æ¶¦|æ¯›åˆ©|æ¯›åˆ©ç‡)[:ï¼š]?\s*([\d,.]+)\s*(%)?', text)
            if m:
                kpis['åˆ©æ¶¦/æ¯›åˆ©'] = f"{m.group(2)}{m.group(3) or ''}"

            # ç•œç‰§å…³é”®æŒ‡æ ‡
            m = re.search(r'(å‡ºæ |å­˜æ )[:ï¼š]?\s*([\d,.]+)\s*(å¤´|åª)?', text)
            if m:
                kpis[m.group(1)] = f"{m.group(2)} {m.group(3) or ''}".strip()
            m = re.search(r'(æ–™è‚‰æ¯”|FCR)[:ï¼š]?\s*([\d,.]+)', text)
            if m:
                kpis['æ–™è‚‰æ¯”'] = m.group(2)

            # é¥æ„ŸæŒ‡æ•°
            m = re.search(r'(NDVI|EVI)[:ï¼š]?\s*([\d,.]+)', text)
            if m:
                kpis[m.group(1)] = m.group(2)
        except Exception:
            pass
        return kpis
    
    def calculate_checksum(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def get_file_type(self, filename: str) -> str:
        """è·å–æ–‡ä»¶ç±»å‹"""
        mime_type, _ = mimetypes.guess_type(filename)
        if mime_type:
            return mime_type.split('/')[0]
        return 'unknown'
    
    def upload_file(self, uploaded_file, folder_id: Optional[int] = None) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡ä»¶"""
        try:
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            timestamp = int(time.time())
            filename = f"{timestamp}_{uploaded_file.name}"
            file_path = self.storage_dir / filename
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # è®¡ç®—æ–‡ä»¶ä¿¡æ¯
            file_size = file_path.stat().st_size
            checksum = self.calculate_checksum(str(file_path))
            file_type = self.get_file_type(uploaded_file.name)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO files (filename, file_path, file_size, file_type, folder_id, checksum)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (uploaded_file.name, str(file_path), file_size, file_type, folder_id, checksum))
            conn.commit()
            conn.close()
            
            return {
                "success": True,
                "filename": uploaded_file.name,
                "file_size": file_size,
                "file_type": file_type
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_files(self, folder_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """è·å–æ–‡ä»¶åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if folder_id is None:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files WHERE folder_id IS NULL
                ORDER BY upload_time DESC
            ''')
        else:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files WHERE folder_id = ?
                ORDER BY upload_time DESC
            ''', (folder_id,))
        
        files = []
        for row in cursor.fetchall():
            files.append({
                "id": row[0],
                "filename": row[1],
                "file_size": row[2],
                "file_type": row[3],
                "upload_time": row[4],
                "is_cached": bool(row[5])
            })
        
        conn.close()
        return files
    
    def create_folder(self, folder_name: str, parent_folder_id: Optional[int] = None) -> Dict[str, Any]:
        """åˆ›å»ºæ–‡ä»¶å¤¹"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO folders (folder_name, parent_folder_id)
                VALUES (?, ?)
            ''', (folder_name, parent_folder_id))
            conn.commit()
            folder_id = cursor.lastrowid
            conn.close()
            
            return {"success": True, "folder_id": folder_id}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def search_files(self, query: str, file_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """æœç´¢æ–‡ä»¶"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if file_type:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files 
                WHERE filename LIKE ? AND file_type = ?
                ORDER BY upload_time DESC
            ''', (f"%{query}%", file_type))
        else:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files 
                WHERE filename LIKE ?
                ORDER BY upload_time DESC
            ''', (f"%{query}%",))
        
        files = []
        for row in cursor.fetchall():
            files.append({
                "id": row[0],
                "filename": row[1],
                "file_size": row[2],
                "file_type": row[3],
                "upload_time": row[4],
                "is_cached": bool(row[5])
            })
        
        conn.close()
        return files
    
    def preview_file(self, file_id: int) -> Optional[bytes]:
        """é¢„è§ˆæ–‡ä»¶"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT file_path, file_type FROM files WHERE id = ?', (file_id,))
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return None
        
        file_path, file_type = result
        
        try:
            with open(file_path, 'rb') as f:
                return f.read()
        except:
            return None
    
    def cache_file(self, file_id: int) -> bool:
        """ç¼“å­˜æ–‡ä»¶åˆ°æœ¬åœ°"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            
            if result:
                file_path, filename = result
                cache_path = self.cache_dir / filename
                shutil.copy2(file_path, cache_path)
                
                # æ›´æ–°æ•°æ®åº“
                cursor.execute('UPDATE files SET is_cached = TRUE WHERE id = ?', (file_id,))
                conn.commit()
                conn.close()
                return True
        except:
            pass
        return False
    
    def format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1
        return f"{size_bytes:.1f}{size_names[i]}"
    
    def get_file_icon(self, file_type: str) -> str:
        """è·å–æ–‡ä»¶ç±»å‹å›¾æ ‡"""
        icons = {
            'image': 'ğŸ–¼ï¸',
            'application': 'ğŸ“„',
            'text': 'ğŸ“',
            'video': 'ğŸ¥',
            'audio': 'ğŸµ',
            'unknown': 'ğŸ“'
        }
        return icons.get(file_type, 'ğŸ“')
    
    def upload_file_with_resume(self, uploaded_file, folder_id: Optional[int] = None, chunk_size: int = 1024*1024) -> Dict[str, Any]:
        """å¸¦æ–­ç‚¹ç»­ä¼ çš„æ–‡ä»¶ä¸Šä¼ """
        try:
            filename = uploaded_file.name
            file_size = len(uploaded_file.getbuffer())
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸Šä¼ 
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                SELECT id, uploaded_size, checksum FROM upload_progress 
                WHERE filename = ? AND total_size = ?
                ORDER BY upload_time DESC LIMIT 1
            ''', (filename, file_size))
            
            progress_record = cursor.fetchone()
            
            if progress_record:
                # æ–­ç‚¹ç»­ä¼ 
                progress_id, uploaded_size, stored_checksum = progress_record
                st.info(f"ğŸ”„ Resumable upload found, continue from {uploaded_size} bytes...")
            else:
                # æ–°ä¸Šä¼ 
                uploaded_size = 0
                progress_id = None
                stored_checksum = None
            
            # åˆ†å—ä¸Šä¼ 
            uploaded_file.seek(uploaded_size)
            current_size = uploaded_size
            
            progress_bar = st.progress(uploaded_size / file_size)
            status_text = st.empty()
            
            while current_size < file_size:
                chunk = uploaded_file.read(min(chunk_size, file_size - current_size))
                if not chunk:
                    break
                
                # è¿™é‡Œåº”è¯¥å°†chunkå‘é€åˆ°æœåŠ¡å™¨
                # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥å†™å…¥æœ¬åœ°æ–‡ä»¶
                temp_file_path = self.storage_dir / f"temp_{filename}"
                with open(temp_file_path, "ab") as f:
                    f.write(chunk)
                
                current_size += len(chunk)
                progress = current_size / file_size
                progress_bar.progress(progress)
                status_text.text(f"Uploading: {current_size}/{file_size} bytes ({progress*100:.1f}%)")
                
                # æ›´æ–°è¿›åº¦åˆ°æ•°æ®åº“
                if progress_id:
                    cursor.execute('''
                        UPDATE upload_progress 
                        SET uploaded_size = ? 
                        WHERE id = ?
                    ''', (current_size, progress_id))
                else:
                    cursor.execute('''
                        INSERT INTO upload_progress (filename, total_size, uploaded_size, chunk_size, checksum)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (filename, file_size, current_size, chunk_size, stored_checksum))
                    progress_id = cursor.lastrowid
                
                conn.commit()
                
                # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
                time.sleep(0.1)
            
            # ä¸Šä¼ å®Œæˆï¼Œç§»åŠ¨æ–‡ä»¶åˆ°æœ€ç»ˆä½ç½®
            final_file_path = self.storage_dir / f"{int(time.time())}_{filename}"
            shutil.move(str(temp_file_path), str(final_file_path))
            
            # è®¡ç®—æ ¡éªŒå’Œ
            checksum = self.calculate_checksum(str(final_file_path))
            file_type = self.get_file_type(filename)
            
            # ä¿å­˜æ–‡ä»¶ä¿¡æ¯åˆ°æ•°æ®åº“
            cursor.execute('''
                INSERT INTO files (filename, file_path, file_size, file_type, folder_id, checksum)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (filename, str(final_file_path), file_size, file_type, folder_id, checksum))
            
            # åˆ é™¤è¿›åº¦è®°å½•
            if progress_id:
                cursor.execute('DELETE FROM upload_progress WHERE id = ?', (progress_id,))
            
            conn.commit()
            conn.close()
            
            progress_bar.empty()
            status_text.empty()
            
            return {
                "success": True,
                "filename": filename,
                "file_size": file_size,
                "file_type": file_type,
                "checksum": checksum
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_upload_progress(self) -> List[Dict[str, Any]]:
        """è·å–ä¸Šä¼ è¿›åº¦åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT filename, total_size, uploaded_size, upload_time
            FROM upload_progress
            ORDER BY upload_time DESC
        ''')
        
        progress_list = []
        for row in cursor.fetchall():
            filename, total_size, uploaded_size, upload_time = row
            progress_list.append({
                "filename": filename,
                "total_size": total_size,
                "uploaded_size": uploaded_size,
                "progress": uploaded_size / total_size if total_size > 0 else 0,
                "upload_time": upload_time
            })
        
        conn.close()
        return progress_list
    
    def resume_upload(self, filename: str) -> Dict[str, Any]:
        """æ¢å¤ä¸Šä¼ """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, total_size, uploaded_size, chunk_size, checksum
            FROM upload_progress 
            WHERE filename = ?
            ORDER BY upload_time DESC LIMIT 1
        ''', (filename,))
        
        result = cursor.fetchone()
        if result:
            progress_id, total_size, uploaded_size, chunk_size, checksum = result
            return {
                "success": True,
                "progress_id": progress_id,
                "total_size": total_size,
                "uploaded_size": uploaded_size,
                "chunk_size": chunk_size,
                "checksum": checksum
            }
        else:
            return {"success": False, "error": "æœªæ‰¾åˆ°ä¸Šä¼ è¿›åº¦è®°å½•"}
    
    def cancel_upload(self, filename: str) -> bool:
        """å–æ¶ˆä¸Šä¼ """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('DELETE FROM upload_progress WHERE filename = ?', (filename,))
            conn.commit()
            conn.close()
            return True
        except:
            return False
    
    # ==================== AIåŠŸèƒ½æ–¹æ³• ====================
    
    def extract_text_from_file(self, file_id: int) -> str:
        """ä»æ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return ""
        
        file_path, file_type, filename = result
        extracted_text = ""
        
        try:
            if file_type == 'text' or filename.endswith('.txt'):
                # æ–‡æœ¬æ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    extracted_text = f.read()
            
            elif file_type == 'application' and filename.endswith('.pdf'):
                # PDFæ–‡ä»¶
                if PDF_AVAILABLE:
                    doc = fitz.open(file_path)
                    for page in doc:
                        extracted_text += page.get_text()
                    doc.close()
                # è‹¥ä¸å¯ç”¨åˆ™ä¿æŒä¸ºç©ºï¼Œåç»­ç»™å‡ºå‹å¥½å ä½
            
            elif file_type == 'application' and filename.endswith(('.xlsx', '.xls')):
                # Excelæ–‡ä»¶
                try:
                    df = pd.read_excel(file_path)
                    # ç¡®ä¿DataFrameä¸ä¸ºç©º
                    if not df.empty:
                        # å®‰å…¨åœ°è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…numpy.str_é”™è¯¯
                        try:
                            extracted_text = df.to_string()
                        except Exception as str_error:
                            # å¦‚æœto_stringå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                            extracted_text = str(df.values.tolist())
                    else:
                        extracted_text = "Excel file is empty"
                except Exception as e:
                    st.warning(f"Excel reading failed: {str(e)}")
                    extracted_text = ""

            elif filename.endswith('.csv'):
                # CSVæ–‡ä»¶
                try:
                    df = pd.read_csv(file_path)
                    if not df.empty:
                        try:
                            extracted_text = df.to_string()
                        except Exception:
                            extracted_text = str(df.values.tolist())
                    else:
                        extracted_text = "CSV file is empty"
                except Exception as e:
                    st.warning(f"CSV reading failed: {str(e)}")
                    extracted_text = ""

            elif filename.endswith('.docx'):
                # DOCXï¼ˆå¯é€‰å¤„ç†ï¼‰
                try:
                    import docx  # type: ignore
                    doc = docx.Document(file_path)
                    paras = [p.text for p in doc.paragraphs if p.text]
                    extracted_text = "\n".join(paras)
                except Exception:
                    # æœªå®‰è£…æˆ–è§£æå¤±è´¥åˆ™å¿½ç•¥
                    pass
            
            elif file_type == 'image':
                # å›¾ç‰‡æ–‡ä»¶ - OCRè¯†åˆ«
                if OCR_AVAILABLE:
                    if self.ocr_reader is None:
                        # å»¶è¿ŸåŠ è½½OCRæ¨¡å‹
                        st.info("ğŸ”„ Loading OCR model, please wait...")
                        try:
                            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])
                            st.success("âœ… OCR model loaded")
                        except Exception as e:
                            st.error(f"OCR model load failed: {str(e)}")
                            return ""
                    
                    if self.ocr_reader:
                        results = self.ocr_reader.readtext(file_path)
                        extracted_text = ' '.join([result[1] for result in results])
        
        except Exception as e:
            st.error(f"Text extraction failed: {str(e)}")
        
        # å…œåº•ï¼šä»æ— æ³•æå–æ–‡æœ¬æ—¶ï¼Œè¿”å›å ä½æ–‡æœ¬ï¼Œé¿å…AIæµç¨‹ç›´æ¥å¤±è´¥
        if not extracted_text:
            extracted_text = f"(No extractable text from file: {filename}. Try preview/download.)"
        
        return extracted_text
    
    def classify_industry(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨çœŸæ­£çš„AIå¯¹æ–‡æ¡£è¿›è¡Œè¡Œä¸šåˆ†ç±»"""
        if not text:
            return {"category": "æœªåˆ†ç±»", "confidence": 0.0, "keywords": []}
        
        # æ–¹æ³•1: ä½¿ç”¨BERTæ¨¡å‹åˆ†ç±»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.text_classifier and len(text) > 10:
            try:
                # æˆªå–æ–‡æœ¬å‰512ä¸ªå­—ç¬¦ï¼ˆBERTé™åˆ¶ï¼‰
                text_sample = text[:512]
                result = self.text_classifier(text_sample)
                
                # å°†BERTç»“æœæ˜ å°„åˆ°æˆ‘ä»¬çš„è¡Œä¸šåˆ†ç±»
                bert_label = result[0]['label']
                bert_confidence = result[0]['score']
                
                # ç®€å•çš„æ ‡ç­¾æ˜ å°„ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
                label_mapping = {
                    'LABEL_0': 'ç§æ¤ä¸š',
                    'LABEL_1': 'ç•œç‰§ä¸š',
                    'LABEL_2': 'å†œèµ„ä¸åœŸå£¤',
                    'LABEL_3': 'å†œä¸šé‡‘è',
                    'LABEL_4': 'ä¾›åº”é“¾ä¸ä»“å‚¨',
                    'LABEL_5': 'æ°”å€™ä¸é¥æ„Ÿ',
                    'LABEL_6': 'å†œä¸šç‰©è”ç½‘'
                }
                
                mapped_category = label_mapping.get(bert_label, 'æœªåˆ†ç±»')
                
                if mapped_category != 'æœªåˆ†ç±»':
                    return {
                        "category": mapped_category,
                        "confidence": bert_confidence,
                        "keywords": self._extract_keywords_from_text(text),
                        "method": "BERT"
                    }
            except Exception as e:
                st.warning(f"BERTåˆ†ç±»å¤±è´¥: {str(e)}")
        
        # æ–¹æ³•2: ä½¿ç”¨æœºå™¨å­¦ä¹ åˆ†ç±»å™¨ï¼ˆå¦‚æœå¯ç”¨ä¸”å·²è®­ç»ƒï¼‰
        if self.ml_classifier and self.ml_trained and len(text) > 20:
            try:
                X = [text]
                y_pred = self.ml_classifier.predict(X)
                y_proba = self.ml_classifier.predict_proba(X)
                
                categories = list(self.industry_keywords.keys())
                predicted_category = categories[y_pred[0]]
                confidence = y_proba[0].max()
                
                return {
                    "category": predicted_category,
                    "confidence": confidence,
                    "keywords": self._extract_keywords_from_text(text),
                    "method": "ML"
                }
            except Exception as e:
                st.warning(f"æœºå™¨å­¦ä¹ åˆ†ç±»å¤±è´¥: {str(e)}")
        
        # æ–¹æ³•3: æ™ºèƒ½å…³é”®è¯åŒ¹é…ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        words = jieba.lcut(text)
        category_scores = {}
        matched_keywords = {}
        
        for category, keywords in self.industry_keywords.items():
            score = 0
            matched = []
            
            # åŸºç¡€å…³é”®è¯åŒ¹é…
            for keyword in keywords:
                if keyword in text:
                    score += 1
                    matched.append(keyword)
            
            # åŒä¹‰è¯å’Œç›¸ä¼¼è¯åŒ¹é…
            synonyms = self._get_synonyms(category)
            for synonym in synonyms:
                if synonym in text:
                    score += 0.5
                    matched.append(synonym)
            
            # è¯é¢‘æƒé‡
            for keyword in keywords:
                count = text.count(keyword)
                if count > 1:
                    score += count * 0.2
            
            category_scores[category] = score
            matched_keywords[category] = matched
        
        if category_scores and max(category_scores.values()) > 0:
            best_category = max(category_scores, key=category_scores.get)
            max_score = category_scores[best_category]
            
            # æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—
            total_keywords = len(self.industry_keywords[best_category])
            confidence = min(max_score / (total_keywords * 1.5), 1.0)
            
            # å¦‚æœç½®ä¿¡åº¦å¤ªä½ï¼Œæ ‡è®°ä¸ºæœªåˆ†ç±»
            if confidence < 0.1:
                return {"category": "æœªåˆ†ç±»", "confidence": 0.0, "keywords": [], "method": "å…³é”®è¯åŒ¹é…"}
            
            return {
                "category": best_category,
                "confidence": confidence,
                "keywords": matched_keywords[best_category],
                "method": "æ™ºèƒ½å…³é”®è¯åŒ¹é…"
            }
        
        return {"category": "æœªåˆ†ç±»", "confidence": 0.0, "keywords": [], "method": "æ— åŒ¹é…"}
    
    def _get_synonyms(self, category: str) -> List[str]:
        """è·å–è¡Œä¸šåˆ†ç±»çš„åŒä¹‰è¯"""
        synonyms_map = {
            "ç§æ¤ä¸š": ["ç§æ¤", "è€•ä½œ", "è‚²ç§§", "ç§»æ ½", "å¯†æ¤", "ç—…è™«å®³", "æ–½è‚¥", "çŒæº‰", "ç”°é—´ç®¡ç†", "ç‰ç±³", "é«˜ç²±", "å°ç±³", "æœ¨è–¯", "èŠ±ç”Ÿ", "èŠéº»", "æ£‰èŠ±", "å¯å¯", "å’–å•¡"],
            "ç•œç‰§ä¸š": ["å…»æ®–", "é¥²å–‚", "å…ç–«", "é˜²ç–«", "ç¹è‚²", "æ–­å¥¶", "å‡ºæ ", "å­˜æ ", "å¢é‡"],
            "å†œèµ„ä¸åœŸå£¤": ["é…æ–¹æ–½è‚¥", "åœŸå£¤æ”¹è‰¯", "æ–½ç”¨é‡", "æœ‰æœºè‚¥", "å¾®é‡å…ƒç´ ", "åœŸå£¤å…»åˆ†"],
            "å†œä¸šé‡‘è": ["è´´ç°", "æˆä¿¡", "ä¿è´¹", "èµ”ä»˜", "æ‰¿ä¿", "é£æ§", "ä¿å•"],
            "ä¾›åº”é“¾ä¸ä»“å‚¨": ["å†·é“¾è¿è¾“", "æŸè€—ç‡", "æ‰¹æ¬¡è¿½æº¯", "åº“å®¹", "å‘¨è½¬ç‡", "åˆ†æ‹£"],
            "æ°”å€™ä¸é¥æ„Ÿ": ["é™é›¨", "æ°”æ¸©", "ç§¯æ¸©", "å¹²æ—±æŒ‡æ•°", "NDVI", "EVI", "é¥æ„Ÿ", "æ²™æ¼ è—è™«", "è‰åœ°è´ªå¤œè›¾"],
            "å†œä¸šç‰©è”ç½‘": ["å«æ°´ç‡", "EC", "æ»´çŒ", "å–·çŒ", "é˜€é—¨", "é˜ˆå€¼", "æŠ¥è­¦"]
        }
        return synonyms_map.get(category, [])
    
    def init_pretrained_classifier(self):
        """åˆå§‹åŒ–é¢„è®­ç»ƒçš„åˆ†ç±»å™¨"""
        if not self.ml_classifier:
            return False
        
        try:
            # ä½¿ç”¨é¢„å®šä¹‰çš„å…³é”®è¯ä½œä¸ºç‰¹å¾è¿›è¡Œè®­ç»ƒ
            X_train = []
            y_train = []
            
            # ä¸ºæ¯ä¸ªè¡Œä¸šç±»åˆ«åˆ›å»ºè®­ç»ƒæ ·æœ¬
            for category, keywords in self.industry_keywords.items():
                # ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºè®­ç»ƒæ ·æœ¬
                for keyword in keywords:
                    # åˆ›å»ºåŒ…å«å…³é”®è¯çš„æ ·æœ¬æ–‡æœ¬
                    sample_text = f"è¿™æ˜¯ä¸€ä¸ªå…³äº{keyword}çš„æ–‡æ¡£ï¼Œæ¶‰åŠ{category}é¢†åŸŸçš„å†…å®¹ã€‚"
                    X_train.append(sample_text)
                    y_train.append(category)
                
                # æ·»åŠ åŒä¹‰è¯æ ·æœ¬
                synonyms = self._get_synonyms(category)
                for synonym in synonyms:
                    sample_text = f"è¿™æ˜¯ä¸€ä¸ªå…³äº{synonym}çš„æ–‡æ¡£ï¼Œæ¶‰åŠ{category}é¢†åŸŸçš„å†…å®¹ã€‚"
                    X_train.append(sample_text)
                    y_train.append(category)
            
            # è®­ç»ƒåˆ†ç±»å™¨
            if len(X_train) > 0:
                self.ml_classifier.fit(X_train, y_train)
                self.ml_trained = True
                return True
            else:
                return False
                
        except Exception as e:
            st.error(f"åˆå§‹åŒ–é¢„è®­ç»ƒåˆ†ç±»å™¨å¤±è´¥: {str(e)}")
            return False
    
    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
        try:
            # ä½¿ç”¨jiebaçš„TF-IDFæå–å…³é”®è¯
            keywords = jieba.analyse.extract_tags(text, topK=10, withWeight=False)
            return keywords
        except:
            # ç®€å•çš„å…³é”®è¯æå–
            words = jieba.lcut(text)
            word_count = Counter(words)
            stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
            filtered_words = {word: count for word, count in word_count.items() 
                            if len(word) > 1 and word not in stop_words and count > 1}
            return list(dict(sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:10]).keys())
    
    def extract_key_phrases(self, text: str, top_k: int = 10) -> List[str]:
        """æå–å…³é”®çŸ­è¯­"""
        if not text:
            return []
        
        try:
            # ä½¿ç”¨jiebaçš„TF-IDFæå–å…³é”®è¯
            keywords = jieba.analyse.extract_tags(text, topK=top_k, withWeight=False)
            return keywords
        except:
            # ç®€å•çš„å…³é”®è¯æå–
            words = jieba.lcut(text)
            word_count = Counter(words)
            # è¿‡æ»¤æ‰å•å­—ç¬¦å’Œå¸¸è§åœç”¨è¯
            stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
            filtered_words = {word: count for word, count in word_count.items() 
                            if len(word) > 1 and word not in stop_words and count > 1}
            return list(dict(sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:top_k]).keys())
    
    def generate_summary(self, text: str, max_length: int = 200) -> str:
        """ä½¿ç”¨çœŸæ­£çš„AIç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
        if not text:
            return "æ— æ³•ç”Ÿæˆæ‘˜è¦"
        
        # æ–¹æ³•1: ä½¿ç”¨T5æ¨¡å‹ç”Ÿæˆæ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.summarizer and len(text) > 50:
            try:
                # æˆªå–æ–‡æœ¬å‰1024ä¸ªå­—ç¬¦ï¼ˆT5é™åˆ¶ï¼‰
                text_sample = text[:1024]
                summary_result = self.summarizer(
                    text_sample,
                    max_length=min(max_length, 150),
                    min_length=30,
                    do_sample=False
                )
                
                if summary_result and len(summary_result) > 0:
                    ai_summary = summary_result[0]['summary_text']
                    return f"ğŸ¤– AIæ‘˜è¦: {ai_summary}"
            except Exception as e:
                st.warning(f"T5æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # æ–¹æ³•2: ä½¿ç”¨OpenAI GPTï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if OPENAI_AVAILABLE and len(text) > 100:
            try:
                # è¿™é‡Œéœ€è¦OpenAI APIå¯†é’¥
                # æš‚æ—¶è·³è¿‡ï¼Œå› ä¸ºéœ€è¦APIå¯†é’¥
                pass
            except Exception as e:
                st.warning(f"OpenAIæ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # æ–¹æ³•3: æ™ºèƒ½å¥å­é€‰æ‹©ï¼ˆæ”¹è¿›çš„è§„åˆ™æ–¹æ³•ï¼‰
        try:
            # ä½¿ç”¨æ›´æ™ºèƒ½çš„å¥å­é€‰æ‹©
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
            sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]
            
            if len(sentences) <= 2:
                return text[:max_length] + "..." if len(text) > max_length else text
            
            # é€‰æ‹©æœ€é‡è¦çš„å¥å­ï¼ˆåŸºäºé•¿åº¦å’Œå…³é”®è¯ï¼‰
            scored_sentences = []
            for i, sentence in enumerate(sentences):
                score = len(sentence)  # åŸºç¡€åˆ†æ•°ï¼šå¥å­é•¿åº¦
                
                # å…³é”®è¯åŠ åˆ†
                important_words = ['é‡è¦', 'å…³é”®', 'ä¸»è¦', 'æ ¸å¿ƒ', 'æ€»ç»“', 'ç»“è®º', 'ç»“æœ', 'å‘ç°']
                for word in important_words:
                    if word in sentence:
                        score += 20
                
                # ä½ç½®åŠ åˆ†ï¼ˆå¼€å¤´å’Œç»“å°¾çš„å¥å­æ›´é‡è¦ï¼‰
                if i < 2 or i >= len(sentences) - 2:
                    score += 10
                
                scored_sentences.append((score, sentence))
            
            # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„2-3ä¸ªå¥å­
            scored_sentences.sort(reverse=True)
            selected_sentences = [s[1] for s in scored_sentences[:3]]
            
            summary = 'ã€‚'.join(selected_sentences)
            if len(summary) > max_length:
                summary = summary[:max_length] + "..."
            
            return f"ğŸ“ æ™ºèƒ½æ‘˜è¦: {summary}"
        except:
            # æ–¹æ³•4: ç®€å•æˆªå–ï¼ˆæœ€åå¤‡ç”¨ï¼‰
            return text[:max_length] + "..." if len(text) > max_length else text
    
    def analyze_file_with_ai(self, file_id: int) -> Dict[str, Any]:
        """ä½¿ç”¨AIåˆ†ææ–‡ä»¶"""
        # æå–æ–‡æœ¬
        extracted_text = self.extract_text_from_file(file_id)
        
        if not extracted_text:
            return {"success": False, "error": "æ— æ³•æå–æ–‡æœ¬å†…å®¹"}
        
        # è¡Œä¸šåˆ†ç±»
        classification = self.classify_industry(extracted_text)
        
        # æå–å…³é”®çŸ­è¯­
        key_phrases = self.extract_key_phrases(extracted_text)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self.generate_summary(extracted_text)
        
        # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO ai_analysis (file_id, analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (file_id, "full_analysis", classification["category"], 
              extracted_text[:1000], json.dumps(key_phrases, ensure_ascii=False), 
              summary, classification["confidence"], classification.get("method", "Unknown")))
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "extracted_text": extracted_text,
            "classification": classification,
            "key_phrases": key_phrases,
            "summary": summary
        }
    
    def get_ai_analysis(self, file_id: int) -> Optional[Dict[str, Any]]:
        """è·å–æ–‡ä»¶çš„AIåˆ†æç»“æœ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method, analysis_time
            FROM ai_analysis WHERE file_id = ? ORDER BY analysis_time DESC LIMIT 1
        ''', (file_id,))
        result = cursor.fetchone()
        conn.close()
        
        if result:
            analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method, analysis_time = result
            return {
                "analysis_type": analysis_type,
                "industry_category": industry_category,
                "extracted_text": extracted_text,
                "key_phrases": json.loads(key_phrases) if key_phrases else [],
                "summary": summary,
                "confidence_score": confidence_score,
                "method": method or "Unknown",
                "analysis_time": analysis_time
            }
        return None
    
    def create_industry_folder(self, category: str) -> int:
        """ä¸ºè¡Œä¸šåˆ†ç±»åˆ›å»ºæ–‡ä»¶å¤¹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å·²å­˜åœ¨ï¼ˆè‹±æ–‡å‘½åï¼‰
        eng_category = self._to_english_category(category)
        cursor.execute('SELECT id FROM folders WHERE folder_name = ?', (f"AI_{eng_category}",))
        result = cursor.fetchone()
        
        if result:
            folder_id = result[0]
        else:
            cursor.execute('''
                INSERT INTO folders (folder_name, parent_folder_id)
                VALUES (?, ?)
            ''', (f"AI_{eng_category}", None))
            folder_id = cursor.lastrowid
        
        conn.commit()
        conn.close()
        return folder_id
    
    def move_file_to_industry_folder(self, file_id: int, category: str) -> bool:
        """å°†æ–‡ä»¶ç§»åŠ¨åˆ°è¡Œä¸šåˆ†ç±»æ–‡ä»¶å¤¹"""
        try:
            folder_id = self.create_industry_folder(category)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('UPDATE files SET folder_id = ? WHERE id = ?', (folder_id, file_id))
            conn.commit()
            conn.close()
            return True
        except:
            return False
    
    # ==================== åŸºç¡€æ–‡ä»¶ç®¡ç†åŠŸèƒ½ ====================
    
    def rename_file(self, file_id: int, new_filename: str) -> Dict[str, Any]:
        """é‡å‘½åæ–‡ä»¶"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ–°æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨
            cursor.execute('SELECT id FROM files WHERE filename = ? AND id != ?', (new_filename, file_id))
            if cursor.fetchone():
                conn.close()
                return {"success": False, "error": "æ–‡ä»¶åå·²å­˜åœ¨"}
            
            # æ›´æ–°æ–‡ä»¶å
            cursor.execute('UPDATE files SET filename = ? WHERE id = ?', (new_filename, file_id))
            conn.commit()
            conn.close()
            
            return {"success": True, "new_filename": new_filename}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def delete_file(self, file_id: int) -> Dict[str, Any]:
        """åˆ é™¤æ–‡ä»¶"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ–‡ä»¶è·¯å¾„
            cursor.execute('SELECT file_path FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            
            if result:
                file_path = result[0]
                
                # åˆ é™¤ç‰©ç†æ–‡ä»¶
                if os.path.exists(file_path):
                    os.remove(file_path)
                
                # åˆ é™¤æ•°æ®åº“è®°å½•
                cursor.execute('DELETE FROM files WHERE id = ?', (file_id,))
                
                # åˆ é™¤AIåˆ†æè®°å½•
                cursor.execute('DELETE FROM ai_analysis WHERE file_id = ?', (file_id,))
                
                conn.commit()
                conn.close()
                
                return {"success": True}
            else:
                conn.close()
                return {"success": False, "error": "æ–‡ä»¶ä¸å­˜åœ¨"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def rename_folder(self, folder_id: int, new_folder_name: str) -> Dict[str, Any]:
        """é‡å‘½åæ–‡ä»¶å¤¹"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ–°æ–‡ä»¶å¤¹åæ˜¯å¦å·²å­˜åœ¨
            cursor.execute('SELECT id FROM folders WHERE folder_name = ? AND id != ?', (new_folder_name, folder_id))
            if cursor.fetchone():
                conn.close()
                return {"success": False, "error": "æ–‡ä»¶å¤¹åå·²å­˜åœ¨"}
            
            # æ›´æ–°æ–‡ä»¶å¤¹å
            cursor.execute('UPDATE folders SET folder_name = ? WHERE id = ?', (new_folder_name, folder_id))
            conn.commit()
            conn.close()
            
            return {"success": True, "new_folder_name": new_folder_name}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def delete_folder(self, folder_id: int) -> Dict[str, Any]:
        """åˆ é™¤æ–‡ä»¶å¤¹"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º
            cursor.execute('SELECT COUNT(*) FROM files WHERE folder_id = ?', (folder_id,))
            file_count = cursor.fetchone()[0]
            
            if file_count > 0:
                conn.close()
                return {"success": False, "error": f"æ–‡ä»¶å¤¹ä¸ä¸ºç©ºï¼ŒåŒ…å« {file_count} ä¸ªæ–‡ä»¶"}
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å­æ–‡ä»¶å¤¹
            cursor.execute('SELECT COUNT(*) FROM folders WHERE parent_folder_id = ?', (folder_id,))
            subfolder_count = cursor.fetchone()[0]
            
            if subfolder_count > 0:
                conn.close()
                return {"success": False, "error": f"æ–‡ä»¶å¤¹åŒ…å« {subfolder_count} ä¸ªå­æ–‡ä»¶å¤¹"}
            
            # åˆ é™¤æ–‡ä»¶å¤¹
            cursor.execute('DELETE FROM folders WHERE id = ?', (folder_id,))
            conn.commit()
            conn.close()
            
            return {"success": True}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_folders(self, parent_folder_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """è·å–æ–‡ä»¶å¤¹åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if parent_folder_id is None:
            cursor.execute('''
                SELECT id, folder_name, created_time, 
                       (SELECT COUNT(*) FROM files WHERE folder_id = folders.id) as file_count
                FROM folders 
                WHERE parent_folder_id IS NULL
                ORDER BY created_time DESC
            ''')
        else:
            cursor.execute('''
                SELECT id, folder_name, created_time,
                       (SELECT COUNT(*) FROM files WHERE folder_id = folders.id) as file_count
                FROM folders 
                WHERE parent_folder_id = ?
                ORDER BY created_time DESC
            ''', (parent_folder_id,))
        
        folders = []
        for row in cursor.fetchall():
            folders.append({
                "id": row[0],
                "folder_name": row[1],
                "created_time": row[2],
                "file_count": row[3]
            })
        
        conn.close()
        return folders
    
    def sync_cached_files(self) -> Dict[str, Any]:
        """åŒæ­¥ç¼“å­˜æ–‡ä»¶åˆ°äº‘ç«¯"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰å·²ç¼“å­˜çš„æ–‡ä»¶
            cursor.execute('''
                SELECT id, filename, file_path, last_modified
                FROM files 
                WHERE is_cached = TRUE
            ''')
            
            cached_files = cursor.fetchall()
            synced_count = 0
            
            for file_id, filename, file_path, last_modified in cached_files:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
                if os.path.exists(file_path):
                    # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
                    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    cursor.execute('''
                        UPDATE files 
                        SET last_modified = ? 
                        WHERE id = ?
                    ''', (current_time, file_id))
                    synced_count += 1
            
            conn.commit()
            conn.close()
            
            return {
                "success": True,
                "synced_count": synced_count,
                "message": f"æˆåŠŸåŒæ­¥ {synced_count} ä¸ªç¼“å­˜æ–‡ä»¶"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

# åˆå§‹åŒ–äº‘å­˜å‚¨ç®¡ç†å™¨
if 'storage_manager' not in st.session_state:
    st.session_state.storage_manager = CloudStorageManager()

storage_manager = st.session_state.storage_manager

# ä¾§è¾¹æ 
with st.sidebar:
    st.markdown("### ğŸŒ¾ Agribusiness Expert AI Cloud")
    st.markdown("---")
    
    # å¿«é€Ÿæ“ä½œ
    st.markdown("### âš¡ Quick Actions")
    
    # æ–‡ä»¶å¤¹ç®¡ç†
    st.markdown("### ğŸ“ Folder Management")
    
    # åˆ›å»ºæ–‡ä»¶å¤¹
    with st.form("create_folder_form"):
        folder_name = st.text_input("ğŸ“ New Folder", placeholder="Enter folder name")
        if st.form_submit_button("Create", width='stretch'):
            if folder_name:
                result = storage_manager.create_folder(folder_name)
                if result["success"]:
                    st.success(f"âœ… Folder '{folder_name}' created successfully!")
                else:
                    st.error(f"âŒ Creation failed: {result['error']}")
            else:
                st.warning("Please enter folder name")
    
    # æ–‡ä»¶å¤¹åˆ—è¡¨
    folders = storage_manager.get_folders()
    if folders:
        st.markdown("#### Existing Folders")
        for folder in folders:
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                st.write(f"ğŸ“ {folder['folder_name']}")
                st.caption(f"Files: {folder['file_count']} | Created: {folder['created_time']}")
            with col2:
                # é‡å‘½åæ–‡ä»¶å¤¹
                with st.popover("âœï¸", help="Rename folder"):
                    new_name = st.text_input("New Name", value=folder['folder_name'], key=f"folder_rename_{folder['id']}")
                    if st.button("âœ… Confirm", key=f"folder_rename_confirm_{folder['id']}"):
                        result = storage_manager.rename_folder(folder['id'], new_name)
                        if result["success"]:
                            st.success("Rename successful!")
                            st.rerun()
                        else:
                            st.error(f"Rename failed: {result['error']}")
            with col3:
                # åˆ é™¤æ–‡ä»¶å¤¹
                if st.button("ğŸ—‘ï¸", key=f"folder_delete_{folder['id']}", help="Delete folder"):
                    result = storage_manager.delete_folder(folder['id'])
                    if result["success"]:
                        st.success("Folder deleted!")
                        st.rerun()
                    else:
                        st.error(f"Delete failed: {result['error']}")
    
    # åŒæ­¥åŠŸèƒ½
    st.markdown("---")
    if st.button("ğŸ”„ Sync Cache", width='stretch', help="Sync all cached files"):
        result = storage_manager.sync_cached_files()
        if result["success"]:
            st.success(result["message"])
        else:
            st.error(f"Sync failed: {result['error']}")
    
    st.markdown("---")
    
    # Agribusinesså·¥å…·ä¸AIåŠŸèƒ½åŒºåŸŸ
    st.markdown("### ğŸŒ¾ Agribusiness Tools & AI")
    with st.expander("â˜ï¸ Weather & Climate (Open-Meteo)", expanded=False):
        colw1, colw2 = st.columns(2)
        with colw1:
            lat = st.number_input("Latitude", value=0.0, step=0.1)
        with colw2:
            lon = st.number_input("Longitude", value=20.0, step=0.1)
        if st.button("Fetch 7-Day Climate Summary", use_container_width=True):
            with st.spinner("Fetching weather data..."):
                res = storage_manager.fetch_weather_summary(lat, lon)
                if res.get("success"):
                    ws = res["weather"]["summary"]
                    st.success("Weather updated")
                    st.write({
                        "7d total rainfall (mm)": ws.get("7d_total_rain_mm"),
                        "Avg Tmax (Â°C)": ws.get("avg_tmax"),
                        "Avg Tmin (Â°C)": ws.get("avg_tmin")
                    })
                else:
                    st.error(f"Weather fetch failed: {res.get('error')}")

    with st.expander("ğŸ›°ï¸ Remote Sensing (NDVI/EVI)", expanded=False):
        colr1, colr2, colr3 = st.columns(3)
        with colr1:
            rs_lat = st.number_input("Latitude", value=0.0, step=0.1, key="rs_lat")
        with colr2:
            rs_lon = st.number_input("Longitude", value=20.0, step=0.1, key="rs_lon")
        with colr3:
            rs_days = st.slider("Days", min_value=7, max_value=60, value=30, step=1, key="rs_days")
        if st.button("Generate NDVI/EVI Timeseries", use_container_width=True):
            with st.spinner("Generating NDVI/EVI (stub)..."):
                res = storage_manager.compute_remote_sensing_stub(rs_lat, rs_lon, rs_days)
                if res.get("success"):
                    rs = res["remote_sensing"]
                    st.success("Generated")
                    if rs.get("dates") and rs.get("ndvi"):
                        st.markdown("**NDVI**")
                        ndvi_df = pd.DataFrame({"date": rs["dates"], "NDVI": rs["ndvi"]}).set_index("date")
                        st.line_chart(ndvi_df)
                    if rs.get("dates") and rs.get("evi"):
                        st.markdown("**EVI**")
                        evi_df = pd.DataFrame({"date": rs["dates"], "EVI": rs["evi"]}).set_index("date")
                        st.line_chart(evi_df)
                else:
                    st.error(f"Remote sensing generation failed: {res.get('error')}")

    with st.expander("ğŸ§® Agri Quick Calculator", expanded=False):
        st.caption("Quick estimation: total production & profit")
        # æ€»äº§é‡ = é¢ç§¯ Ã— å•äº§ï¼ˆè‡ªåŠ¨åšå°‘é‡å•ä½é€‚é…ï¼‰
        colc1, colc2, colc3 = st.columns(3)
        with colc1:
            area_value = st.number_input("Area value", value=100.0, step=1.0)
            area_unit = st.selectbox("Area unit", ["hectare(ha)", "mu"], index=0)
        with colc2:
            yield_value = st.number_input("Yield value", value=3.0, step=0.1)
            yield_unit = st.selectbox("Yield unit", ["t/ha", "kg/ha", "kg/mu", "jin/mu"], index=0)
        with colc3:
            currency = st.selectbox("Currency", ["USD", "KES", "NGN", "ZAR", "GHS", "XOF", "XAF", "ETB", "TZS"], index=1)
            price_value = st.number_input("Price (per kg)", value=0.5, step=0.05)
            cost_value = st.number_input("Total cost", value=50000.0, step=1000.0)

        if st.button("è®¡ç®—æ€»äº§ä¸åˆ©æ¶¦", use_container_width=True):
            # å•ä½æ¢ç®—åˆ° å…¬æ–¤/äº©
            if yield_unit == "jin/mu":
                yield_kg_per_mu = yield_value * 0.5
            elif yield_unit == "kg/ha":
                yield_kg_per_mu = yield_value / 15.0  # 1 ha â‰ˆ 15 äº©
            elif yield_unit == "t/ha":
                yield_kg_per_mu = (yield_value * 1000.0) / 15.0
            else:
                yield_kg_per_mu = yield_value

            # é¢ç§¯æ¢ç®—åˆ° äº©
            area_mu = area_value * (15.0 if area_unit == "hectare(ha)" else 1.0)

            total_production_kg = area_mu * yield_kg_per_mu
            revenue = total_production_kg * price_value
            profit = revenue - cost_value
            st.success("Calculated")
            st.write({
                "Total production (kg)": round(total_production_kg, 2),
                f"Revenue ({currency})": round(revenue, 2),
                f"Profit ({currency})": round(profit, 2)
            })
    
    # AIæ¨¡å‹çŠ¶æ€
    with st.expander("ğŸ” AI Model Status", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            if OCR_AVAILABLE and storage_manager.ocr_reader is not None:
                st.success("âœ… OCR Text Recognition")
            elif OCR_AVAILABLE:
                st.warning("ğŸ”„ OCR model loading...")
            else:
                st.error("âŒ OCR Text Recognition")
            
            if TRANSFORMERS_AVAILABLE:
                st.success("âœ… Deep Learning Model")
            else:
                st.error("âŒ Deep Learning Model")
        
        with col2:
            if ML_AVAILABLE:
                st.success("âœ… Machine Learning Classification")
            else:
                st.error("âŒ Machine Learning Classification")
            
            if OPENAI_AVAILABLE:
                st.success("âœ… OpenAI Integration")
            else:
                st.warning("âš ï¸ OpenAI Integration")
    
    # AIåˆ†ææŒ‰é’®
    if st.button("ğŸ§  Smart Analysis", width='stretch', help="Perform AI analysis on all files"):
        st.session_state.show_ai_analysis = True
    else:
        st.session_state.show_ai_analysis = False
    
    # é‡æ–°åˆå§‹åŒ–AIæ¨¡å‹
    if st.button("ğŸ”„ Reload AI", width='stretch', help="Reinitialize AI models"):
        with st.spinner("Reloading AI models..."):
            storage_manager.init_ai_models()
            st.success("âœ… AI models reloaded successfully!")
    
    # è¡Œä¸šåˆ†ç±»æŸ¥çœ‹
    if st.button("ğŸ“Š Industry Classification", width='stretch', help="View files classified by industry"):
        st.session_state.show_industry_view = True
    else:
        st.session_state.show_industry_view = False
    
    # æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆ
    if st.button("ğŸ“ˆ Smart Report", width='stretch', help="Generate smart analysis reports and charts"):
        st.session_state.show_smart_report = True
    else:
        st.session_state.show_smart_report = False
    
    st.markdown("---")
    
    # æœç´¢åŠŸèƒ½
    st.markdown("### ğŸ” Search Files")
    search_query = st.text_input("Search File Name", placeholder="Enter keywords")
    search_type = st.selectbox("File Type", ["All", "image", "application", "text", "video", "audio"])
    
    if st.button("ğŸ” Search", width='stretch') and search_query:
        file_type = None if search_type == "All" else search_type
        search_results = storage_manager.search_files(search_query, file_type)
        st.session_state.search_results = search_results
        st.session_state.show_search = True
    else:
        st.session_state.show_search = False

# ä¸»ç•Œé¢
st.title("ğŸŒ¾ Agribusiness Expert AI Cloud")
st.markdown("Built for agribusiness: document management + KPIs + climate/remote sensing insights")

# æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
st.markdown("### ğŸ“¤ File Upload")

# ä¸Šä¼ æ¨¡å¼é€‰æ‹©
upload_mode = st.radio(
    "Select Upload Mode",
    ["Normal Upload", "Resume Upload"],
    horizontal=True,
    help="Resume upload supports continuing after network interruption"
)

# é€‰æ‹©ä¸Šä¼ æ–‡ä»¶å¤¹
folders = storage_manager.get_folders()
folder_options = ["Root Directory"] + [f["folder_name"] for f in folders]
selected_folder = st.selectbox("Select Upload Folder", folder_options, help="Choose the folder to upload files to")

# è·å–é€‰ä¸­çš„æ–‡ä»¶å¤¹ID
target_folder_id = None
if selected_folder != "Root Directory":
    for folder in folders:
        if folder["folder_name"] == selected_folder:
            target_folder_id = folder["id"]
            break

uploaded_files = st.file_uploader(
    "Choose Files to Upload", 
    type=["xlsx", "xls", "csv", "pdf", "png", "jpg", "jpeg", "gif", "bmp", "txt", "doc", "docx"],
    accept_multiple_files=True,
    help="Supports Excel, PDF, Images, CSV and other formats"
)

if uploaded_files:
    for uploaded_file in uploaded_files:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.write(f"ğŸ“„ {uploaded_file.name} ({storage_manager.format_file_size(len(uploaded_file.getbuffer()))})")
        
        with col2:
            if upload_mode == "Normal Upload":
                if st.button(f"ğŸ“¤ Upload", key=f"upload_{uploaded_file.name}"):
                    with st.spinner(f"Uploading {uploaded_file.name}..."):
                        result = storage_manager.upload_file(uploaded_file, target_folder_id)
                        if result["success"]:
                            folder_name = selected_folder if selected_folder != "Root Directory" else "Root Directory"
                            st.success(f"âœ… {uploaded_file.name} uploaded to {folder_name}!")
                        else:
                            st.error(f"âŒ Upload failed: {result['error']}")
            else:
                if st.button(f"ğŸ”„ Resume Upload", key=f"resume_upload_{uploaded_file.name}"):
                    with st.spinner(f"Resume uploading {uploaded_file.name}..."):
                        result = storage_manager.upload_file_with_resume(uploaded_file, target_folder_id)
                        if result["success"]:
                            folder_name = selected_folder if selected_folder != "Root Directory" else "Root Directory"
                            st.success(f"âœ… {uploaded_file.name} resume uploaded to {folder_name}!")
                        else:
                            st.error(f"âŒ Resume upload failed: {result['error']}")

# ä¸Šä¼ è¿›åº¦æ˜¾ç¤º
progress_list = storage_manager.get_upload_progress()
if progress_list:
    st.markdown("### ğŸ”„ Upload Progress")
    for progress in progress_list:
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.write(f"ğŸ“„ {progress['filename']}")
            st.progress(progress['progress'])
            st.caption(f"{storage_manager.format_file_size(progress['uploaded_size'])} / {storage_manager.format_file_size(progress['total_size'])}")
        
        with col2:
            if st.button("ğŸ”„ ç»§ç»­", key=f"resume_{progress['filename']}"):
                result = storage_manager.resume_upload(progress['filename'])
                if result["success"]:
                    st.success("Continue uploading...")
                else:
                    st.error("Unable to continue upload")
        
        with col3:
            if st.button("âŒ å–æ¶ˆ", key=f"cancel_{progress['filename']}"):
                if storage_manager.cancel_upload(progress['filename']):
                    st.success("Upload cancelled")
                    st.rerun()
                else:
                    st.error("Cancel failed")

# æ–‡ä»¶å¤¹å¯¼èˆª
current_folder_id = st.session_state.get('current_folder_id', None)
if current_folder_id is not None:
    # æ˜¾ç¤ºå½“å‰æ–‡ä»¶å¤¹ä¿¡æ¯
    conn = sqlite3.connect(storage_manager.db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT folder_name FROM folders WHERE id = ?', (current_folder_id,))
    folder_name = cursor.fetchone()
    conn.close()
    
    if folder_name:
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"### ğŸ“ Current Folder: {folder_name[0]}")
        with col2:
            if st.button("â¬…ï¸ Back to Root", width='stretch'):
                st.session_state.current_folder_id = None
                st.rerun()

# æ£€æŸ¥æ˜¾ç¤ºæ¨¡å¼
files = []  # ç¡®ä¿åç»­ä½¿ç”¨æ—¶å·²å®šä¹‰
if st.session_state.get('show_ai_analysis', False):
    st.markdown("### ğŸ¤– AI Smart Analysis")
    
    # è·å–æ‰€æœ‰æ–‡ä»¶è¿›è¡ŒAIåˆ†æ
    all_files = storage_manager.get_files()
    
    if all_files:
        st.info(f"Analyzing {len(all_files)} files with AI...")
        
        # æ‰¹é‡AIåˆ†æ
        analysis_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, file in enumerate(all_files):
            status_text.text(f"Analyzing: {file['filename']}")
            result = storage_manager.analyze_file_with_ai(file['id'])
            analysis_results.append({
                'file': file,
                'analysis': result
            })
            progress_bar.progress((i + 1) / len(all_files))
        
        progress_bar.empty()
        status_text.empty()
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        st.success("AI analysis completed!")
        
        # æŒ‰è¡Œä¸šåˆ†ç±»æ˜¾ç¤º
        industry_groups = {}
        for result in analysis_results:
            if result['analysis']['success']:
                category = result['analysis']['classification']['category']
                if category not in industry_groups:
                    industry_groups[category] = []
                industry_groups[category].append(result)
        
        for category, files in industry_groups.items():
            with st.expander(f"ğŸ“Š {category} ({len(files)} files)", expanded=True):
                for result in files:
                    file = result['file']
                    analysis = result['analysis']
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"ğŸ“„ {file['filename']}")
                        st.caption(f"Confidence: {analysis['classification']['confidence']:.2%}")
                        if analysis['summary']:
                            st.info(f"Summary: {analysis['summary']}")
                    with col2:
                        if st.button("ğŸ“ Classify", key=f"batch_classify_{file['id']}"):
                            if storage_manager.move_file_to_industry_folder(file['id'], category):
                                st.success("Classified!")
                                st.rerun()
    
    else:
        st.warning("No files to analyze")

elif st.session_state.get('show_industry_view', False):
    st.markdown("### ğŸ“Š Industry Classification View")
    
    # è·å–æ‰€æœ‰è¡Œä¸šåˆ†ç±»
    conn = sqlite3.connect(storage_manager.db_path)
    cursor = conn.cursor()
    cursor.execute('''
        SELECT DISTINCT industry_category, COUNT(*) as file_count
        FROM ai_analysis 
        WHERE industry_category IS NOT NULL
        GROUP BY industry_category
        ORDER BY file_count DESC
    ''')
    categories = cursor.fetchall()
    conn.close()
    
    if categories:
        for category, count in categories:
            with st.expander(f"ğŸ“ {category} ({count} files)", expanded=True):
                # è·å–è¯¥åˆ†ç±»çš„æ–‡ä»¶
                conn = sqlite3.connect(storage_manager.db_path)
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT f.id, f.filename, f.file_size, f.upload_time, a.confidence_score, a.summary
                    FROM files f
                    JOIN ai_analysis a ON f.id = a.file_id
                    WHERE a.industry_category = ?
                    ORDER BY a.confidence_score DESC
                ''', (category,))
                file_rows = cursor.fetchall()
                conn.close()
                
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¿æŒä¸€è‡´æ€§
                files = []
                for file_id, filename, file_size, upload_time, confidence, summary in file_rows:
                    files.append({
                        "id": file_id,
                        "filename": filename,
                        "file_size": file_size,
                        "upload_time": upload_time,
                        "confidence": confidence,
                        "summary": summary
                    })
                
                for file in files:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"ğŸ“„ {file['filename']}")
                        st.caption(f"Uploaded: {file['upload_time']}")
                        if file['summary']:
                            st.info(f"Summary: {file['summary']}")
                    with col2:
                        st.metric("Confidence", f"{file['confidence']:.2%}")
                    with col3:
                        st.metric("File Size", storage_manager.format_file_size(file['file_size']))
    else:
        st.info("No files have been analyzed by AI yet")

# æ–‡ä»¶åˆ—è¡¨æ˜¾ç¤º
elif st.session_state.get('show_search', False) and 'search_results' in st.session_state:
    st.markdown("### ğŸ” Search Results")
    files = st.session_state.search_results
    st.info(f"ğŸ” Search Results: Found {len(files)} files")
else:
    st.markdown("### ğŸ“ File List")
    files = storage_manager.get_files(current_folder_id)
    
    # æ˜¾ç¤ºå­æ–‡ä»¶å¤¹
    if current_folder_id is None:
        subfolders = storage_manager.get_folders()
    else:
        subfolders = storage_manager.get_folders(current_folder_id)
    
    if subfolders:
        st.markdown("#### ğŸ“ Folders")
        for folder in subfolders:
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                if st.button(f"ğŸ“ {folder['folder_name']} ({folder['file_count']} files)", key=f"enter_folder_{folder['id']}", width='stretch'):
                    st.session_state.current_folder_id = folder['id']
                    st.rerun()
            with col2:
                if st.button("âœï¸", key=f"rename_folder_ui_{folder['id']}", help="Rename"):
                    st.session_state[f"rename_folder_{folder['id']}"] = True
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"delete_folder_ui_{folder['id']}", help="Delete"):
                    result = storage_manager.delete_folder(folder['id'])
                    if result["success"]:
                        st.success("Folder deleted!")
                        st.rerun()
                    else:
                        st.error(f"Delete failed: {result['error']}")
        
        st.markdown("---")

if files:
    # æ–‡ä»¶ç»Ÿè®¡
    total_size = sum(file.get('file_size', 0) for file in files)
    cached_count = sum(1 for file in files if file.get('is_cached', False))
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Files", len(files))
    with col2:
        st.metric("Total Size", storage_manager.format_file_size(total_size))
    with col3:
        st.metric("Cached", f"{cached_count}/{len(files)}")
    with col4:
        st.metric("Cache Rate", f"{cached_count/len(files)*100:.1f}%")
    
    st.markdown("---")
    
    # æ–‡ä»¶åˆ—è¡¨ - ä½¿ç”¨å¡ç‰‡å¼å¸ƒå±€
    for file in files:
        with st.container():
            # æ–‡ä»¶å¡ç‰‡
            st.markdown(f"""
            <div class="file-card">
                <div style="display: flex; align-items: center; justify-content: space-between;">
                    <div style="display: flex; align-items: center; flex: 1;">
                        <span class="file-icon">{storage_manager.get_file_icon(file['file_type'])}</span>
                        <div>
                            <h4 style="margin: 0; color: #1e293b;">{file['filename']}</h4>
                            <p style="margin: 4px 0 0 0; color: #64748b; font-size: 14px;">
                                Type: {file['file_type']} | Uploaded: {file['upload_time']}
                            </p>
                        </div>
                    </div>
                    <div style="display: flex; align-items: center; gap: 16px;">
                        <span style="font-weight: 600; color: #475569;">{storage_manager.format_file_size(file['file_size'])}</span>
                        <span style="padding: 4px 8px; border-radius: 4px; font-size: 12px; background: {'#dcfce7' if file['is_cached'] else '#dbeafe'}; color: {'#166534' if file['is_cached'] else '#1e40af'};">
                            {'âœ… Cached' if file['is_cached'] else 'â˜ï¸ Cloud'}
                        </span>
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§æ“ä½œæŒ‰é’®ï¼Œå³ä¾§é¢„è§ˆå†…å®¹
            col_left, col_right = st.columns([1, 1])
            
            with col_left:
                # é¢„è§ˆæ§åˆ¶
                show_preview = st.checkbox("ğŸ‘ï¸ Preview File", key=f"preview_{file['id']}", help="Click to preview file content")
                
                # æ“ä½œæŒ‰é’®è¡Œ
                col1, col2 = st.columns(2)
                
                with col1:
                    # AIåˆ†ææŒ‰é’®
                    if st.button("ğŸ§  AI Analysis", key=f"ai_analyze_{file['id']}", help="Use AI to analyze file content", width='stretch'):
                        with st.spinner("AI is analyzing file..."):
                            result = storage_manager.analyze_file_with_ai(file['id'])
                            if result["success"]:
                                st.success("AI analysis completed!")
                                st.rerun()
                            else:
                                st.error(f"AI analysis failed: {result['error']}")
                    
                    # æ™ºèƒ½æŠ¥å‘ŠæŒ‰é’®
                    if st.button("ğŸ“ˆ Smart Report", key=f"smart_report_{file['id']}", help="Generate smart analysis report and charts", width='stretch'):
                        with st.spinner("Generating smart report..."):
                            result = storage_manager.generate_smart_report(file['id'])
                            if result["success"]:
                                st.session_state[f"show_report_{file['id']}"] = True
                                st.session_state[f"report_data_{file['id']}"] = result
                                st.success("Smart report generated successfully!")
                                st.rerun()
                            else:
                                st.error(f"Report generation failed: {result['error']}")
                
                with col2:
                    # ç¼“å­˜æŒ‰é’®
                    if not file['is_cached']:
                        if st.button("ğŸ’¾ Cache", key=f"cache_{file['id']}", help="Cache to local", width='stretch'):
                            if storage_manager.cache_file(file['id']):
                                st.success("Cached successfully!")
                                st.rerun()
                            else:
                                st.error("Cache failed")
                    else:
                        st.success("Cached")
                    
                    # ä¸‹è½½æŒ‰é’®
                    if st.button("ğŸ“¥ Download", key=f"download_btn_{file['id']}", help="Download file", width='stretch'):
                        file_data = storage_manager.preview_file(file['id'])
                        if file_data:
                            st.download_button(
                                "ğŸ“¥ Download File",
                                file_data,
                                file['filename'],
                                key=f"download_file_{file['id']}"
                            )
                        else:
                            st.error("File not found")
                
                # æ–‡ä»¶æ“ä½œèœå•
                with st.popover("âš™ï¸ Actions", help="File operation menu"):
                    # é‡å‘½å
                    new_name = st.text_input("Rename", value=file['filename'], key=f"rename_input_{file['id']}")
                    if st.button("âœ… Confirm Rename", key=f"rename_confirm_{file['id']}"):
                        result = storage_manager.rename_file(file['id'], new_name)
                        if result["success"]:
                            st.success("Rename successful!")
                            st.rerun()
                        else:
                            st.error(f"Rename failed: {result['error']}")
                    
                    st.markdown("---")
                    
                    # ç§»åŠ¨æ–‡ä»¶
                    st.markdown("**Move to Folder:**")
                    move_folders = storage_manager.get_folders()
                    move_options = ["Root Directory"] + [f["folder_name"] for f in move_folders]
                    target_move_folder = st.selectbox("Select Target Folder", move_options, key=f"move_folder_{file['id']}")
                    
                    if st.button("ğŸ“ Move File", key=f"move_file_{file['id']}"):
                        target_move_folder_id = None
                        if target_move_folder != "Root Directory":
                            for folder in move_folders:
                                if folder["folder_name"] == target_move_folder:
                                    target_move_folder_id = folder["id"]
                                    break
                        
                        conn = sqlite3.connect(storage_manager.db_path)
                        cursor = conn.cursor()
                        cursor.execute('UPDATE files SET folder_id = ? WHERE id = ?', (target_move_folder_id, file['id']))
                        conn.commit()
                        conn.close()
                        
                        st.success(f"File moved to {target_move_folder}!")
                        st.rerun()
                    
                    st.markdown("---")
                    
                    # åˆ é™¤
                    if st.button("ğŸ—‘ï¸ Delete File", key=f"delete_{file['id']}", help="Permanently delete file"):
                        if st.session_state.get(f"confirm_delete_{file['id']}", False):
                            result = storage_manager.delete_file(file['id'])
                            if result["success"]:
                                st.success("File deleted!")
                                st.rerun()
                            else:
                                st.error(f"Delete failed: {result['error']}")
                        else:
                            st.session_state[f"confirm_delete_{file['id']}"] = True
                            st.warning("âš ï¸ Click again to confirm deletion")
            
            with col_right:
                # é¢„è§ˆå†…å®¹åŒºåŸŸ - æ”¾åœ¨å³ä¾§åˆ—
                if show_preview:
                    st.markdown("#### ğŸ“„ File Preview")
                    
                    file_data = storage_manager.preview_file(file['id'])
                    if file_data:
                        if file['file_type'] == 'image':
                            st.image(file_data, caption=file['filename'], width='stretch')
                        elif file['file_type'] == 'application' and file['filename'].endswith('.pdf'):
                            if PDF_AVAILABLE:
                                try:
                                    # ä½¿ç”¨BytesIOåŒ…è£…æ•°æ®
                                    import io
                                    pdf_stream = io.BytesIO(file_data)
                                    doc = fitz.open(stream=pdf_stream, filetype="pdf")
                                    
                                    if len(doc) > 0:
                                        page = doc[0]
                                        # è®¾ç½®åˆé€‚çš„ç¼©æ”¾æ¯”ä¾‹
                                        mat = fitz.Matrix(1.5, 1.5)  # 1.5å€ç¼©æ”¾
                                        pix = page.get_pixmap(matrix=mat)
                                        img_data = pix.tobytes("png")
                                        st.image(img_data, caption=f"PDF Preview: {file['filename']} (Page 1)", width='stretch')
                                        
                                        # æ˜¾ç¤ºé¡µæ•°ä¿¡æ¯
                                        if len(doc) > 1:
                                            st.caption(f"PDF has {len(doc)} pages, showing page 1")
                                    else:
                                        st.warning("PDF file is empty or cannot be read")
                                    
                                    doc.close()
                                except Exception as e:
                                    st.error(f"PDF preview failed: {str(e)}")
                                    st.info("Try downloading the file to view content")
                                    st.download_button(
                                        "ğŸ“¥ Download PDF",
                                        file_data,
                                        file['filename'],
                                        key=f"preview_download_pdf_{file['id']}"
                                    )
                            else:
                                st.info("PDF preview requires PyMuPDF module")
                                st.info("Please run: pip install PyMuPDF")
                                st.download_button(
                                    "ğŸ“¥ Download PDF",
                                    file_data,
                                    file['filename'],
                                    key=f"preview_download_pdf_no_fitz_{file['id']}"
                                )
                        elif file['file_type'] == 'application' and file['filename'].endswith(('.xlsx', '.xls')):
                            try:
                                import pandas as pd
                                import io
                                df = pd.read_excel(io.BytesIO(file_data))
                                # ç¡®ä¿DataFrameä¸ä¸ºç©º
                                if not df.empty:
                                    # å®‰å…¨åœ°æ˜¾ç¤ºDataFrameï¼Œé¿å…numpy.str_é”™è¯¯
                                    try:
                                        st.dataframe(df.head(10), width='stretch')
                                        st.caption(f"Excel Preview: {file['filename']} (Showing first 10 rows)")
                                    except Exception as display_error:
                                        # å¦‚æœdataframeæ˜¾ç¤ºå¤±è´¥ï¼Œæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                                        st.write(f"Excel File: {file['filename']}")
                                        st.write(f"Rows: {len(df)}, Columns: {len(df.columns)}")
                                        st.write("Column names:", list(df.columns))
                                else:
                                    st.warning("Excel file is empty")
                            except Exception as e:
                                st.error(f"Excel preview failed: {str(e)}")
                                st.download_button(
                                    "ğŸ“¥ Download Excel",
                                    file_data,
                                    file['filename'],
                                    key=f"preview_download_excel_{file['id']}"
                                )
                        elif file['file_type'] == 'text' or file['filename'].endswith('.txt'):
                            try:
                                text_content = file_data.decode('utf-8')
                                st.text_area("File Content", text_content[:1000], height=200, key=f"text_preview_{file['id']}")
                                if len(text_content) > 1000:
                                    st.caption(f"Text Preview: {file['filename']} (Showing first 1000 characters)")
                                else:
                                    st.caption(f"Text Preview: {file['filename']}")
                            except Exception as e:
                                st.error(f"Text preview failed: {str(e)}")
                                st.download_button(
                                    "ğŸ“¥ Download Text",
                                    file_data,
                                    file['filename'],
                                    key=f"preview_download_txt_{file['id']}"
                                )
                        else:
                            st.info(f"Preview not supported for {file['file_type']} file type")
                            st.download_button(
                                "ğŸ“¥ Download File",
                                file_data,
                                file['filename'],
                                key=f"preview_download_other_{file['id']}"
                            )
                    else:
                        st.error("Unable to read file content")
            
            # AIåˆ†æç»“æœæ˜¾ç¤º
            ai_analysis = storage_manager.get_ai_analysis(file['id'])
            if ai_analysis:
                st.markdown("---")
                st.markdown("#### ğŸ¤– AI Analysis Results")
                
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.markdown(f"**Industry Category**: {ai_analysis['industry_category']}")
                    st.markdown(f"**Confidence**: {ai_analysis['confidence_score']:.2%}")
                    st.markdown(f"**Analysis Method**: {ai_analysis.get('method', 'Unknown')}")
                    st.markdown(f"**Analysis Time**: {ai_analysis['analysis_time']}")
                
                with col2:
                    if ai_analysis['key_phrases']:
                        st.markdown("**Key Phrases**:")
                        for phrase in ai_analysis['key_phrases'][:5]:
                            st.markdown(f"â€¢ {phrase}")
                
                if ai_analysis['summary']:
                    st.markdown("**Document Summary**:")
                    st.info(ai_analysis['summary'])
                
                # è‡ªåŠ¨åˆ†ç±»æŒ‰é’®
                if st.button("ğŸ“ Auto Classify", key=f"auto_classify_{file['id']}", help="Move file to corresponding industry folder"):
                    if storage_manager.move_file_to_industry_folder(file['id'], ai_analysis['industry_category']):
                        st.success(f"File moved to {ai_analysis['industry_category']} folder!")
                        st.rerun()
                else:
                        st.error("Classification failed")
            
            # æ™ºèƒ½æŠ¥å‘Šæ˜¾ç¤º
            if st.session_state.get(f"show_report_{file['id']}", False):
                report_data = st.session_state.get(f"report_data_{file['id']}")
                if report_data and report_data["success"]:
                    st.markdown("---")
                    st.markdown("#### ğŸ“ˆ Smart Analysis Report")
                    
                    # æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
                    st.markdown(report_data["report"])
                    
                    # æ˜¾ç¤ºå›¾è¡¨
                    if report_data["charts"]:
                        st.markdown("#### ğŸ“Š Data Visualization Charts")
                        
                        for chart in report_data["charts"]:
                            st.markdown(f"**{chart['title']}**")
                            
                            if chart['type'] == 'bar':
                                # æŸ±çŠ¶å›¾
                                chart_data = pd.DataFrame({
                                    'Category': chart['data']['labels'],
                                    'Value': chart['data']['values']
                                })
                                st.bar_chart(chart_data.set_index('Category'))
                            
                            elif chart['type'] == 'pie':
                                # é¥¼å›¾
                                pie_data = pd.DataFrame({
                                    'Category': chart['data']['labels'],
                                    'Value': chart['data']['values'],
                                    'Percentage': chart['data']['percentages']
                                })
                                st.dataframe(pie_data)
                            
                            elif chart['type'] == 'line':
                                # æŠ˜çº¿å›¾
                                line_data = pd.DataFrame({
                                    'Category': chart['data']['labels'],
                                    'Value': chart['data']['values']
                                })
                                st.line_chart(line_data.set_index('Category'))
                            
                            st.markdown("---")
                    
                    # å…³é—­æŠ¥å‘ŠæŒ‰é’®
                    if st.button("âŒ Close Report", key=f"close_report_{file['id']}"):
                        st.session_state[f"show_report_{file['id']}"] = False
                        st.rerun()
            

else:
    # ç©ºçŠ¶æ€
    st.markdown("<div style='text-align: center; padding: 40px 0;'>", unsafe_allow_html=True)
    st.header("ğŸ“ No Files")
    st.subheader("Upload your first file to start using cloud storage")
    st.markdown("</div>", unsafe_allow_html=True)
    
    # åŠŸèƒ½è¯´æ˜
    features = st.columns(3)
    with features[0]:
        st.info("""
        **ğŸ“¤ File Upload**
        - Multiple formats support
        - Resume upload
        - Auto validation
        """)
    with features[1]:
        st.success("""
        **ğŸ‘ï¸ Online Preview**
        - Instant image preview
        - PDF document viewing
        - No download needed
        """)
    with features[2]:
        st.warning("""
        **ğŸ’¾ Local Cache**
        - Offline access
        - Auto sync
        - Smart management
        """)

# é¡µè„š
st.markdown("---")
st.markdown("**Built with â¤ï¸ â€¢ AI Cloud Storage System â€¢ â˜ï¸ Intelligent Storage**")