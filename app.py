import streamlit as st
import pandas as pd
import os
import json
import hashlib
import mimetypes
import base64
import io
import time
import sqlite3
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import zipfile
import shutil
from pathlib import Path
import requests
from PIL import Image
import re
import numpy as np
from collections import Counter
import jieba
import jieba.analyse
try:
    import fitz  # PyMuPDF for PDF preview
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# AIÂäüËÉΩÁõ∏ÂÖ≥Â∫ì
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import easyocr
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.cluster import KMeans
    from sklearn.naive_bayes import MultinomialNB
    from sklearn.pipeline import Pipeline
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    # Â¶ÇÊûútransformers‰∏çÂèØÁî®ÔºåÊàë‰ª¨‰ΩøÁî®ÂÖ∂‰ªñÊñπÊ≥ï

# Set page config with premium aesthetics
st.set_page_config(
    page_title="Agribusiness Expert AI Cloud",
    page_icon="üåæ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Clean and modern CSS styling
st.markdown("""
<style>
    /* Overall Layout - Baidu Cloud Style */
    .main {
        background: #f5f5f5;
        color: #333;
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
    }
    
    /* Title Styles */
    h1, h2, h3, h4, h5, h6 {
        color: #333;
        font-weight: 500;
        margin-bottom: 1rem;
    }
    
    /* Button Styles - Baidu Cloud Blue */
    .stButton>button {
        background: linear-gradient(135deg, #1890ff 0%, #096dd9 100%);
        color: white;
        border: none;
        padding: 8px 16px;
        border-radius: 6px;
        font-weight: 400;
        font-size: 14px;
        transition: all 0.3s ease;
        box-shadow: 0 2px 8px rgba(24, 144, 255, 0.3);
    }
    
    .stButton>button:hover {
        background: linear-gradient(135deg, #40a9ff 0%, #1890ff 100%);
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(24, 144, 255, 0.4);
    }
    
    /* File Card Styles - Baidu Cloud Card */
    .file-card {
        background: white;
        border: 1px solid #e8e8e8;
        border-radius: 8px;
        padding: 16px;
        margin-bottom: 8px;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
        transition: all 0.3s ease;
        cursor: pointer;
    }
    
    .file-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        transform: translateY(-2px);
        border-color: #1890ff;
    }
    
    /* Metric Card Styles */
    .metric-card {
        background: white;
        border: 1px solid #e8e8e8;
        border-radius: 8px;
        padding: 16px;
        text-align: center;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
    }
    
    /* Sidebar Styles */
    .css-1d391kg {
        background: white;
        border-right: 1px solid #e8e8e8;
    }
    
    /* Preview Section Styles */
    .preview-section {
        background: white;
        border: 1px solid #e8e8e8;
        border-radius: 8px;
        padding: 16px;
        margin-top: 16px;
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
    }
    
    /* File Icon Styles */
    .file-icon {
        font-size: 28px;
        margin-right: 12px;
        width: 32px;
        text-align: center;
    }
    
    /* Action Button Styles */
    .action-btn {
        background: #fafafa;
        border: 1px solid #d9d9d9;
        color: #595959;
        padding: 6px 12px;
        border-radius: 4px;
        font-size: 12px;
        margin: 0 2px;
        transition: all 0.3s ease;
    }
    
    .action-btn:hover {
        background: #f0f0f0;
        border-color: #1890ff;
        color: #1890ff;
    }
    
    /* Status Tags */
    .status-cached {
        background: #f6ffed;
        color: #52c41a;
        border: 1px solid #b7eb8f;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: 500;
    }
    
    .status-cloud {
        background: #e6f7ff;
        color: #1890ff;
        border: 1px solid #91d5ff;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: 500;
    }
    
    /* File Type Colors */
    .file-type-image { color: #ff4d4f; }
    .file-type-document { color: #1890ff; }
    .file-type-video { color: #722ed1; }
    .file-type-audio { color: #fa8c16; }
    .file-type-text { color: #52c41a; }
    
    /* Grid Layout for Files */
    .files-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
        gap: 16px;
        margin-top: 16px;
    }
    
    /* File Card in Grid */
    .file-grid-card {
        background: white;
        border: 1px solid #e8e8e8;
        border-radius: 8px;
        padding: 16px;
        text-align: center;
        transition: all 0.3s ease;
        cursor: pointer;
        min-height: 180px;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
    }
    
    .file-grid-card:hover {
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        transform: translateY(-2px);
        border-color: #1890ff;
    }
    
    /* Action Menu */
    .action-menu {
        position: absolute;
        background: white;
        border: 1px solid #e8e8e8;
        border-radius: 6px;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        padding: 8px 0;
        z-index: 1000;
        min-width: 160px;
    }
    
    .action-menu-item {
        padding: 8px 16px;
        cursor: pointer;
        transition: background 0.2s ease;
        font-size: 14px;
        color: #333;
    }
    
    .action-menu-item:hover {
        background: #f5f5f5;
        color: #1890ff;
    }
</style>
""", unsafe_allow_html=True)

class CloudStorageManager:
    def __init__(self):
        # ‰∫ëÈÉ®ÁΩ≤ÈÖçÁΩÆ
        import os
        self.is_cloud_deployment = os.getenv('STREAMLIT_SERVER_PORT') is not None
        
        if self.is_cloud_deployment:
            # ‰∫ëÈÉ®ÁΩ≤Ôºö‰ΩøÁî®ÊåÅ‰πÖÂåñÂ≠òÂÇ®
            self.storage_dir = Path("/tmp/cloud_storage")
            self.cache_dir = Path("/tmp/local_cache")
            self.ai_analysis_dir = Path("/tmp/ai_analysis")
        else:
            # Êú¨Âú∞ÈÉ®ÁΩ≤Ôºö‰ΩøÁî®ÂΩìÂâçÁõÆÂΩï
            self.storage_dir = Path("cloud_storage")
            self.cache_dir = Path("local_cache")
            self.ai_analysis_dir = Path("ai_analysis")
        
        # ÂàõÂª∫ÁõÆÂΩï
        self.storage_dir.mkdir(exist_ok=True)
        self.cache_dir.mkdir(exist_ok=True)
        self.ai_analysis_dir.mkdir(exist_ok=True)
        
        self.db_path = self.storage_dir / "storage.db"
        self.init_database()
        
        # ÂàùÂßãÂåñAIÂäüËÉΩ
        self.init_ai_models()
        
        # Â§©Ê∞îÁºìÂ≠ò
        self.latest_weather: Optional[Dict[str, Any]] = None
        # ÈÅ•ÊÑüÁºìÂ≠ò
        self.latest_remote_sensing: Optional[Dict[str, Any]] = None
    
    def init_database(self):
        """ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ì"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Êñá‰ª∂Ë°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                file_path TEXT NOT NULL,
                file_size INTEGER,
                file_type TEXT,
                folder_id INTEGER,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                checksum TEXT,
                is_cached BOOLEAN DEFAULT FALSE,
                FOREIGN KEY (folder_id) REFERENCES folders (id)
            )
        ''')
        
        # Êñá‰ª∂Â§πË°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS folders (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                folder_name TEXT NOT NULL,
                parent_folder_id INTEGER,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (parent_folder_id) REFERENCES folders (id)
            )
        ''')
        
        # ‰∏ä‰º†ËøõÂ∫¶Ë°®ÔºàÁî®‰∫éÊñ≠ÁÇπÁª≠‰º†Ôºâ
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS upload_progress (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                total_size INTEGER,
                uploaded_size INTEGER,
                chunk_size INTEGER,
                checksum TEXT,
                upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # AIÂàÜÊûêÁªìÊûúË°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ai_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_id INTEGER,
                analysis_type TEXT,
                industry_category TEXT,
                extracted_text TEXT,
                key_phrases TEXT,
                summary TEXT,
                confidence_score REAL,
                method TEXT,
                analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (file_id) REFERENCES files (id)
            )
        ''')

        # ËøÅÁßªÔºöËã•ÊóßË°®Êó† method ÂàóÂàôË°•ÂÖÖ
        try:
            cursor.execute("PRAGMA table_info(ai_analysis)")
            cols = [row[1] for row in cursor.fetchall()]
            if 'method' not in cols:
                cursor.execute('ALTER TABLE ai_analysis ADD COLUMN method TEXT')
        except Exception:
            pass
        
        # Ë°å‰∏öÂàÜÁ±ªË°®
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS industry_categories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category_name TEXT UNIQUE,
                keywords TEXT,
                description TEXT,
                created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def init_ai_models(self):
        """ÂàùÂßãÂåñAIÊ®°Âûã"""
        # ÂàùÂßãÂåñË°å‰∏öÂàÜÁ±ªÂÖ≥ÈîÆËØçÔºàAgribusinessÁªÜÂàÜÔºåË°•ÂÖÖÈùûÊ¥≤Â∏∏ËßÅ‰ΩúÁâ©/Ë¶ÅÁ¥†Ôºâ
        self.industry_keywords = {
            "ÁßçÊ§ç‰∏ö": ["‰ΩúÁâ©", "ÁéâÁ±≥", "Â∞èÁ±≥", "È´òÁ≤±", "Ê∞¥Á®ª", "Êú®ËñØ", "Â±±ËçØ", "Á∫¢ËñØ", "Ëä±Áîü", "ËäùÈ∫ª", "ËëµËä±Á±Ω", "Ê£âËä±", "ÂèØÂèØ", "ÂíñÂï°", "Ëå∂Âè∂", "È¶ôËïâ", "ËäíÊûú", "Ëè†Ëêù", "Ëî¨Ëèú", "ÊûúÂõ≠", "‰∫ßÈáè", "Âçï‰∫ß", "ÂÖ¨È°∑", "‰∫©", "Êí≠Áßç", "Êî∂Ëé∑", "ÁÅåÊ∫â", "ÁóÖËô´ÂÆ≥", "Èô§Ëçâ", "ÂØÜÂ∫¶"],
            "ÁïúÁâß‰∏ö": ["ÁîüÁå™", "ÁâõÁæä", "ÂÆ∂Á¶Ω", "Â•∂Áâõ", "Âá∫Ê†è", "Â≠òÊ†è", "È•≤Êñô", "Êó•ÈæÑ", "Â¢ûÈáç", "ÊñôËÇâÊØî", "ÂÖçÁñ´", "ÂÖΩËçØ", "Áñ´ÁóÖ", "ÁπÅËÇ≤", "ÁääÁâõ", "Â±†ÂÆ∞"],
            "ÂÜúËµÑ‰∏éÂúüÂ£§": ["ËÇ•Êñô", "Ê∞ÆËÇ•", "Á£∑ËÇ•", "ÈíæËÇ•", "ÈÖçÊñπÊñΩËÇ•", "ÊúâÊú∫Ë¥®", "pH", "ÂúüÂ£§ÁõêÂàÜ", "ÂæÆÈáèÂÖÉÁ¥†", "‰øùÊ∞¥", "Ë¶ÜÁõñ", "Ê∑±Êùæ", "Áß∏ÁßÜËøòÁî∞"],
            "ÂÜú‰∏öÈáëËûç": ["ÈááË¥≠", "ÊàêÊú¨", "Ë¥∑Ê¨æ", "‰øùÂçï", "‰øùÈô©", "Ëµî‰ªò", "‰øùË¥π", "Êéà‰ø°", "Áé∞ÈáëÊµÅ", "Â∫îÊî∂", "Â∫î‰ªò", "Âà©Ê∂¶", "ÊØõÂà©Áéá", "‰ª∑Ê†º", "ÊúüË¥ß"],
            "‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®": ["ÂÜ∑Èìæ", "‰ªìÂÇ®", "Áâ©ÊµÅ", "ËøêËæì", "Â∫ìÂÆπ", "ÊçüËÄó", "Âë®ËΩ¨", "‰∫§‰ªò", "ËÆ¢Âçï", "ÊâπÊ¨°", "ËøΩÊ∫Ø"],
            "Ê∞îÂÄô‰∏éÈÅ•ÊÑü": ["ÈôçÈõ®", "ÈôçÊ∞¥", "Ê∏©Â∫¶", "ÁßØÊ∏©", "Ëí∏Êï£", "Âπ≤Êó±", "NDVI", "EVI", "Âç´Êòü", "ÈÅ•ÊÑü", "Ê∞îË±°Á´ô", "ËæêÂ∞Ñ", "Ê≤ôÊº†ËùóËô´", "ËçâÂú∞Ë¥™Â§úËõæ"],
            "ÂÜú‰∏öÁâ©ËÅîÁΩë": ["‰º†ÊÑüÂô®", "ÊπøÂ∫¶", "Âê´Ê∞¥Áéá", "EC", "ÈòàÂÄº", "ÈòÄÈó®", "Ê≥µÁ´ô", "Êª¥ÁÅå", "Âñ∑ÁÅå", "Ëá™Âä®Âåñ", "Êä•Ë≠¶"]
        }
        
        # ÂàùÂßãÂåñOCRÊ®°Âûã
        self.ocr_reader = None
        self.ocr_loading = False
        if OCR_AVAILABLE:
            try:
                # ÂºÇÊ≠•Âä†ËΩΩOCRÊ®°ÂûãÔºåÈÅøÂÖçÈòªÂ°ûÁïåÈù¢
                st.info("üîÑ Loading OCR model, please wait...")
                self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])
                st.success("‚úÖ OCR model loaded successfully")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è OCR model loading failed: {str(e)}")
                st.info("üí° Please click 'üîÑ Reload AI' to retry later")
        
        # ÂàùÂßãÂåñÊñáÊú¨ÂàÜÁ±ªÊ®°Âûã
        self.text_classifier = None
        if TRANSFORMERS_AVAILABLE:
            try:
                # ‰ΩøÁî®‰∏≠ÊñáBERTÊ®°ÂûãËøõË°åÊñáÊú¨ÂàÜÁ±ª
                self.text_classifier = pipeline(
                    "text-classification",
                    model="bert-base-chinese",
                    tokenizer="bert-base-chinese"
                )
                st.success("‚úÖ BERT text classification model loaded successfully")
            except Exception as e:
                # Downgrade to info to avoid noisy toast; rules/ML will fallback
                st.info(f"BERT model loading failed, fallback will be used")
        else:
            st.info("‚ÑπÔ∏è Transformers library not installed, using machine learning classification")
        
        # ÂàùÂßãÂåñÊëòË¶ÅÁîüÊàêÊ®°Âûã
        self.summarizer = None
        if TRANSFORMERS_AVAILABLE:
            try:
                # ‰ΩøÁî®T5Ê®°ÂûãËøõË°åÊëòË¶ÅÁîüÊàê
                self.summarizer = pipeline(
                    "summarization",
                    model="t5-small",
                    tokenizer="t5-small"
                )
                st.success("‚úÖ T5 summarization model loaded successfully")
            except Exception as e:
                st.info("T5 summarization not available, using smart rules")
        else:
            st.info("‚ÑπÔ∏è Using smart summarization algorithm")
        
        # ÂàùÂßãÂåñÊú∫Âô®Â≠¶‰π†ÂàÜÁ±ªÂô®
        self.ml_classifier = None
        self.ml_trained = False
        if ML_AVAILABLE:
            try:
                # ‰ΩøÁî®Êú¥Á¥†Ë¥ùÂè∂ÊñØÂàÜÁ±ªÂô®
                self.ml_classifier = Pipeline([
                    ('tfidf', TfidfVectorizer(max_features=1000, stop_words=None)),
                    ('classifier', MultinomialNB())
                ])
                # Ëá™Âä®ÂàùÂßãÂåñÈ¢ÑËÆ≠ÁªÉÂàÜÁ±ªÂô®
                if self.init_pretrained_classifier():
                    st.success("‚úÖ Pre-trained machine learning classifier loaded successfully")
                else:
                    st.info("Pre-trained ML classifier unavailable, using keyword matching")
            except Exception as e:
                st.info("ML classifier init failed, using keyword matching")
        else:
            st.info("‚ÑπÔ∏è ‰ΩøÁî®ÂÖ≥ÈîÆËØçÂåπÈÖçÂàÜÁ±ª")
        
        # ÂàùÂßãÂåñÈªòËÆ§Ë°å‰∏öÂàÜÁ±ª
        self.init_default_categories()

    def fetch_weather_summary(self, latitude: float, longitude: float) -> Dict[str, Any]:
        """‰ªé Open-Meteo Ëé∑ÂèñÊú™Êù•7Â§©ÁöÑÊ∞îË±°ÊëòË¶ÅÔºàÊó†ÈúÄAPIÂØÜÈí•Ôºâ"""
        try:
            url = (
                "https://api.open-meteo.com/v1/forecast"
                f"?latitude={latitude}&longitude={longitude}"
                "&hourly=temperature_2m,precipitation"
                "&daily=precipitation_sum,temperature_2m_max,temperature_2m_min"
                "&forecast_days=7&timezone=auto"
            )
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
            data = resp.json()
            daily = data.get("daily", {})
            result = {
                "location": {"lat": latitude, "lon": longitude},
                "precipitation_sum": daily.get("precipitation_sum", []),
                "tmax": daily.get("temperature_2m_max", []),
                "tmin": daily.get("temperature_2m_min", []),
                "dates": daily.get("time", [])
            }
            # ÁÆÄË¶ÅÁªüËÆ°
            try:
                total_rain = float(sum(x for x in result["precipitation_sum"] if isinstance(x, (int, float))))
            except Exception:
                total_rain = 0.0
            result["summary"] = {
                "7d_total_rain_mm": round(total_rain, 1),
                "avg_tmax": round(sum(result["tmax"]) / max(1, len(result["tmax"])), 1) if result["tmax"] else None,
                "avg_tmin": round(sum(result["tmin"]) / max(1, len(result["tmin"])), 1) if result["tmin"] else None,
            }
            self.latest_weather = result
            return {"success": True, "weather": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def compute_remote_sensing_stub(self, latitude: float, longitude: float, days: int = 30) -> Dict[str, Any]:
        """ÈÅ•ÊÑüÊåáÊï∞Âç†‰ΩçÔºöÁîüÊàêËøëdaysÂ§©ÁöÑNDVI/EVIÁÆÄÊòìÊó∂Â∫èÔºàÊó†ÈúÄÂ§ñÈÉ®ÊúçÂä°Ôºâ„ÄÇ"""
        try:
            import math
            base_date = datetime.now()
            dates = [(base_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days-1, -1, -1)]
            ndvi = []
            evi = []
            for i in range(days):
                # ÁîüÊàêÂπ≥ÊªëÁöÑÊ≥¢Âä®Êï∞ÊçÆÔºåËåÉÂõ¥ÂÅöÁâ©ÁêÜÂêàÁêÜÁ∫¶Êùü
                v = 0.5 + 0.3 * math.sin(i/6.0) + 0.1 * math.sin(i/2.5)
                ndvi.append(round(max(0.0, min(0.9, v)), 3))
                e = 0.4 + 0.25 * math.sin(i/7.0 + 0.5)
                evi.append(round(max(0.0, min(0.8, e)), 3))
            summary = {
                "ndvi_avg": round(sum(ndvi)/len(ndvi), 3) if ndvi else None,
                "evi_avg": round(sum(evi)/len(evi), 3) if evi else None,
                "ndvi_last": ndvi[-1] if ndvi else None,
                "evi_last": evi[-1] if evi else None,
            }
            result = {
                "location": {"lat": latitude, "lon": longitude},
                "dates": dates,
                "ndvi": ndvi,
                "evi": evi,
                "summary": summary,
            }
            self.latest_remote_sensing = result
            return {"success": True, "remote_sensing": result}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def extract_agri_structured_fields(self, text: str) -> Dict[str, Any]:
        """ÂÜú‰∏öÊä•Ë°®Ê®°ÊùøÊäΩÂèñÔºàËßÑÂàôÁâàÂç†‰ΩçÔºâÔºö‰ΩúÁâ©„ÄÅÈù¢ÁßØ„ÄÅÊó•Êúü„ÄÅÊñΩËÇ•/ÁÅåÊ∫â/Áî®ËçØ/Âçï‰∫ßÁ≠â„ÄÇ"""
        if not text:
            return {}
        import re
        fields: Dict[str, Any] = {}
        try:
            # ‰ΩúÁâ©
            m = re.search(r'(‰ΩúÁâ©|ÂìÅÁßç|‰ΩúÁâ©ÂêçÁß∞)[Ôºö:Ôºå]\s*([\u4e00-\u9fffA-Za-z0-9]+)', text)
            if m: fields['‰ΩúÁâ©'] = m.group(2)
            # Èù¢ÁßØÔºà‰∫©/ÂÖ¨È°∑/haÔºâ
            m = re.search(r'(Èù¢ÁßØ|Êí≠ÁßçÈù¢ÁßØ|Êî∂Ëé∑Èù¢ÁßØ)[Ôºö:Ôºå]\s*([\d,.]+)\s*(‰∫©|ÂÖ¨È°∑|ha)', text)
            if m: fields['Èù¢ÁßØ'] = f"{m.group(2)} {m.group(3)}"
            # Êó•ÊúüÔºàÁÆÄÂçïËØÜÂà´ Âπ¥-Êúà-Êó• Êàñ Âπ¥/Êúà/Êó• Êàñ ‰∏≠ÊñáÔºâ
            m = re.search(r'(Êó•Êúü|Êó∂Èó¥|ËÆ∞ÂΩïÊó∂Èó¥)[Ôºö:Ôºå]\s*(\d{4}[-Âπ¥/]\d{1,2}[-Êúà/]\d{1,2})', text)
            if m: fields['Êó•Êúü'] = m.group(2)
            # ÊñΩËÇ•
            m = re.search(r'(ÊñΩËÇ•|ËÇ•Êñô|ÈÖçÊñπÊñΩËÇ•)[Ôºö:Ôºå]?\s*([\u4e00-\u9fffA-Za-z0-9]+)?\s*([\d,.]+)\s*(kg|ÂÖ¨Êñ§|Êñ§)', text)
            if m: fields['ÊñΩËÇ•'] = f"{(m.group(2) or '').strip()} {m.group(3)} {m.group(4)}".strip()
            # ÁÅåÊ∫â
            m = re.search(r'(ÁÅåÊ∫â|ÊµáÊ∞¥)[Ôºö:Ôºå]?\s*([\d,.]+)\s*(mm|Á´ãÊñπ|m3|Êñπ)', text)
            if m: fields['ÁÅåÊ∫â'] = f"{m.group(2)} {m.group(3)}"
            # Áî®ËçØ
            m = re.search(r'(ÂÜúËçØ|Áî®ËçØ|Èò≤Ê≤ª)[Ôºö:Ôºå]?\s*([\u4e00-\u9fffA-Za-z0-9]+)\s*([\d,.]+)\s*(ml|ÊØ´Âçá|L|Âçá|kg|ÂÖã|g)', text)
            if m: fields['Áî®ËçØ'] = f"{m.group(2)} {m.group(3)} {m.group(4)}"
            # Âçï‰∫ß/‰∫ßÈáè
            m = re.search(r'(Âçï‰∫ß|‰∫©‰∫ß)[Ôºö:Ôºå]\s*([\d,.]+)\s*(Êñ§/‰∫©|ÂÖ¨Êñ§/‰∫©|kg/ha|t/ha)', text)
            if m: fields['Âçï‰∫ß'] = f"{m.group(2)} {m.group(3)}"
            m = re.search(r'(ÊÄª‰∫ß|‰∫ßÈáè)[Ôºö:Ôºå]\s*([\d,.]+)\s*(kg|Âê®|t)', text)
            if m: fields['‰∫ßÈáè'] = f"{m.group(2)} {m.group(3)}"
        except Exception:
            pass
        return fields
    
    def init_default_categories(self):
        """ÂàùÂßãÂåñÈªòËÆ§Ë°å‰∏öÂàÜÁ±ª"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for category, keywords in self.industry_keywords.items():
            cursor.execute('''
                INSERT OR IGNORE INTO industry_categories (category_name, keywords, description)
                VALUES (?, ?, ?)
            ''', (category, json.dumps(keywords, ensure_ascii=False), f"{category}Áõ∏ÂÖ≥ÊñáÊ°£"))
        
        conn.commit()
        conn.close()

    def _to_english_category(self, category: str) -> str:
        mapping = {
            "ÁßçÊ§ç‰∏ö": "Planting",
            "ÁïúÁâß‰∏ö": "Livestock",
            "ÂÜúËµÑ‰∏éÂúüÂ£§": "Inputs-Soil",
            "ÂÜú‰∏öÈáëËûç": "Agri-Finance",
            "‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®": "SupplyChain-Storage",
            "Ê∞îÂÄô‰∏éÈÅ•ÊÑü": "Climate-RemoteSensing",
            "ÂÜú‰∏öÁâ©ËÅîÁΩë": "Agri-IoT",
        }
        return mapping.get(category, category)
    
    def generate_smart_report(self, file_id: int) -> Dict[str, Any]:
        """ÁîüÊàêÊô∫ËÉΩÊä•ÂëäÂíåÂõæË°®"""
        try:
            # Ëé∑ÂèñÊñá‰ª∂‰ø°ÊÅØ
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            conn.close()
            
            if not result:
                return {"success": False, "error": "Êñá‰ª∂‰∏çÂ≠òÂú®"}
            
            file_path, file_type, filename = result
            
            # ÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ
            text = self.extract_text_from_file(file_id)
            if not text:
                return {"success": False, "error": "Êó†Ê≥ïÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ"}
            
            # ÂàÜÊûêÊñáÊ°£ÁªìÊûÑ
            analysis = self.analyze_document_structure(text)
            analysis["full_text"] = text
            
            # ÊèêÂèñÊï∞ÊçÆÁÇπ
            data_points = self.extract_data_points(text)
            
            # ÁîüÊàêÂõæË°®
            charts = self.generate_charts(data_points)
            
            # ÁîüÊàêÊä•Âëä
            report = self.create_smart_report(analysis, charts, filename)
            
            return {
                "success": True,
                "analysis": analysis,
                "data_points": data_points,
                "charts": charts,
                "report": report
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def analyze_document_structure(self, text: str) -> Dict[str, Any]:
        """ÂàÜÊûêÊñáÊ°£ÁªìÊûÑÔºåËØÜÂà´ÂÜú‰∏öÈ¢ÜÂüüÊñáÊ°£Á±ªÂûã‰∏éË¶ÅÁ¥†"""
        analysis = {
            "document_type": "Êú™Áü•",
            "data_types": [],
            "key_metrics": [],
            "time_periods": [],
            "categories": [],
            "confidence": 0.0
        }
        
        # ËØÜÂà´ÂÜú‰∏öÊñáÊ°£Á±ªÂûã
        if any(k in text for k in ["Âçï‰∫ß", "‰∫©‰∫ß", "t/ha", "kg/ha", "Êí≠ÁßçÈù¢ÁßØ", "Êî∂Ëé∑Èù¢ÁßØ", "‰∫ßÈáè"]):
            analysis["document_type"] = "ÁßçÊ§ç‰∏öÁîü‰∫ßÊä•Âëä"
            analysis["data_types"].extend(["Èù¢ÁßØ", "‰∫ßÈáè", "Âçï‰∫ß", "Ë∂ãÂäø"])
        elif any(k in text for k in ["Âá∫Ê†è", "Â≠òÊ†è", "Â¢ûÈáç", "Êó•Â¢ûÈáç", "ÊñôËÇâÊØî", "ÂÖçÁñ´"]):
            analysis["document_type"] = "ÁïúÁâß‰∏öÁîü‰∫ßÊä•Âëä"
            analysis["data_types"].extend(["Â§¥Êï∞", "ÈáçÈáè", "ËΩ¨Êç¢Áéá", "ÂÖçÁñ´"])
        elif any(k in text for k in ["ÈôçÈõ®", "ÈôçÊ∞¥", "mm", "ÁßØÊ∏©", "Âπ≤Êó±", "NDVI", "ÈÅ•ÊÑü"]):
            analysis["document_type"] = "Ê∞îÂÄô‰∏éÈÅ•ÊÑüÁõëÊµã"
            analysis["data_types"].extend(["ÈôçÈõ®", "Ê∏©Â∫¶", "ÊåáÊï∞", "Êó∂Èó¥Â∫èÂàó"])
        elif any(k in text for k in ["ÊàêÊú¨", "ÈááË¥≠", "‰ª∑Ê†º", "‰øùÈô©", "Ëµî‰ªò", "Âà©Ê∂¶", "ÊØõÂà©Áéá"]):
            analysis["document_type"] = "ÂÜú‰∏öË¥¢Âä°/‰æõÂ∫îÈìæÊä•Âëä"
            analysis["data_types"].extend(["ÈáëÈ¢ù", "ÊØîÁéá", "ÂØπÊØî", "‰ª∑Ê†ºË∂ãÂäø"])
        
        # ÊèêÂèñÂÖ≥ÈîÆÊåáÊ†á
        import re
        # Êü•ÊâæÊï∞Â≠óÊ®°ÂºèÔºàÊîØÊåÅÂ∏¶Âçï‰ΩçÔºâ
        numbers = re.findall(r'[\d,]+\.?\d*\s*(?:t/ha|kg/ha|kg|t|Âê®|ÂÖ¨Êñ§|ÂÖÉ/Êñ§|ÂÖÉ/Âê®|mm)?', text)
        analysis["key_metrics"] = numbers[:10]  # ÂèñÂâç10‰∏™Êï∞Â≠ó
        
        # Êü•ÊâæÊó∂Èó¥Ê®°Âºè
        time_patterns = re.findall(r'\d{4}Âπ¥|\d{1,2}Êúà|\d{1,2}Êó•|Q[1-4]', text)
        analysis["time_periods"] = list(set(time_patterns))
        
        # Êü•ÊâæÂàÜÁ±ª‰ø°ÊÅØ
        category_patterns = re.findall(r'[A-Za-z\u4e00-\u9fff]+[Ôºö:]\s*[\d,]+', text)
        analysis["categories"] = category_patterns[:5]
        
        # ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶ÔºàÂÜú‰∏öÂú∫ÊôØÁ®çÂæÆÊèêÈ´òÂÖ≥ÈîÆÊåáÊ†áÊùÉÈáçÔºâ
        confidence = min(len(analysis["key_metrics"]) * 0.12 + 
                        len(analysis["time_periods"]) * 0.18 + 
                        len(analysis["categories"]) * 0.1, 1.0)
        analysis["confidence"] = confidence
        
        return analysis
    
    def extract_data_points(self, text: str) -> List[Dict[str, Any]]:
        """ÊèêÂèñÊï∞ÊçÆÁÇπÁî®‰∫éÁîüÊàêÂõæË°®ÔºàÂ¢ûÂº∫ÂÜú‰∏öÂçï‰ΩçËØÜÂà´Ôºâ"""
        data_points = []
        
        import re
        
        # ÊèêÂèñÊï∞ÂÄºÂíåÊ†áÁ≠æ
        patterns = [
            r'([A-Za-z\u4e00-\u9fff]+)[Ôºö:]\s*([\d,]+\.?\d*)\s*(t/ha|kg/ha|kg|t|Âê®|ÂÖ¨Êñ§|mm|%)?',
            r'([A-Za-z\u4e00-\u9fff]+)\s*([\d,]+\.?\d*)\s*(%)',
            r'([A-Za-z\u4e00-\u9fff]+)\s*‰∏∫\s*([\d,]+\.?\d*)\s*(t/ha|kg/ha|kg|t|Âê®|ÂÖ¨Êñ§|mm|%)?'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) == 3:
                    label, value, unit = match
                else:
                    label, value = match
                    unit = None
                try:
                    # Ê∏ÖÁêÜÊï∞ÂÄº
                    clean_value = float(value.replace(',', ''))
                    if clean_value > 0:  # Âè™‰øùÁïôÊ≠£Êï∞
                        data_points.append({
                            "label": label.strip(),
                            "value": clean_value,
                            "type": unit or "Êï∞ÂÄº"
                        })
                except ValueError:
                    continue
        
        # ÂéªÈáçÂπ∂ÊéíÂ∫è
        seen = set()
        unique_points = []
        for point in data_points:
            key = point["label"]
            if key not in seen:
                seen.add(key)
                unique_points.append(point)
        
        # ÊåâÊï∞ÂÄºÊéíÂ∫è
        unique_points.sort(key=lambda x: x["value"], reverse=True)
        
        return unique_points[:10]  # ËøîÂõûÂâç10‰∏™Êï∞ÊçÆÁÇπ
    
    def generate_charts(self, data_points: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ÁîüÊàêÂõæË°®Êï∞ÊçÆ"""
        charts = []
        
        if not data_points:
            return charts
        
        # ÁîüÊàêÊü±Áä∂ÂõæÊï∞ÊçÆ
        if len(data_points) >= 2:
            bar_chart = {
                "type": "bar",
                "title": "Êï∞ÊçÆÂØπÊØîÊü±Áä∂Âõæ",
                "data": {
                    "labels": [point["label"] for point in data_points[:8]],
                    "values": [point["value"] for point in data_points[:8]]
                }
            }
            charts.append(bar_chart)
        
        # ÁîüÊàêÈ•ºÂõæÊï∞ÊçÆÔºàÂâç5‰∏™Ôºâ
        if len(data_points) >= 3:
            pie_data = data_points[:5]
            total = sum(point["value"] for point in pie_data)
            pie_chart = {
                "type": "pie",
                "title": "Êï∞ÊçÆÂàÜÂ∏ÉÈ•ºÂõæ",
                "data": {
                    "labels": [point["label"] for point in pie_data],
                    "values": [point["value"] for point in pie_data],
                    "percentages": [round(point["value"]/total*100, 1) for point in pie_data]
                }
            }
            charts.append(pie_chart)
        
        # ÁîüÊàêË∂ãÂäøÂõæÔºàÂ¶ÇÊûúÊúâÊó∂Èó¥Êï∞ÊçÆÔºâ
        if len(data_points) >= 4:
            line_chart = {
                "type": "line",
                "title": "Êï∞ÊçÆË∂ãÂäøÂõæ",
                "data": {
                    "labels": [point["label"] for point in data_points[:6]],
                    "values": [point["value"] for point in data_points[:6]]
                }
            }
            charts.append(line_chart)
        
        return charts
    
    def create_smart_report(self, analysis: Dict, charts: List[Dict], filename: str) -> str:
        """ÁîüÊàêÊô∫ËÉΩÊä•ÂëäÔºàÂä†ÂÖ•ÂÜú‰∏öÊ¥ûÂØü‰∏éKPIÔºâ"""
        report = f"# üìä Agribusiness Smart Analysis Report\n\n"
        report += f"**File name**: {filename}\n\n"
        report += f"**Document type**: {analysis['document_type']}\n\n"
        report += f"**Confidence**: {analysis['confidence']:.1%}\n\n"
        
        # ÂÜú‰∏öKPIÔºà‰ªéÂÖ®ÊñáÊô∫ËÉΩÊèêÂèñÔºâ
        agrikpis = self.compute_agribusiness_kpis(analysis.get('full_text', '')) if isinstance(analysis, dict) else {}
        if agrikpis:
            report += "## üåæ Agribusiness KPIs\n\n"
            for k, v in agrikpis.items():
                report += f"- {k}: {v}\n"
            report += "\n"

        # Â§©Ê∞îÊëòË¶ÅÔºàÂ¶ÇÊûúÂ∑≤Ëé∑ÂèñÔºâ
        if getattr(self, 'latest_weather', None):
            ws = self.latest_weather.get('summary', {})
            report += "## ‚òÅÔ∏è Climate summary (next 7 days)\n\n"
            if ws:
                if ws.get('7d_total_rain_mm') is not None:
                    report += f"- Total rainfall: {ws['7d_total_rain_mm']} mm\n"
                if ws.get('avg_tmax') is not None:
                    report += f"- Avg Tmax: {ws['avg_tmax']} ¬∞C\n"
                if ws.get('avg_tmin') is not None:
                    report += f"- Avg Tmin: {ws['avg_tmin']} ¬∞C\n"
            report += "\n"

        # ÈÅ•ÊÑüÊëòË¶ÅÔºàÂ¶ÇÊûúÂ∑≤Ëé∑ÂèñÔºâ
        if getattr(self, 'latest_remote_sensing', None):
            rs = self.latest_remote_sensing.get('summary', {})
            report += "## üõ∞Ô∏è Remote sensing summary\n\n"
            if rs:
                if rs.get('ndvi_avg') is not None:
                    report += f"- NDVI average: {rs['ndvi_avg']}\n"
                if rs.get('evi_avg') is not None:
                    report += f"- EVI average: {rs['evi_avg']}\n"
                if rs.get('ndvi_last') is not None:
                    report += f"- Latest NDVI: {rs['ndvi_last']}\n"
                if rs.get('evi_last') is not None:
                    report += f"- Latest EVI: {rs['evi_last']}\n"
            report += "\n"

        # Ê®°ÊùøÊäΩÂèñÁªìÊûú
        structured = self.extract_agri_structured_fields(analysis.get('full_text', '')) if isinstance(analysis, dict) else {}
        if structured:
            report += "## üóÇÔ∏è Structured fields (template extraction)\n\n"
            for k, v in structured.items():
                report += f"- {k}: {v}\n"
            report += "\n"
        
        # Key metrics
        if analysis['key_metrics']:
            report += "## üî¢ Key metrics\n\n"
            for i, metric in enumerate(analysis['key_metrics'][:5], 1):
                report += f"{i}. {metric}\n"
            report += "\n"

        # Time periods
        if analysis['time_periods']:
            report += "## üìÖ Time periods\n\n"
            report += f"Detected time info: {', '.join(analysis['time_periods'])}\n\n"

        # Categories
        if analysis['categories']:
            report += "## üìã Categories\n\n"
            for category in analysis['categories']:
                report += f"- {category}\n"
            report += "\n"

        # Visualization notes
        if charts:
            report += "## üìà Data visualization\n\n"
            for chart in charts:
                report += f"### {chart['title']}\n\n"
                if chart['type'] == 'bar':
                    report += "Bar chart shows value comparison across categories to spot highs and lows.\n\n"
                elif chart['type'] == 'pie':
                    report += "Pie chart shows proportion distribution for intuitive share comparison.\n\n"
                elif chart['type'] == 'line':
                    report += "Line chart shows temporal trends to identify growth or decline patterns.\n\n"

        # Suggestions
        report += "## üí° Suggestions\n\n"
        if analysis['document_type'] in ["ÁßçÊ§ç‰∏öÁîü‰∫ßÊä•Âëä", "ÁïúÁâß‰∏öÁîü‰∫ßÊä•Âëä"]:
            report += "- Track trends of key KPIs (yield, rainfall, FCR).\n"
            report += "- Compare fields/lots or herds to find outliers.\n"
            report += "- Plan interventions (fertigation, pest control) based on thresholds.\n"
        elif analysis['document_type'] in ["ÂÜú‰∏öË¥¢Âä°/‰æõÂ∫îÈìæÊä•Âëä"]:
            report += "- Monitor margins and price trends.\n"
            report += "- Optimize cost structure and inventory turnover.\n"
            report += "- Manage risk with insurance/hedging where applicable.\n"
        else:
            report += "- Keep data updated regularly.\n"
            report += "- Focus on KPI trends and anomalies.\n"
            report += "- Apply data-driven decisions.\n"
        
        return report

    def compute_agribusiness_kpis(self, text: str) -> Dict[str, Any]:
        """Âü∫‰∫éËßÑÂàôÂø´ÈÄüÊèêÂèñÂÜú‰∏öÂ∏∏ËßÅKPIÔºàËΩªÈáèÂç†‰ΩçÔºåÂèØÂêéÁª≠Êç¢Ê®°ÂûãÔºâ"""
        if not text:
            return {}
        import re
        kpis: Dict[str, Any] = {}
        try:
            # Âçï‰∫ßÔºàÊîØÊåÅ kg/ha, t/ha, ‰∫©‰∫ßÔºâ
            m = re.search(r'(Âçï‰∫ß|‰∫©‰∫ß)[:Ôºö]?\s*([\d,.]+)\s*(kg/ha|t/ha|ÂÖ¨Êñ§/‰∫©|Êñ§/‰∫©|Âê®/ÂÖ¨È°∑)?', text)
            if m:
                kpis['Âçï‰∫ß'] = f"{m.group(2)} {m.group(3) or ''}".strip()

            # Èù¢ÁßØÔºà‰∫©„ÄÅÂÖ¨È°∑Ôºâ
            m = re.search(r'(Êí≠ÁßçÈù¢ÁßØ|Êî∂Ëé∑Èù¢ÁßØ|Èù¢ÁßØ)[:Ôºö]?\s*([\d,.]+)\s*(‰∫©|ÂÖ¨È°∑|ha)', text)
            if m:
                kpis['Èù¢ÁßØ'] = f"{m.group(2)} {m.group(3)}"

            # ÈôçÈõ®ÈáèÔºàmmÔºâ
            m = re.search(r'(ÈôçÈõ®|ÈôçÊ∞¥|Á¥ØËÆ°ÈôçÈõ®|Á¥ØËÆ°ÈôçÊ∞¥)[:Ôºö]?\s*([\d,.]+)\s*mm', text)
            if m:
                kpis['Á¥ØËÆ°ÈôçÈõ®'] = f"{m.group(2)} mm"

            # ÊàêÊú¨‰∏éÂà©Ê∂¶
            m = re.search(r'(ÊÄªÊàêÊú¨|ÊàêÊú¨)[:Ôºö]?\s*([\d,.]+)', text)
            if m:
                kpis['ÊàêÊú¨'] = m.group(2)
            m = re.search(r'(Âà©Ê∂¶|ÊØõÂà©|ÊØõÂà©Áéá)[:Ôºö]?\s*([\d,.]+)\s*(%)?', text)
            if m:
                kpis['Âà©Ê∂¶/ÊØõÂà©'] = f"{m.group(2)}{m.group(3) or ''}"

            # ÁïúÁâßÂÖ≥ÈîÆÊåáÊ†á
            m = re.search(r'(Âá∫Ê†è|Â≠òÊ†è)[:Ôºö]?\s*([\d,.]+)\s*(Â§¥|Âè™)?', text)
            if m:
                kpis[m.group(1)] = f"{m.group(2)} {m.group(3) or ''}".strip()
            m = re.search(r'(ÊñôËÇâÊØî|FCR)[:Ôºö]?\s*([\d,.]+)', text)
            if m:
                kpis['ÊñôËÇâÊØî'] = m.group(2)

            # ÈÅ•ÊÑüÊåáÊï∞
            m = re.search(r'(NDVI|EVI)[:Ôºö]?\s*([\d,.]+)', text)
            if m:
                kpis[m.group(1)] = m.group(2)
        except Exception:
            pass
        return kpis
    
    def calculate_checksum(self, file_path: str) -> str:
        """ËÆ°ÁÆóÊñá‰ª∂Ê†°È™åÂíå"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def get_file_type(self, filename: str) -> str:
        """Ëé∑ÂèñÊñá‰ª∂Á±ªÂûã"""
        mime_type, _ = mimetypes.guess_type(filename)
        if mime_type:
            return mime_type.split('/')[0]
        return 'unknown'
    
    def upload_file(self, uploaded_file, folder_id: Optional[int] = None) -> Dict[str, Any]:
        """‰∏ä‰º†Êñá‰ª∂"""
        try:
            # ÁîüÊàêÂîØ‰∏ÄÊñá‰ª∂Âêç
            timestamp = int(time.time())
            filename = f"{timestamp}_{uploaded_file.name}"
            file_path = self.storage_dir / filename
            
            # ‰øùÂ≠òÊñá‰ª∂
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # ËÆ°ÁÆóÊñá‰ª∂‰ø°ÊÅØ
            file_size = file_path.stat().st_size
            checksum = self.calculate_checksum(str(file_path))
            file_type = self.get_file_type(uploaded_file.name)
            
            # ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO files (filename, file_path, file_size, file_type, folder_id, checksum)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (uploaded_file.name, str(file_path), file_size, file_type, folder_id, checksum))
            conn.commit()
            conn.close()
            
            return {
                "success": True,
                "filename": uploaded_file.name,
                "file_size": file_size,
                "file_type": file_type
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_files(self, folder_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """Ëé∑ÂèñÊñá‰ª∂ÂàóË°®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if folder_id is None:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files WHERE folder_id IS NULL
                ORDER BY upload_time DESC
            ''')
        else:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files WHERE folder_id = ?
                ORDER BY upload_time DESC
            ''', (folder_id,))
        
        files = []
        for row in cursor.fetchall():
            files.append({
                "id": row[0],
                "filename": row[1],
                "file_size": row[2],
                "file_type": row[3],
                "upload_time": row[4],
                "is_cached": bool(row[5])
            })
        
        conn.close()
        return files
    
    def create_folder(self, folder_name: str, parent_folder_id: Optional[int] = None) -> Dict[str, Any]:
        """ÂàõÂª∫Êñá‰ª∂Â§π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO folders (folder_name, parent_folder_id)
                VALUES (?, ?)
            ''', (folder_name, parent_folder_id))
            conn.commit()
            folder_id = cursor.lastrowid
            conn.close()
            
            return {"success": True, "folder_id": folder_id}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def search_files(self, query: str, file_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """ÊêúÁ¥¢Êñá‰ª∂"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if file_type:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files 
                WHERE filename LIKE ? AND file_type = ?
                ORDER BY upload_time DESC
            ''', (f"%{query}%", file_type))
        else:
            cursor.execute('''
                SELECT id, filename, file_size, file_type, upload_time, is_cached
                FROM files 
                WHERE filename LIKE ?
                ORDER BY upload_time DESC
            ''', (f"%{query}%",))
        
        files = []
        for row in cursor.fetchall():
            files.append({
                "id": row[0],
                "filename": row[1],
                "file_size": row[2],
                "file_type": row[3],
                "upload_time": row[4],
                "is_cached": bool(row[5])
            })
        
        conn.close()
        return files
    
    def preview_file(self, file_id: int) -> Optional[bytes]:
        """È¢ÑËßàÊñá‰ª∂"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT file_path, file_type FROM files WHERE id = ?', (file_id,))
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return None
        
        file_path, file_type = result
        
        try:
            with open(file_path, 'rb') as f:
                return f.read()
        except:
            return None
    
    def cache_file(self, file_id: int) -> bool:
        """ÁºìÂ≠òÊñá‰ª∂Âà∞Êú¨Âú∞"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT file_path, filename FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            
            if result:
                file_path, filename = result
                cache_path = self.cache_dir / filename
                shutil.copy2(file_path, cache_path)
                
                # Êõ¥Êñ∞Êï∞ÊçÆÂ∫ì
                cursor.execute('UPDATE files SET is_cached = TRUE WHERE id = ?', (file_id,))
                conn.commit()
                conn.close()
                return True
        except:
            pass
        return False
    
    def format_file_size(self, size_bytes: int) -> str:
        """Ê†ºÂºèÂåñÊñá‰ª∂Â§ßÂ∞è"""
        if size_bytes == 0:
            return "0B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1
        return f"{size_bytes:.1f}{size_names[i]}"
    
    def get_file_icon(self, file_type: str) -> str:
        """Ëé∑ÂèñÊñá‰ª∂Á±ªÂûãÂõæÊ†á - ÁôæÂ∫¶‰∫ëÁõòÈ£éÊ†º"""
        icons = {
            'image': 'üñºÔ∏è',
            'application': 'üìÑ',
            'text': 'üìù',
            'video': 'üé•',
            'audio': 'üéµ',
            'unknown': 'üìÅ',
            'pdf': 'üìï',
            'excel': 'üìä',
            'word': 'üìù',
            'ppt': 'üìΩÔ∏è',
            'zip': 'üì¶',
            'code': 'üíª'
        }
        return icons.get(file_type, 'üìÅ')
    
    def get_file_color_class(self, file_type: str) -> str:
        """Ëé∑ÂèñÊñá‰ª∂Á±ªÂûãÈ¢úËâ≤Á±ª"""
        color_map = {
            'image': 'file-type-image',
            'application': 'file-type-document',
            'text': 'file-type-text',
            'video': 'file-type-video',
            'audio': 'file-type-audio',
            'pdf': 'file-type-document',
            'excel': 'file-type-document',
            'word': 'file-type-document',
            'ppt': 'file-type-document',
            'zip': 'file-type-document',
            'code': 'file-type-text'
        }
        return color_map.get(file_type, '')
    
    def upload_file_with_resume(self, uploaded_file, folder_id: Optional[int] = None, chunk_size: int = 1024*1024) -> Dict[str, Any]:
        """Â∏¶Êñ≠ÁÇπÁª≠‰º†ÁöÑÊñá‰ª∂‰∏ä‰º†"""
        try:
            filename = uploaded_file.name
            file_size = len(uploaded_file.getbuffer())
            
            # Ê£ÄÊü•ÊòØÂê¶ÊúâÊú™ÂÆåÊàêÁöÑ‰∏ä‰º†
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                SELECT id, uploaded_size, checksum FROM upload_progress 
                WHERE filename = ? AND total_size = ?
                ORDER BY upload_time DESC LIMIT 1
            ''', (filename, file_size))
            
            progress_record = cursor.fetchone()
            
            if progress_record:
                # Êñ≠ÁÇπÁª≠‰º†
                progress_id, uploaded_size, stored_checksum = progress_record
                st.info(f"üîÑ Resumable upload found, continue from {uploaded_size} bytes...")
            else:
                # Êñ∞‰∏ä‰º†
                uploaded_size = 0
                progress_id = None
                stored_checksum = None
            
            # ÂàÜÂùó‰∏ä‰º†
            uploaded_file.seek(uploaded_size)
            current_size = uploaded_size
            
            progress_bar = st.progress(uploaded_size / file_size)
            status_text = st.empty()
            
            while current_size < file_size:
                chunk = uploaded_file.read(min(chunk_size, file_size - current_size))
                if not chunk:
                    break
                
                # ËøôÈáåÂ∫îËØ•Â∞ÜchunkÂèëÈÄÅÂà∞ÊúçÂä°Âô®
                # ‰∏∫‰∫ÜÊºîÁ§∫ÔºåÊàë‰ª¨Áõ¥Êé•ÂÜôÂÖ•Êú¨Âú∞Êñá‰ª∂
                temp_file_path = self.storage_dir / f"temp_{filename}"
                with open(temp_file_path, "ab") as f:
                    f.write(chunk)
                
                current_size += len(chunk)
                progress = current_size / file_size
                progress_bar.progress(progress)
                status_text.text(f"Uploading: {current_size}/{file_size} bytes ({progress*100:.1f}%)")
                
                # Êõ¥Êñ∞ËøõÂ∫¶Âà∞Êï∞ÊçÆÂ∫ì
                if progress_id:
                    cursor.execute('''
                        UPDATE upload_progress 
                        SET uploaded_size = ? 
                        WHERE id = ?
                    ''', (current_size, progress_id))
                else:
                    cursor.execute('''
                        INSERT INTO upload_progress (filename, total_size, uploaded_size, chunk_size, checksum)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (filename, file_size, current_size, chunk_size, stored_checksum))
                    progress_id = cursor.lastrowid
                
                conn.commit()
                
                # Ê®°ÊãüÁΩëÁªúÂª∂Ëøü
                time.sleep(0.1)
            
            # ‰∏ä‰º†ÂÆåÊàêÔºåÁßªÂä®Êñá‰ª∂Âà∞ÊúÄÁªà‰ΩçÁΩÆ
            final_file_path = self.storage_dir / f"{int(time.time())}_{filename}"
            shutil.move(str(temp_file_path), str(final_file_path))
            
            # ËÆ°ÁÆóÊ†°È™åÂíå
            checksum = self.calculate_checksum(str(final_file_path))
            file_type = self.get_file_type(filename)
            
            # ‰øùÂ≠òÊñá‰ª∂‰ø°ÊÅØÂà∞Êï∞ÊçÆÂ∫ì
            cursor.execute('''
                INSERT INTO files (filename, file_path, file_size, file_type, folder_id, checksum)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (filename, str(final_file_path), file_size, file_type, folder_id, checksum))
            
            # Âà†Èô§ËøõÂ∫¶ËÆ∞ÂΩï
            if progress_id:
                cursor.execute('DELETE FROM upload_progress WHERE id = ?', (progress_id,))
            
            conn.commit()
            conn.close()
            
            progress_bar.empty()
            status_text.empty()
            
            return {
                "success": True,
                "filename": filename,
                "file_size": file_size,
                "file_type": file_type,
                "checksum": checksum
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_upload_progress(self) -> List[Dict[str, Any]]:
        """Ëé∑Âèñ‰∏ä‰º†ËøõÂ∫¶ÂàóË°®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT filename, total_size, uploaded_size, upload_time
            FROM upload_progress
            ORDER BY upload_time DESC
        ''')
        
        progress_list = []
        for row in cursor.fetchall():
            filename, total_size, uploaded_size, upload_time = row
            progress_list.append({
                "filename": filename,
                "total_size": total_size,
                "uploaded_size": uploaded_size,
                "progress": uploaded_size / total_size if total_size > 0 else 0,
                "upload_time": upload_time
            })
        
        conn.close()
        return progress_list
    
    def resume_upload(self, filename: str) -> Dict[str, Any]:
        """ÊÅ¢Â§ç‰∏ä‰º†"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, total_size, uploaded_size, chunk_size, checksum
            FROM upload_progress 
            WHERE filename = ?
            ORDER BY upload_time DESC LIMIT 1
        ''', (filename,))
        
        result = cursor.fetchone()
        if result:
            progress_id, total_size, uploaded_size, chunk_size, checksum = result
            return {
                "success": True,
                "progress_id": progress_id,
                "total_size": total_size,
                "uploaded_size": uploaded_size,
                "chunk_size": chunk_size,
                "checksum": checksum
            }
        else:
            return {"success": False, "error": "Êú™ÊâæÂà∞‰∏ä‰º†ËøõÂ∫¶ËÆ∞ÂΩï"}
    
    def cancel_upload(self, filename: str) -> bool:
        """ÂèñÊ∂à‰∏ä‰º†"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('DELETE FROM upload_progress WHERE filename = ?', (filename,))
            conn.commit()
            conn.close()
            return True
        except:
            return False
    
    # ==================== AIÂäüËÉΩÊñπÊ≥ï ====================
    
    def extract_text_from_file(self, file_id: int) -> str:
        """‰ªéÊñá‰ª∂‰∏≠ÊèêÂèñÊñáÊú¨ÂÜÖÂÆπ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT file_path, file_type, filename FROM files WHERE id = ?', (file_id,))
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return ""
        
        file_path, file_type, filename = result
        extracted_text = ""
        
        try:
            if file_type == 'text' or filename.endswith('.txt'):
                # ÊñáÊú¨Êñá‰ª∂
                with open(file_path, 'r', encoding='utf-8') as f:
                    extracted_text = f.read()
            
            elif file_type == 'application' and filename.endswith('.pdf'):
                # PDFÊñá‰ª∂
                if PDF_AVAILABLE:
                    doc = fitz.open(file_path)
                    for page in doc:
                        extracted_text += page.get_text()
                    doc.close()
                # Ëã•‰∏çÂèØÁî®Âàô‰øùÊåÅ‰∏∫Á©∫ÔºåÂêéÁª≠ÁªôÂá∫ÂèãÂ•ΩÂç†‰Ωç
            
            elif file_type == 'application' and filename.endswith(('.xlsx', '.xls')):
                # ExcelÊñá‰ª∂
                try:
                    df = pd.read_excel(file_path)
                    # Á°Æ‰øùDataFrame‰∏ç‰∏∫Á©∫
                    if not df.empty:
                        # ÂÆâÂÖ®Âú∞ËΩ¨Êç¢‰∏∫Â≠óÁ¨¶‰∏≤ÔºåÈÅøÂÖçnumpy.str_ÈîôËØØ
                        try:
                            extracted_text = df.to_string()
                        except Exception as str_error:
                            # Â¶ÇÊûúto_stringÂ§±Ë¥•ÔºåÂ∞ùËØïÂÖ∂‰ªñÊñπÊ≥ï
                            extracted_text = str(df.values.tolist())
                    else:
                        extracted_text = "Excel file is empty"
                except Exception as e:
                    st.warning(f"Excel reading failed: {str(e)}")
                    extracted_text = ""

            elif filename.endswith('.csv'):
                # CSVÊñá‰ª∂
                try:
                    df = pd.read_csv(file_path)
                    if not df.empty:
                        try:
                            extracted_text = df.to_string()
                        except Exception:
                            extracted_text = str(df.values.tolist())
                    else:
                        extracted_text = "CSV file is empty"
                except Exception as e:
                    st.warning(f"CSV reading failed: {str(e)}")
                    extracted_text = ""

            elif filename.endswith('.docx'):
                # DOCXÔºàÂèØÈÄâÂ§ÑÁêÜÔºâ
                try:
                    import docx  # type: ignore
                    doc = docx.Document(file_path)
                    paras = [p.text for p in doc.paragraphs if p.text]
                    extracted_text = "\n".join(paras)
                except Exception:
                    # Êú™ÂÆâË£ÖÊàñËß£ÊûêÂ§±Ë¥•ÂàôÂøΩÁï•
                    pass
            
            elif file_type == 'image':
                # ÂõæÁâáÊñá‰ª∂ - OCRËØÜÂà´
                if OCR_AVAILABLE:
                    if self.ocr_reader is None:
                        # Âª∂ËøüÂä†ËΩΩOCRÊ®°Âûã
                        st.info("üîÑ Loading OCR model, please wait...")
                        try:
                            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])
                            st.success("‚úÖ OCR model loaded")
                        except Exception as e:
                            st.error(f"OCR model load failed: {str(e)}")
                            return ""
                    
                    if self.ocr_reader:
                        results = self.ocr_reader.readtext(file_path)
                        extracted_text = ' '.join([result[1] for result in results])
        
        except Exception as e:
            st.error(f"Text extraction failed: {str(e)}")
        
        # ÂÖúÂ∫ïÔºö‰ªçÊó†Ê≥ïÊèêÂèñÊñáÊú¨Êó∂ÔºåËøîÂõûÂç†‰ΩçÊñáÊú¨ÔºåÈÅøÂÖçAIÊµÅÁ®ãÁõ¥Êé•Â§±Ë¥•
        if not extracted_text:
            extracted_text = f"(No extractable text from file: {filename}. Try preview/download.)"
        
        return extracted_text
    
    def classify_industry(self, text: str) -> Dict[str, Any]:
        """‰ΩøÁî®ÁúüÊ≠£ÁöÑAIÂØπÊñáÊ°£ËøõË°åË°å‰∏öÂàÜÁ±ª"""
        if not text:
            return {"category": "Êú™ÂàÜÁ±ª", "confidence": 0.0, "keywords": []}
        
        # ÊñπÊ≥ï1: ‰ΩøÁî®BERTÊ®°ÂûãÂàÜÁ±ªÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if self.text_classifier and len(text) > 10:
            try:
                # Êà™ÂèñÊñáÊú¨Ââç512‰∏™Â≠óÁ¨¶ÔºàBERTÈôêÂà∂Ôºâ
                text_sample = text[:512]
                result = self.text_classifier(text_sample)
                
                # Â∞ÜBERTÁªìÊûúÊò†Â∞ÑÂà∞Êàë‰ª¨ÁöÑË°å‰∏öÂàÜÁ±ª
                bert_label = result[0]['label']
                bert_confidence = result[0]['score']
                
                # ÁÆÄÂçïÁöÑÊ†áÁ≠æÊò†Â∞ÑÔºàÂèØ‰ª•Ê†πÊçÆÈúÄË¶ÅÊâ©Â±ïÔºâ
                label_mapping = {
                    'LABEL_0': 'ÁßçÊ§ç‰∏ö',
                    'LABEL_1': 'ÁïúÁâß‰∏ö',
                    'LABEL_2': 'ÂÜúËµÑ‰∏éÂúüÂ£§',
                    'LABEL_3': 'ÂÜú‰∏öÈáëËûç',
                    'LABEL_4': '‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®',
                    'LABEL_5': 'Ê∞îÂÄô‰∏éÈÅ•ÊÑü',
                    'LABEL_6': 'ÂÜú‰∏öÁâ©ËÅîÁΩë'
                }
                
                mapped_category = label_mapping.get(bert_label, 'Êú™ÂàÜÁ±ª')
                
                if mapped_category != 'Êú™ÂàÜÁ±ª':
                    return {
                        "category": mapped_category,
                        "confidence": bert_confidence,
                        "keywords": self._extract_keywords_from_text(text),
                        "method": "BERT"
                    }
            except Exception as e:
                # Suppress noisy toast; fallback methods will be tried below
                pass
        
        # ÊñπÊ≥ï2: ‰ΩøÁî®Êú∫Âô®Â≠¶‰π†ÂàÜÁ±ªÂô®ÔºàÂ¶ÇÊûúÂèØÁî®‰∏îÂ∑≤ËÆ≠ÁªÉÔºâ
        if self.ml_classifier and self.ml_trained and len(text) > 20:
            try:
                X = [text]
                y_pred = self.ml_classifier.predict(X)
                y_proba = self.ml_classifier.predict_proba(X)
                
                categories = list(self.industry_keywords.keys())
                predicted_category = categories[y_pred[0]]
                confidence = y_proba[0].max()
                
                return {
                    "category": predicted_category,
                    "confidence": confidence,
                    "keywords": self._extract_keywords_from_text(text),
                    "method": "ML"
                }
            except Exception as e:
                # Suppress noisy toast; fallback to rules
                pass
        
        # ÊñπÊ≥ï3: Êô∫ËÉΩÂÖ≥ÈîÆËØçÂåπÈÖçÔºàÊîπËøõÁâàÔºâ
        words = jieba.lcut(text)
        category_scores = {}
        matched_keywords = {}
        
        for category, keywords in self.industry_keywords.items():
            score = 0
            matched = []
            
            # Âü∫Á°ÄÂÖ≥ÈîÆËØçÂåπÈÖç
            for keyword in keywords:
                if keyword in text:
                    score += 1
                    matched.append(keyword)
            
            # Âêå‰πâËØçÂíåÁõ∏‰ººËØçÂåπÈÖç
            synonyms = self._get_synonyms(category)
            for synonym in synonyms:
                if synonym in text:
                    score += 0.5
                    matched.append(synonym)
            
            # ËØçÈ¢ëÊùÉÈáç
            for keyword in keywords:
                count = text.count(keyword)
                if count > 1:
                    score += count * 0.2
            
            category_scores[category] = score
            matched_keywords[category] = matched
        
        if category_scores and max(category_scores.values()) > 0:
            best_category = max(category_scores, key=category_scores.get)
            max_score = category_scores[best_category]
            
            # ÊîπËøõÁöÑÁΩÆ‰ø°Â∫¶ËÆ°ÁÆó
            total_keywords = len(self.industry_keywords[best_category])
            confidence = min(max_score / (total_keywords * 1.5), 1.0)
            
            # Â¶ÇÊûúÁΩÆ‰ø°Â∫¶Â§™‰ΩéÔºåÊ†áËÆ∞‰∏∫Êú™ÂàÜÁ±ª
            if confidence < 0.1:
                return {"category": "Êú™ÂàÜÁ±ª", "confidence": 0.0, "keywords": [], "method": "ÂÖ≥ÈîÆËØçÂåπÈÖç"}
            
            return {
                "category": best_category,
                "confidence": confidence,
                "keywords": matched_keywords[best_category],
                "method": "Êô∫ËÉΩÂÖ≥ÈîÆËØçÂåπÈÖç"
            }
        
        return {"category": "Êú™ÂàÜÁ±ª", "confidence": 0.0, "keywords": [], "method": "Êó†ÂåπÈÖç"}
    
    def _get_synonyms(self, category: str) -> List[str]:
        """Ëé∑ÂèñË°å‰∏öÂàÜÁ±ªÁöÑÂêå‰πâËØç"""
        synonyms_map = {
            "ÁßçÊ§ç‰∏ö": ["ÁßçÊ§ç", "ËÄï‰Ωú", "ËÇ≤Áßß", "ÁßªÊ†Ω", "ÂØÜÊ§ç", "ÁóÖËô´ÂÆ≥", "ÊñΩËÇ•", "ÁÅåÊ∫â", "Áî∞Èó¥ÁÆ°ÁêÜ", "ÁéâÁ±≥", "È´òÁ≤±", "Â∞èÁ±≥", "Êú®ËñØ", "Ëä±Áîü", "ËäùÈ∫ª", "Ê£âËä±", "ÂèØÂèØ", "ÂíñÂï°"],
            "ÁïúÁâß‰∏ö": ["ÂÖªÊÆñ", "È•≤ÂñÇ", "ÂÖçÁñ´", "Èò≤Áñ´", "ÁπÅËÇ≤", "Êñ≠Â•∂", "Âá∫Ê†è", "Â≠òÊ†è", "Â¢ûÈáç"],
            "ÂÜúËµÑ‰∏éÂúüÂ£§": ["ÈÖçÊñπÊñΩËÇ•", "ÂúüÂ£§ÊîπËâØ", "ÊñΩÁî®Èáè", "ÊúâÊú∫ËÇ•", "ÂæÆÈáèÂÖÉÁ¥†", "ÂúüÂ£§ÂÖªÂàÜ"],
            "ÂÜú‰∏öÈáëËûç": ["Ë¥¥Áé∞", "Êéà‰ø°", "‰øùË¥π", "Ëµî‰ªò", "Êâø‰øù", "È£éÊéß", "‰øùÂçï"],
            "‰æõÂ∫îÈìæ‰∏é‰ªìÂÇ®": ["ÂÜ∑ÈìæËøêËæì", "ÊçüËÄóÁéá", "ÊâπÊ¨°ËøΩÊ∫Ø", "Â∫ìÂÆπ", "Âë®ËΩ¨Áéá", "ÂàÜÊã£"],
            "Ê∞îÂÄô‰∏éÈÅ•ÊÑü": ["ÈôçÈõ®", "Ê∞îÊ∏©", "ÁßØÊ∏©", "Âπ≤Êó±ÊåáÊï∞", "NDVI", "EVI", "ÈÅ•ÊÑü", "Ê≤ôÊº†ËùóËô´", "ËçâÂú∞Ë¥™Â§úËõæ"],
            "ÂÜú‰∏öÁâ©ËÅîÁΩë": ["Âê´Ê∞¥Áéá", "EC", "Êª¥ÁÅå", "Âñ∑ÁÅå", "ÈòÄÈó®", "ÈòàÂÄº", "Êä•Ë≠¶"]
        }
        return synonyms_map.get(category, [])
    
    def init_pretrained_classifier(self):
        """ÂàùÂßãÂåñÈ¢ÑËÆ≠ÁªÉÁöÑÂàÜÁ±ªÂô®"""
        if not self.ml_classifier:
            return False
        
        try:
            # ‰ΩøÁî®È¢ÑÂÆö‰πâÁöÑÂÖ≥ÈîÆËØç‰Ωú‰∏∫ÁâπÂæÅËøõË°åËÆ≠ÁªÉ
            X_train = []
            y_train = []
            
            # ‰∏∫ÊØè‰∏™Ë°å‰∏öÁ±ªÂà´ÂàõÂª∫ËÆ≠ÁªÉÊ†∑Êú¨
            for category, keywords in self.industry_keywords.items():
                # ‰∏∫ÊØè‰∏™ÂÖ≥ÈîÆËØçÂàõÂª∫ËÆ≠ÁªÉÊ†∑Êú¨
                for keyword in keywords:
                    # ÂàõÂª∫ÂåÖÂê´ÂÖ≥ÈîÆËØçÁöÑÊ†∑Êú¨ÊñáÊú¨
                    sample_text = f"ËøôÊòØ‰∏Ä‰∏™ÂÖ≥‰∫é{keyword}ÁöÑÊñáÊ°£ÔºåÊ∂âÂèä{category}È¢ÜÂüüÁöÑÂÜÖÂÆπ„ÄÇ"
                    X_train.append(sample_text)
                    y_train.append(category)
                
                # Ê∑ªÂä†Âêå‰πâËØçÊ†∑Êú¨
                synonyms = self._get_synonyms(category)
                for synonym in synonyms:
                    sample_text = f"ËøôÊòØ‰∏Ä‰∏™ÂÖ≥‰∫é{synonym}ÁöÑÊñáÊ°£ÔºåÊ∂âÂèä{category}È¢ÜÂüüÁöÑÂÜÖÂÆπ„ÄÇ"
                    X_train.append(sample_text)
                    y_train.append(category)
            
            # ËÆ≠ÁªÉÂàÜÁ±ªÂô®
            if len(X_train) > 0:
                self.ml_classifier.fit(X_train, y_train)
                self.ml_trained = True
                return True
            else:
                return False
                
        except Exception as e:
            st.error(f"ÂàùÂßãÂåñÈ¢ÑËÆ≠ÁªÉÂàÜÁ±ªÂô®Â§±Ë¥•: {str(e)}")
            return False
    
    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """‰ªéÊñáÊú¨‰∏≠ÊèêÂèñÂÖ≥ÈîÆËØç"""
        try:
            # ‰ΩøÁî®jiebaÁöÑTF-IDFÊèêÂèñÂÖ≥ÈîÆËØç
            keywords = jieba.analyse.extract_tags(text, topK=10, withWeight=False)
            return keywords
        except:
            # ÁÆÄÂçïÁöÑÂÖ≥ÈîÆËØçÊèêÂèñ
            words = jieba.lcut(text)
            word_count = Counter(words)
            stop_words = {'ÁöÑ', '‰∫Ü', 'Âú®', 'ÊòØ', 'Êàë', 'Êúâ', 'Âíå', 'Â∞±', '‰∏ç', '‰∫∫', 'ÈÉΩ', '‰∏Ä', '‰∏Ä‰∏™', '‰∏ä', '‰πü', 'Âæà', 'Âà∞', 'ËØ¥', 'Ë¶Å', 'Âéª', '‰Ω†', '‰ºö', 'ÁùÄ', 'Ê≤°Êúâ', 'Áúã', 'Â•Ω', 'Ëá™Â∑±', 'Ëøô'}
            filtered_words = {word: count for word, count in word_count.items() 
                            if len(word) > 1 and word not in stop_words and count > 1}
            return list(dict(sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:10]).keys())
    
    def extract_key_phrases(self, text: str, top_k: int = 10) -> List[str]:
        """ÊèêÂèñÂÖ≥ÈîÆÁü≠ËØ≠"""
        if not text:
            return []
        
        try:
            # ‰ΩøÁî®jiebaÁöÑTF-IDFÊèêÂèñÂÖ≥ÈîÆËØç
            keywords = jieba.analyse.extract_tags(text, topK=top_k, withWeight=False)
            return keywords
        except:
            # ÁÆÄÂçïÁöÑÂÖ≥ÈîÆËØçÊèêÂèñ
            words = jieba.lcut(text)
            word_count = Counter(words)
            # ËøáÊª§ÊéâÂçïÂ≠óÁ¨¶ÂíåÂ∏∏ËßÅÂÅúÁî®ËØç
            stop_words = {'ÁöÑ', '‰∫Ü', 'Âú®', 'ÊòØ', 'Êàë', 'Êúâ', 'Âíå', 'Â∞±', '‰∏ç', '‰∫∫', 'ÈÉΩ', '‰∏Ä', '‰∏Ä‰∏™', '‰∏ä', '‰πü', 'Âæà', 'Âà∞', 'ËØ¥', 'Ë¶Å', 'Âéª', '‰Ω†', '‰ºö', 'ÁùÄ', 'Ê≤°Êúâ', 'Áúã', 'Â•Ω', 'Ëá™Â∑±', 'Ëøô'}
            filtered_words = {word: count for word, count in word_count.items() 
                            if len(word) > 1 and word not in stop_words and count > 1}
            return list(dict(sorted(filtered_words.items(), key=lambda x: x[1], reverse=True)[:top_k]).keys())
    
    def generate_summary(self, text: str, max_length: int = 200) -> str:
        """Generate document summary (model first, fallback to rules)."""
        if not text:
            return "Unable to generate summary"
        
        # ÊñπÊ≥ï1: ‰ΩøÁî®T5Ê®°ÂûãÁîüÊàêÊëòË¶ÅÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if self.summarizer and len(text) > 50:
            try:
                # Êà™ÂèñÊñáÊú¨Ââç1024‰∏™Â≠óÁ¨¶ÔºàT5ÈôêÂà∂Ôºâ
                text_sample = text[:1024]
                summary_result = self.summarizer(
                    text_sample,
                    max_length=min(max_length, 150),
                    min_length=30,
                    do_sample=False
                )
                
                if summary_result and len(summary_result) > 0:
                    ai_summary = summary_result[0]['summary_text']
                    return f"ü§ñ AI Summary: {ai_summary}"
            except Exception as e:
                st.warning(f"T5 summarization failed: {str(e)}")
        
        # ÊñπÊ≥ï2: ‰ΩøÁî®OpenAI GPTÔºàÂ¶ÇÊûúÂèØÁî®Ôºâ
        if OPENAI_AVAILABLE and len(text) > 100:
            try:
                # ËøôÈáåÈúÄË¶ÅOpenAI APIÂØÜÈí•
                # ÊöÇÊó∂Ë∑≥ËøáÔºåÂõ†‰∏∫ÈúÄË¶ÅAPIÂØÜÈí•
                pass
            except Exception as e:
                st.warning(f"OpenAI summarization failed: {str(e)}")
        
        # ÊñπÊ≥ï3: Êô∫ËÉΩÂè•Â≠êÈÄâÊã©ÔºàÊîπËøõÁöÑËßÑÂàôÊñπÊ≥ïÔºâ
        try:
            # ‰ΩøÁî®Êõ¥Êô∫ËÉΩÁöÑÂè•Â≠êÈÄâÊã©
            sentences = re.split(r'[„ÄÇÔºÅÔºü.!?]', text)
            sentences = [s.strip() for s in sentences if s.strip() and len(s) > 10]
            
            if len(sentences) <= 2:
                return text[:max_length] + "..." if len(text) > max_length else text
            
            # ÈÄâÊã©ÊúÄÈáçË¶ÅÁöÑÂè•Â≠êÔºàÂü∫‰∫éÈïøÂ∫¶ÂíåÂÖ≥ÈîÆËØçÔºâ
            scored_sentences = []
            for i, sentence in enumerate(sentences):
                score = len(sentence)  # Âü∫Á°ÄÂàÜÊï∞ÔºöÂè•Â≠êÈïøÂ∫¶
                
                # ÂÖ≥ÈîÆËØçÂä†ÂàÜ
                important_words = ['ÈáçË¶Å', 'ÂÖ≥ÈîÆ', '‰∏ªË¶Å', 'Ê†∏ÂøÉ', 'ÊÄªÁªì', 'ÁªìËÆ∫', 'ÁªìÊûú', 'ÂèëÁé∞']
                for word in important_words:
                    if word in sentence:
                        score += 20
                
                # ‰ΩçÁΩÆÂä†ÂàÜÔºàÂºÄÂ§¥ÂíåÁªìÂ∞æÁöÑÂè•Â≠êÊõ¥ÈáçË¶ÅÔºâ
                if i < 2 or i >= len(sentences) - 2:
                    score += 10
                
                scored_sentences.append((score, sentence))
            
            # ÈÄâÊã©ÂæóÂàÜÊúÄÈ´òÁöÑ2-3‰∏™Âè•Â≠ê
            scored_sentences.sort(reverse=True)
            selected_sentences = [s[1] for s in scored_sentences[:3]]
            
            summary = '„ÄÇ'.join(selected_sentences)
            if len(summary) > max_length:
                summary = summary[:max_length] + "..."
            
            return f"üìù Smart summary: {summary}"
        except:
            # ÊñπÊ≥ï4: ÁÆÄÂçïÊà™ÂèñÔºàÊúÄÂêéÂ§áÁî®Ôºâ
            return text[:max_length] + "..." if len(text) > max_length else text
    
    def analyze_file_with_ai(self, file_id: int) -> Dict[str, Any]:
        """‰ΩøÁî®AIÂàÜÊûêÊñá‰ª∂"""
        # ÊèêÂèñÊñáÊú¨
        extracted_text = self.extract_text_from_file(file_id)
        
        if not extracted_text:
            return {"success": False, "error": "Unable to extract text"}
        
        # Ë°å‰∏öÂàÜÁ±ª
        classification = self.classify_industry(extracted_text)
        if isinstance(classification, dict) and 'category' in classification:
            classification['category'] = self._to_english_category(classification['category'])
        
        # ÊèêÂèñÂÖ≥ÈîÆÁü≠ËØ≠
        key_phrases = self.extract_key_phrases(extracted_text)
        
        # ÁîüÊàêÊëòË¶Å
        summary = self.generate_summary(extracted_text)
        
        # ‰øùÂ≠òÂàÜÊûêÁªìÊûúÂà∞Êï∞ÊçÆÂ∫ì
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO ai_analysis (file_id, analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (file_id, "full_analysis", classification["category"], 
              extracted_text[:1000], json.dumps(key_phrases, ensure_ascii=False), 
              summary, classification["confidence"], classification.get("method", "Unknown")))
        
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "extracted_text": extracted_text,
            "classification": classification,
            "key_phrases": key_phrases,
            "summary": summary
        }
    
    def get_ai_analysis(self, file_id: int) -> Optional[Dict[str, Any]]:
        """Ëé∑ÂèñÊñá‰ª∂ÁöÑAIÂàÜÊûêÁªìÊûú"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            SELECT analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method, analysis_time
            FROM ai_analysis WHERE file_id = ? ORDER BY analysis_time DESC LIMIT 1
        ''', (file_id,))
        result = cursor.fetchone()
        conn.close()
        
        if result:
            analysis_type, industry_category, extracted_text, key_phrases, summary, confidence_score, method, analysis_time = result
            return {
                "analysis_type": analysis_type,
                "industry_category": industry_category,
                "extracted_text": extracted_text,
                "key_phrases": json.loads(key_phrases) if key_phrases else [],
                "summary": summary,
                "confidence_score": confidence_score,
                "method": method or "Unknown",
                "analysis_time": analysis_time
            }
        return None
    
    def create_industry_folder(self, category: str) -> int:
        """‰∏∫Ë°å‰∏öÂàÜÁ±ªÂàõÂª∫Êñá‰ª∂Â§π"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ê£ÄÊü•Êñá‰ª∂Â§πÊòØÂê¶Â∑≤Â≠òÂú®ÔºàËã±ÊñáÂëΩÂêçÔºâ
        eng_category = self._to_english_category(category)
        cursor.execute('SELECT id FROM folders WHERE folder_name = ?', (f"AI_{eng_category}",))
        result = cursor.fetchone()
        
        if result:
            folder_id = result[0]
        else:
            cursor.execute('''
                INSERT INTO folders (folder_name, parent_folder_id)
                VALUES (?, ?)
            ''', (f"AI_{eng_category}", None))
            folder_id = cursor.lastrowid
        
        conn.commit()
        conn.close()
        return folder_id
    
    def move_file_to_industry_folder(self, file_id: int, category: str) -> bool:
        """Â∞ÜÊñá‰ª∂ÁßªÂä®Âà∞Ë°å‰∏öÂàÜÁ±ªÊñá‰ª∂Â§π"""
        try:
            folder_id = self.create_industry_folder(category)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('UPDATE files SET folder_id = ? WHERE id = ?', (folder_id, file_id))
            conn.commit()
            conn.close()
            return True
        except:
            return False
    
    # ==================== Âü∫Á°ÄÊñá‰ª∂ÁÆ°ÁêÜÂäüËÉΩ ====================
    
    def rename_file(self, file_id: int, new_filename: str) -> Dict[str, Any]:
        """ÈáçÂëΩÂêçÊñá‰ª∂"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ê£ÄÊü•Êñ∞Êñá‰ª∂ÂêçÊòØÂê¶Â∑≤Â≠òÂú®
            cursor.execute('SELECT id FROM files WHERE filename = ? AND id != ?', (new_filename, file_id))
            if cursor.fetchone():
                conn.close()
                return {"success": False, "error": "Êñá‰ª∂ÂêçÂ∑≤Â≠òÂú®"}
            
            # Êõ¥Êñ∞Êñá‰ª∂Âêç
            cursor.execute('UPDATE files SET filename = ? WHERE id = ?', (new_filename, file_id))
            conn.commit()
            conn.close()
            
            return {"success": True, "new_filename": new_filename}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def delete_file(self, file_id: int) -> Dict[str, Any]:
        """Âà†Èô§Êñá‰ª∂"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ëé∑ÂèñÊñá‰ª∂Ë∑ØÂæÑ
            cursor.execute('SELECT file_path FROM files WHERE id = ?', (file_id,))
            result = cursor.fetchone()
            
            if result:
                file_path = result[0]
                
                # Âà†Èô§Áâ©ÁêÜÊñá‰ª∂
                if os.path.exists(file_path):
                    os.remove(file_path)
                
                # Âà†Èô§Êï∞ÊçÆÂ∫ìËÆ∞ÂΩï
                cursor.execute('DELETE FROM files WHERE id = ?', (file_id,))
                
                # Âà†Èô§AIÂàÜÊûêËÆ∞ÂΩï
                cursor.execute('DELETE FROM ai_analysis WHERE file_id = ?', (file_id,))
                
                conn.commit()
                conn.close()
                
                return {"success": True}
            else:
                conn.close()
                return {"success": False, "error": "Êñá‰ª∂‰∏çÂ≠òÂú®"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def rename_folder(self, folder_id: int, new_folder_name: str) -> Dict[str, Any]:
        """ÈáçÂëΩÂêçÊñá‰ª∂Â§π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ê£ÄÊü•Êñ∞Êñá‰ª∂Â§πÂêçÊòØÂê¶Â∑≤Â≠òÂú®
            cursor.execute('SELECT id FROM folders WHERE folder_name = ? AND id != ?', (new_folder_name, folder_id))
            if cursor.fetchone():
                conn.close()
                return {"success": False, "error": "Êñá‰ª∂Â§πÂêçÂ∑≤Â≠òÂú®"}
            
            # Êõ¥Êñ∞Êñá‰ª∂Â§πÂêç
            cursor.execute('UPDATE folders SET folder_name = ? WHERE id = ?', (new_folder_name, folder_id))
            conn.commit()
            conn.close()
            
            return {"success": True, "new_folder_name": new_folder_name}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def delete_folder(self, folder_id: int) -> Dict[str, Any]:
        """Âà†Èô§Êñá‰ª∂Â§π"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ê£ÄÊü•Êñá‰ª∂Â§πÊòØÂê¶‰∏∫Á©∫
            cursor.execute('SELECT COUNT(*) FROM files WHERE folder_id = ?', (folder_id,))
            file_count = cursor.fetchone()[0]
            
            if file_count > 0:
                conn.close()
                return {"success": False, "error": f"Êñá‰ª∂Â§π‰∏ç‰∏∫Á©∫ÔºåÂåÖÂê´ {file_count} ‰∏™Êñá‰ª∂"}
            
            # Ê£ÄÊü•ÊòØÂê¶ÊúâÂ≠êÊñá‰ª∂Â§π
            cursor.execute('SELECT COUNT(*) FROM folders WHERE parent_folder_id = ?', (folder_id,))
            subfolder_count = cursor.fetchone()[0]
            
            if subfolder_count > 0:
                conn.close()
                return {"success": False, "error": f"Êñá‰ª∂Â§πÂåÖÂê´ {subfolder_count} ‰∏™Â≠êÊñá‰ª∂Â§π"}
            
            # Âà†Èô§Êñá‰ª∂Â§π
            cursor.execute('DELETE FROM folders WHERE id = ?', (folder_id,))
            conn.commit()
            conn.close()
            
            return {"success": True}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_folders(self, parent_folder_id: Optional[int] = None) -> List[Dict[str, Any]]:
        """Ëé∑ÂèñÊñá‰ª∂Â§πÂàóË°®"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if parent_folder_id is None:
            cursor.execute('''
                SELECT id, folder_name, created_time, 
                       (SELECT COUNT(*) FROM files WHERE folder_id = folders.id) as file_count
                FROM folders 
                WHERE parent_folder_id IS NULL
                ORDER BY created_time DESC
            ''')
        else:
            cursor.execute('''
                SELECT id, folder_name, created_time,
                       (SELECT COUNT(*) FROM files WHERE folder_id = folders.id) as file_count
                FROM folders 
                WHERE parent_folder_id = ?
                ORDER BY created_time DESC
            ''', (parent_folder_id,))
        
        folders = []
        for row in cursor.fetchall():
            folders.append({
                "id": row[0],
                "folder_name": row[1],
                "created_time": row[2],
                "file_count": row[3]
            })
        
        conn.close()
        return folders
    
    def sync_cached_files(self) -> Dict[str, Any]:
        """ÂêåÊ≠•ÁºìÂ≠òÊñá‰ª∂Âà∞‰∫ëÁ´Ø"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ëé∑ÂèñÊâÄÊúâÂ∑≤ÁºìÂ≠òÁöÑÊñá‰ª∂
            cursor.execute('''
                SELECT id, filename, file_path, last_modified
                FROM files 
                WHERE is_cached = TRUE
            ''')
            
            cached_files = cursor.fetchall()
            synced_count = 0
            
            for file_id, filename, file_path, last_modified in cached_files:
                # Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶‰ªçÁÑ∂Â≠òÂú®
                if os.path.exists(file_path):
                    # Êõ¥Êñ∞ÊúÄÂêé‰øÆÊîπÊó∂Èó¥
                    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    cursor.execute('''
                        UPDATE files 
                        SET last_modified = ? 
                        WHERE id = ?
                    ''', (current_time, file_id))
                    synced_count += 1
            
            conn.commit()
            conn.close()
            
            return {
                "success": True,
                "synced_count": synced_count,
                "message": f"ÊàêÂäüÂêåÊ≠• {synced_count} ‰∏™ÁºìÂ≠òÊñá‰ª∂"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

# ÂàùÂßãÂåñ‰∫ëÂ≠òÂÇ®ÁÆ°ÁêÜÂô®
if 'storage_manager' not in st.session_state:
    st.session_state.storage_manager = CloudStorageManager()

storage_manager = st.session_state.storage_manager

# Sidebar - Clean layout inspired by Baidu Cloud
with st.sidebar:
    # Header
    st.markdown("### üåæ Agribusiness Cloud")
    st.markdown("---")
    
    # Main Navigation
    st.markdown("**Main**")
    nav_selected = st.radio(
        "Navigation",
        ["Home", "AI Analysis", "Tools", "Settings"],
        label_visibility="collapsed",
        key="main_nav"
    )
    
    if nav_selected == "Home":
        st.session_state.current_view = "home"
    elif nav_selected == "AI Analysis":
        st.session_state.current_view = "ai_analysis"
    elif nav_selected == "Tools":
        st.session_state.current_view = "tools"
    else:
        st.session_state.current_view = "settings"
    
    st.markdown("---")
    
    # File Categories
    st.markdown("**My Files**")
    category_selected = st.radio(
        "File Categories",
        ["All Files", "Documents", "Images", "Spreadsheets", "PDFs", "Other"],
        label_visibility="collapsed",
        key="file_category"
    )
    
    st.markdown("---")
    
    # Quick Access - Folders
    st.markdown("**Quick Access**")
    folders = storage_manager.get_folders()
    if folders:
        for folder in folders[:5]:  # Show top 5
            if st.button(f"üìÅ {folder['folder_name']}", key=f"nav_folder_{folder['id']}", use_container_width=True):
                st.session_state.current_folder_id = folder['id']
                st.rerun()
    
    # Create new folder
    with st.expander("‚ûï New Folder", expanded=False):
        folder_name = st.text_input("Folder name", placeholder="Enter name", key="new_folder_input")
        if st.button("Create", key="create_folder_btn", use_container_width=True):
            if folder_name:
                result = storage_manager.create_folder(folder_name)
                if result["success"]:
                    st.success("Created!")
                    st.rerun()
                else:
                    st.error(result.get('error', 'Failed'))
    
    st.markdown("---")
    
    # Storage Usage (bottom)
    all_files = storage_manager.get_files()
    total_size = sum(f.get('file_size', 0) for f in all_files)
    total_size_gb = total_size / (1024**3)
    st.markdown(f"**Storage:** {total_size_gb:.1f} GB used")
    st.progress(min(total_size_gb / 100, 1.0))  # Assume 100GB limit for visual
    
    # Collapsible AI Tools Section
    with st.expander("ü§ñ AI Tools", expanded=False):
        if st.button("üß† Smart Analysis", use_container_width=True):
            st.session_state.show_ai_analysis = True
            st.rerun()
        if st.button("üìä Industry View", use_container_width=True):
            st.session_state.show_industry_view = True
            st.rerun()
    
    # Collapsible Calculator
    with st.expander("üßÆ Calculator", expanded=False):
        colc1, colc2 = st.columns(2)
        with colc1:
            area_value = st.number_input("Area", value=100.0, step=1.0, key="calc_area")
            area_unit = st.selectbox("Unit", ["ha", "mu"], key="calc_area_unit")
        with colc2:
            yield_value = st.number_input("Yield", value=3.0, step=0.1, key="calc_yield")
            yield_unit = st.selectbox("Yield Unit", ["t/ha", "kg/ha"], key="calc_yield_unit")
        price = st.number_input("Price (per kg)", value=0.5, step=0.05, key="calc_price")
        cost = st.number_input("Total Cost", value=50000.0, step=1000.0, key="calc_cost")
        
        if st.button("Calculate", use_container_width=True):
            # Convert to kg/mu
            if yield_unit == "t/ha":
                yield_kg_per_mu = (yield_value * 1000.0) / 15.0
            else:
                yield_kg_per_mu = yield_value / 15.0
            area_mu = area_value * (15.0 if area_unit == "ha" else 1.0)
            total_kg = area_mu * yield_kg_per_mu
            revenue = total_kg * price
            profit = revenue - cost
            st.write({
                "Production (kg)": round(total_kg, 2),
                "Revenue": round(revenue, 2),
                "Profit": round(profit, 2)
            })

# Main Content Area - Clean layout inspired by Baidu Cloud
current_view = st.session_state.get('current_view', 'home')

# Top Action Bar
col_action1, col_action2, col_action3, col_action4 = st.columns([1, 1, 1, 3])

with col_action1:
    if st.button("üì§ Upload", use_container_width=True, type="primary"):
        st.session_state.show_upload = True
    else:
        st.session_state.show_upload = False

with col_action2:
    folder_name_new = st.text_input("New folder", placeholder="Folder name", label_visibility="collapsed", key="top_new_folder")
    if folder_name_new:
        if st.button("Create", key="top_create_btn"):
            result = storage_manager.create_folder(folder_name_new)
            if result["success"]:
                st.success("Created!")
                st.rerun()

with col_action3:
    st.button("üîÑ Sync", use_container_width=True)

with col_action4:
    search_query_top = st.text_input("Search", placeholder="Search files...", label_visibility="collapsed", key="top_search")
    if search_query_top:
        search_results_top = storage_manager.search_files(search_query_top, None)
        if search_results_top:
            st.session_state.search_results = search_results_top
            st.session_state.show_search = True
        else:
            st.session_state.show_search = False

st.markdown("---")

# Current folder breadcrumb
current_folder_id = st.session_state.get('current_folder_id', None)
if current_folder_id is not None:
    conn = sqlite3.connect(storage_manager.db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT folder_name FROM folders WHERE id = ?', (current_folder_id,))
    folder_name = cursor.fetchone()
    conn.close()
    if folder_name:
        col_bread1, col_bread2 = st.columns([10, 1])
        with col_bread1:
            st.markdown(f"üìÅ **{folder_name[0]}**")
        with col_bread2:
            if st.button("‚¨ÖÔ∏è Back", use_container_width=True):
                st.session_state.current_folder_id = None
                st.rerun()
        st.markdown("---")

# Upload area (collapsible)
if st.session_state.get('show_upload', False):
    with st.expander("üì§ Upload Files", expanded=True):
        uploaded_files = st.file_uploader(
            "Choose files", 
            type=["xlsx", "xls", "csv", "pdf", "png", "jpg", "jpeg", "gif", "bmp", "txt", "doc", "docx"],
            accept_multiple_files=True
        )
        if uploaded_files:
            for uploaded_file in uploaded_files:
                col_up1, col_up2 = st.columns([4, 1])
                with col_up1:
                    st.write(f"üìÑ {uploaded_file.name} ({storage_manager.format_file_size(len(uploaded_file.getbuffer()))})")
                with col_up2:
                    if st.button("Upload", key=f"upload_{uploaded_file.name}", use_container_width=True):
                        result = storage_manager.upload_file(uploaded_file, current_folder_id)
                        if result["success"]:
                            st.success("‚úÖ Uploaded!")
                            st.rerun()
                        else:
                            st.error(f"Failed: {result.get('error')}")

# File List - Table View (Baidu Cloud style)
st.markdown("### All Files")

# Ê£ÄÊü•ÊòæÁ§∫Ê®°Âºè
files = []  # Á°Æ‰øùÂêéÁª≠‰ΩøÁî®Êó∂Â∑≤ÂÆö‰πâ
if st.session_state.get('show_ai_analysis', False):
    st.markdown("### ü§ñ AI Smart Analysis")
    
    # Ëé∑ÂèñÊâÄÊúâÊñá‰ª∂ËøõË°åAIÂàÜÊûê
    all_files = storage_manager.get_files()
    
    if all_files:
        st.info(f"Analyzing {len(all_files)} files with AI...")
        
        # ÊâπÈáèAIÂàÜÊûê
        analysis_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, file in enumerate(all_files):
            status_text.text(f"Analyzing: {file['filename']}")
            result = storage_manager.analyze_file_with_ai(file['id'])
            analysis_results.append({
                'file': file,
                'analysis': result
            })
            progress_bar.progress((i + 1) / len(all_files))
        
        progress_bar.empty()
        status_text.empty()
        
        # ÊòæÁ§∫ÂàÜÊûêÁªìÊûú
        st.success("AI analysis completed!")
        
        # ÊåâË°å‰∏öÂàÜÁ±ªÊòæÁ§∫
        industry_groups = {}
        for result in analysis_results:
            if result['analysis']['success']:
                category = result['analysis']['classification']['category']
                if category not in industry_groups:
                    industry_groups[category] = []
                industry_groups[category].append(result)
        
        for category, files in industry_groups.items():
            with st.expander(f"üìä {category} ({len(files)} files)", expanded=True):
                for result in files:
                    file = result['file']
                    analysis = result['analysis']
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"üìÑ {file['filename']}")
                        st.caption(f"Confidence: {analysis['classification']['confidence']:.2%}")
                        if analysis['summary']:
                            st.info(f"Summary: {analysis['summary']}")
                    with col2:
                        if st.button("üìÅ Classify", key=f"batch_classify_{file['id']}"):
                            if storage_manager.move_file_to_industry_folder(file['id'], category):
                                st.success("Classified!")
                                st.rerun()
    
    else:
        st.warning("No files to analyze")

elif st.session_state.get('show_industry_view', False):
    st.markdown("### üìä Industry Classification View")
    
    # Ëé∑ÂèñÊâÄÊúâË°å‰∏öÂàÜÁ±ª
    conn = sqlite3.connect(storage_manager.db_path)
    cursor = conn.cursor()
    cursor.execute('''
        SELECT DISTINCT industry_category, COUNT(*) as file_count
        FROM ai_analysis 
        WHERE industry_category IS NOT NULL
        GROUP BY industry_category
        ORDER BY file_count DESC
    ''')
    categories = cursor.fetchall()
    conn.close()
    
    if categories:
        for category, count in categories:
            with st.expander(f"üìÅ {category} ({count} files)", expanded=True):
                # Ëé∑ÂèñËØ•ÂàÜÁ±ªÁöÑÊñá‰ª∂
                conn = sqlite3.connect(storage_manager.db_path)
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT f.id, f.filename, f.file_size, f.upload_time, a.confidence_score, a.summary
                    FROM files f
                    JOIN ai_analysis a ON f.id = a.file_id
                    WHERE a.industry_category = ?
                    ORDER BY a.confidence_score DESC
                ''', (category,))
                file_rows = cursor.fetchall()
                conn.close()
                
                # ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏Ê†ºÂºè‰ª•‰øùÊåÅ‰∏ÄËá¥ÊÄß
                files = []
                for file_id, filename, file_size, upload_time, confidence, summary in file_rows:
                    files.append({
                        "id": file_id,
                        "filename": filename,
                        "file_size": file_size,
                        "upload_time": upload_time,
                        "confidence": confidence,
                        "summary": summary
                    })
                
                for file in files:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"üìÑ {file['filename']}")
                        st.caption(f"Uploaded: {file['upload_time']}")
                        if file['summary']:
                            st.info(f"Summary: {file['summary']}")
                    with col2:
                        st.metric("Confidence", f"{file['confidence']:.2%}")
                    with col3:
                        st.metric("File Size", storage_manager.format_file_size(file['file_size']))
    else:
        st.info("No files have been analyzed by AI yet")

# File List Display - Baidu Cloud Style
if st.session_state.get('show_search', False) and 'search_results' in st.session_state:
    files = st.session_state.search_results
    st.info(f"üîç Found {len(files)} files")
else:
    files = storage_manager.get_files(current_folder_id)
    
    # Show subfolders first
    if current_folder_id is None:
        subfolders = storage_manager.get_folders()
    else:
        subfolders = storage_manager.get_folders(current_folder_id)

# Prepare table data
if subfolders or files:
    # Folders section - Baidu Cloud style
    if subfolders:
        st.markdown("### üìÅ Êñá‰ª∂Â§π")
        cols = st.columns(4)  # 4 columns for folder grid
        for idx, folder in enumerate(subfolders):
            with cols[idx % 4]:
                if st.button(f"üìÅ {folder['folder_name']}", key=f"folder_{folder['id']}", use_container_width=True):
                    st.session_state.current_folder_id = folder['id']
                    st.rerun()
    
    st.markdown("---")
    
    # Files section - Baidu Cloud card layout
    if files:
        st.markdown("### üìÑ Êñá‰ª∂ÂàóË°®")
        
        # View mode toggle
        view_mode = st.radio("ËßÜÂõæÊ®°Âºè", ["Âç°ÁâáËßÜÂõæ", "ÂàóË°®ËßÜÂõæ"], horizontal=True, key="view_mode")
        
        if view_mode == "Âç°ÁâáËßÜÂõæ":
            # Grid layout for cards
            cols = st.columns(4)
            for idx, file in enumerate(files):
                with cols[idx % 4]:
                    with st.container():
                        # File card
                        file_icon = storage_manager.get_file_icon(file.get('file_type', 'unknown'))
                        color_class = storage_manager.get_file_color_class(file.get('file_type', 'unknown'))
                        
                        st.markdown(f"""
                        <div class="file-grid-card" style="position: relative;">
                            <div style="text-align: center; margin-bottom: 12px;">
                                <div class="{color_class}" style="font-size: 48px; margin-bottom: 8px;">{file_icon}</div>
                                <div style="font-weight: 500; color: #333; margin-bottom: 4px; font-size: 14px; line-height: 1.4; height: 40px; overflow: hidden; text-overflow: ellipsis;">
                                    {file.get('filename', 'Unknown')}
                                </div>
                                <div style="color: #999; font-size: 12px; margin-bottom: 8px;">
                                    {storage_manager.format_file_size(file.get('file_size', 0))}
                                </div>
                                <div style="margin-bottom: 8px;">
                                    <span class="{'status-cached' if file.get('is_cached', False) else 'status-cloud'}">
                                        {'Â∑≤ÁºìÂ≠ò' if file.get('is_cached', False) else '‰∫ëÁ´Ø'}
                                    </span>
                                </div>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Action buttons
                        col1, col2 = st.columns(2)
                        with col1:
                            if st.button("È¢ÑËßà", key=f"preview_card_{file['id']}", use_container_width=True):
                                st.session_state[f"show_preview_{file['id']}"] = True
                        with col2:
                            with st.popover("Êõ¥Â§ö", use_container_width=True):
                                if st.button("AIÂàÜÊûê", key=f"ai_card_{file['id']}"):
                                    with st.spinner("AIÂàÜÊûê‰∏≠..."):
                                        result = storage_manager.analyze_file_with_ai(file['id'])
                                        if result["success"]:
                                            st.success("ÂàÜÊûêÂÆåÊàê!")
                                            st.rerun()
                                
                                if st.button("‰∏ãËΩΩ", key=f"download_card_{file['id']}"):
                                    file_data = storage_manager.preview_file(file['id'])
                                    if file_data:
                                        st.download_button(
                                            "‰∏ãËΩΩÊñá‰ª∂",
                                            file_data,
                                            file.get('filename', 'file'),
                                            key=f"dl_card_{file['id']}"
                                        )
                                
                                if not file.get('is_cached', False):
                                    if st.button("ÁºìÂ≠ò", key=f"cache_card_{file['id']}"):
                                        if storage_manager.cache_file(file['id']):
                                            st.success("ÁºìÂ≠òÊàêÂäü!")
                                            st.rerun()
                                        else:
                                            st.error("ÁºìÂ≠òÂ§±Ë¥•")
                                else:
                                    st.success("Â∑≤ÁºìÂ≠ò")
                                
                                if st.button("Âà†Èô§", key=f"delete_card_{file['id']}"):
                                    result = storage_manager.delete_file(file['id'])
                                    if result["success"]:
                                        st.success("Âà†Èô§ÊàêÂäü!")
                                        st.rerun()
                        
                        # Show preview if requested
                        if st.session_state.get(f"show_preview_{file['id']}", False):
                            with st.expander("Êñá‰ª∂È¢ÑËßà", expanded=True):
                                file_preview_data = storage_manager.preview_file(file['id'])
                                if file_preview_data:
                                    if file.get('file_type') == 'image':
                                        st.image(file_preview_data, caption=file.get('filename'))
                                    elif file.get('file_type') == 'application' and str(file.get('filename','')).endswith('.pdf'):
                                        if PDF_AVAILABLE:
                                            try:
                                                import io
                                                pdf_stream = io.BytesIO(file_preview_data)
                                                doc = fitz.open(stream=pdf_stream, filetype="pdf")
                                                if len(doc) > 0:
                                                    page = doc.load_page(0)
                                                    pix = page.get_pixmap()
                                                    img_data = pix.tobytes("png")
                                                    st.image(img_data, caption=file.get('filename'))
                                                doc.close()
                                            except Exception as e:
                                                st.error(f"PDFÈ¢ÑËßàÂ§±Ë¥•: {str(e)}")
                                                st.download_button("‰∏ãËΩΩÊñá‰ª∂", file_preview_data, file.get('filename'))
                                        else:
                                            st.info("PDFÈ¢ÑËßàÂäüËÉΩÈúÄË¶ÅPyMuPDFÂ∫ì")
                                            st.download_button("‰∏ãËΩΩÊñá‰ª∂", file_preview_data, file.get('filename'))
                                    else:
                                        st.info("ËØ•Êñá‰ª∂Á±ªÂûãÊöÇ‰∏çÊîØÊåÅÈ¢ÑËßà")
                                        st.download_button("‰∏ãËΩΩÊñá‰ª∂", file_preview_data, file.get('filename'))
                                else:
                                    st.error("Êó†Ê≥ïÈ¢ÑËßàÊ≠§Êñá‰ª∂")
        else:
            # List view - more compact
            for file in files:
                with st.container():
                    # File card in list format
                    file_icon = storage_manager.get_file_icon(file.get('file_type', 'unknown'))
                    color_class = storage_manager.get_file_color_class(file.get('file_type', 'unknown'))
                    
                    col1, col2, col3, col4 = st.columns([1, 4, 2, 3])
                    
                    with col1:
                        st.markdown(f"<div class='{color_class}' style='font-size: 24px;'>{file_icon}</div>", unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"**{file.get('filename', 'Unknown')}**")
                        st.caption(f"Á±ªÂûã: {file.get('file_type', 'unknown')} | ‰∏ä‰º†Êó∂Èó¥: {file.get('upload_time', '')}")
                    
                    with col3:
                        st.markdown(f"**{storage_manager.format_file_size(file.get('file_size', 0))}**")
                        st.markdown(f"<span class='{'status-cached' if file.get('is_cached', False) else 'status-cloud'}'>{'Â∑≤ÁºìÂ≠ò' if file.get('is_cached', False) else '‰∫ëÁ´Ø'}</span>", unsafe_allow_html=True)
                    
                    with col4:
                        # Action buttons
                        col_a1, col_a2, col_a3 = st.columns(3)
                        with col_a1:
                            if st.button("üëÅÔ∏è", key=f"preview_list_{file['id']}", help="È¢ÑËßàÊñá‰ª∂"):
                                st.session_state[f"show_preview_{file['id']}"] = True
                        with col_a2:
                            with st.popover("‚öôÔ∏è"):
                                if st.button("AIÂàÜÊûê", key=f"ai_list_{file['id']}"):
                                    with st.spinner("AIÂàÜÊûê‰∏≠..."):
                                        result = storage_manager.analyze_file_with_ai(file['id'])
                                        if result["success"]:
                                            st.success("ÂàÜÊûêÂÆåÊàê!")
                                            st.rerun()
                                
                                if st.button("‰∏ãËΩΩ", key=f"download_list_{file['id']}"):
                                    file_data = storage_manager.preview_file(file['id'])
                                    if file_data:
                                        st.download_button(
                                            "‰∏ãËΩΩÊñá‰ª∂",
                                            file_data,
                                            file.get('filename', 'file'),
                                            key=f"dl_list_{file['id']}"
                                        )
                                
                                if not file.get('is_cached', False):
                                    if st.button("ÁºìÂ≠ò", key=f"cache_list_{file['id']}"):
                                        if storage_manager.cache_file(file['id']):
                                            st.success("ÁºìÂ≠òÊàêÂäü!")
                                            st.rerun()
                                        else:
                                            st.error("ÁºìÂ≠òÂ§±Ë¥•")
                                
                                if st.button("Âà†Èô§", key=f"delete_list_{file['id']}"):
                                    result = storage_manager.delete_file(file['id'])
                                    if result["success"]:
                                        st.success("Âà†Èô§ÊàêÂäü!")
                                        st.rerun()
                        with col_a3:
                            st.button("üìà", key=f"report_list_{file['id']}", help="Êô∫ËÉΩÊä•Âëä")
                    
                    # Show preview if requested
                    if st.session_state.get(f"show_preview_{file['id']}", False):
                        with st.expander("Êñá‰ª∂È¢ÑËßà", expanded=True):
                            file_preview_data = storage_manager.preview_file(file['id'])
                            if file_preview_data:
                                if file.get('file_type') == 'image':
                                    st.image(file_preview_data, caption=file.get('filename'))
                                elif file.get('file_type') == 'application' and str(file.get('filename','')).endswith('.pdf'):
                                    if PDF_AVAILABLE:
                                        try:
                                            import io
                                            pdf_stream = io.BytesIO(file_preview_data)
                                            doc = fitz.open(stream=pdf_stream, filetype="pdf")
                                            if len(doc) > 0:
                                                page = doc.load_page(0)
                                                pix = page.get_pixmap()
                                                img_data = pix.tobytes("png")
                                                st.image(img_data, caption=file.get('filename'))
                                            doc.close()
                                        except Exception as e:
                                            st.error(f"PDFÈ¢ÑËßàÂ§±Ë¥•: {str(e)}")
                                            st.download_button("‰∏ãËΩΩÊñá‰ª∂", file_preview_data, file.get('filename'))
                                    else:
                                        st.info("PDFÈ¢ÑËßàÂäüËÉΩÈúÄË¶ÅPyMuPDFÂ∫ì")
                                        st.download_button("‰∏ãËΩΩÊñá‰ª∂", file_preview_data, file.get('filename'))
                                else:
                                    st.info("ËØ•Êñá‰ª∂Á±ªÂûãÊöÇ‰∏çÊîØÊåÅÈ¢ÑËßà")
                                    st.download_button("‰∏ãËΩΩÊñá‰ª∂", file_preview_data, file.get('filename'))
                            else:
                                st.error("Êó†Ê≥ïÈ¢ÑËßàÊ≠§Êñá‰ª∂")
                
                st.markdown("---")

# Footer
st.markdown("---")
st.markdown("**Built with ‚ù§Ô∏è ‚Ä¢ AI Cloud Storage System ‚Ä¢ ‚òÅÔ∏è Intelligent Storage**")